model.optimizer = "bobyqa",
n.iter = 1000000,
verbose = verbose)
# Use trained model to make predictions for kth validation set
pred_m <- stats::predict(model_m, newdata = data_valid,
type = "response", allow.new.levels = TRUE)
# Evaluate predictions based on loss function
perform_m <- loss_function(pred = pred_m, data.valid = data_valid,
unit = "individual", measure = "mse",
y = y, geo.unit = geo.unit)
})
# Mean over all k folds
mean(unlist(k_errors))
})
# Choose best-performing model
min.m <- which.min(m_errors)
out <- models[[min.m]]
# Function output
return(out)
}
best_subset_out <- best_subset(y = y, L1.x = L1.x, L2.x = L2.x,
geo.unit = geo.unit,
cv.data = cv_folds,
verbose = TRUE)
best_subset_out
# Individual-level random effects
L1_re <- paste(paste("(1 | ", L1.x, ")", sep = ""), collapse = " + ")
list(as.formula(paste(y, " ~ ", L1_re, sep = "")))
y
# Remaining models
L2_list <- lapply(seq_along(L2.x), function(x) combn(L2.x, x))
lapply(L2_list, function(x) apply(x, 2, function(c)
as.formula(paste(y, " ~ ", paste(c, collapse = " + "), " + ", L1_re, sep = "")))) %>%
unlist()
paste(L1.x, collapse = " + ")
paste(L2.x, collapse = " + ")
as.formula(paste(y, " ~ ", L2_fe, sep = ""))
# Context-level fixed effects
L2_fe <- paste(L2.x, collapse = " + ")
as.formula(paste(y, " ~ ", L2_fe, sep = ""))
L1.x
setNames(as.list(rep(~ 1, times = length(L1.x))), L1.x)
setNames(as.list(rep(c(~ 1), times = length(L1.x))), L1.x)
L2.fix
L2_fe <- paste(L2.x, collapse = " + ")
L2_fe_form <- as.formula(paste(y, " ~ ", L2_fe, sep = ""))
# Individual-level random effects as named list
L1_re <- setNames(as.list(rep(c(~ 1), times = length(L1.x))), L1.x)
L2.fix
install.packages("glmmLasso")
data.frame(c(1, 2), c(2, 3))
is.vector(data.frame(c(1, 2), c(2, 3)))
c(1, 2)
is.vector(c(1, 2))
is.data.frame(c(1, 2))
setNames(as.list(rep(c(~ 1), times = length(L1.x))), L1.x)
L2_fe_form
c(1, 2, 3)
0 %in% c(1, 2, 3)
L1
1L
0L
0 %in% c(0, 1, 2, 3)
0 %in% c(0L, 1, 2, 3)
test <- c(1, 2, 3)
!0 in test
!0 %in% test
c(0, test)
L2_fe_form
class(cv.data)
length(cv.data)
k <- 1
k
# Split data in training and validation sets
data_train <- dplyr::bind_rows(cv.data[-k])
data_valid <- dplyr::bind_rows(cv.data[k])
dim(data_train)
dim(data_valid)
lasso_classifier <- function(L2.fix, L1.re, data.train, lambda,
model.family = binomial(link = "probit"),
verbose = c(TRUE, FALSE)) {
# Train model on training data with lambda as tuning parameter
if (verbose == TRUE) {
out <- glmmLasso::glmmLasso(fix = L2.fix, rnd = L1.re,
data = data.train, lambda = lambda,
family = model.family,
switch.NR = FALSE, final.re = TRUE,
control = list(standarize = FALSE))
} else {
}
}
verbose
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda,
model.family = binomial(link = "probit"),
verbose = verbose)
lambda <- 2
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda,
model.family = binomial(link = "probit"),
verbose = verbose)
model_l
summary(model_l)
class(model_l)
pred_l <- stats::predict(model_l, newdata = data_valid,
type = "response", allow.new.levels = TRUE)
class(pred_l)
dim(pred_l)
head(pred_l)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data_valid)
head(pred_l)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data_valid)
dim(pred_l)
head(pred_l)
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
unit = "individual", measure = "mse",
y = y, geo.unit = geo.unit)
class(perform_l)
length(perform_l)
head(perform_l)
dim(data_valid)
pred_m <- stats::predict(model_m, newdata = data_valid,
type = "response", allow.new.levels = TRUE)
class(pred_m)
length(pred_m)
class(pred_l)
dim(pred_l)
lasso_classifier <- function(L2.fix, L1.re, data.train, lambda,
model.family = binomial(link = "probit"),
verbose = c(TRUE, FALSE)) {
# Train model on training data with lambda as tuning parameter
if (verbose == TRUE) {
out <- glmmLasso::glmmLasso(fix = L2.fix, rnd = L1.re,
data = data.train, lambda = lambda,
family = model.family,
switch.NR = FALSE, final.re = TRUE,
control = list(standarize = FALSE))
} else {
}
# Function output
return(out)
}
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda,
model.family = binomial(link = "probit"),
verbose = verbose)
summary(model_l)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data_valid)
dim(pred_l)
head(pred_l)
class(c(pred_l))
dim(c(pred_l))
length(c(pred_l))
head(c(pred_l))
pred_l <- stats::predict(model_l, newdata = data_valid) %>%
c()
head(pred_l)
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
unit = "individual", measure = "mse",
y = y, geo.unit = geo.unit)
class(perform_l)
length(perform_l)
head(perform_l)
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
unit = "individual", measure = "mse",
y = y, geo.unit = geo.unit)
length(perform_l)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data_valid)
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
unit = "individual", measure = "mse",
y = y, geo.unit = geo.unit)
perform_l
k_errors <- lapply(seq_along(cv.data), function(k) {
# Split data in training and validation sets
data_train <- dplyr::bind_rows(cv.data[-k])
data_valid <- dplyr::bind_rows(cv.data[k])
# Train model using lambda on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda,
model.family = binomial(link = "probit"),
verbose = verbose)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data_valid)
# Evaluate predictions based on loss function
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
unit = "individual", measure = "mse",
y = y, geo.unit = geo.unit)
})
perform_l
k_errors
lambda.set
lambda
lambda.set <- c(1, 2)
lambda_errors <- lapply(seq_along(lambda.set), function(lambda) {
# Print lambda
if (verbose == TRUE) {
L <- length(lambda.set)
cat(paste("Lasso: Running lambda ", lambda,
" out of ", L, " lambdas\n", sep = ""))
}
# Loop over each fold
k_errors <- lapply(seq_along(cv.data), function(k) {
# Split data in training and validation sets
data_train <- dplyr::bind_rows(cv.data[-k])
data_valid <- dplyr::bind_rows(cv.data[k])
# Train model using lambda on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda,
model.family = binomial(link = "probit"),
verbose = verbose)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data_valid)
# Evaluate predictions based on loss function
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
unit = "individual", measure = "mse",
y = y, geo.unit = geo.unit)
})
# Mean over all k folds
mean(unlist(k_errors))
})
lambda_errors
m_errors
lambda.set
lambda_errors <- lapply(seq_along(lambda.set), function(lambda) {
# Print lambda
if (verbose == TRUE) {
L <- length(lambda.set)
cat(paste("Lasso: Running lambda ", lambda,
" out of ", L, " lambdas\n", sep = ""))
}
# Loop over each fold
k_errors <- lapply(seq_along(cv.data), function(k) {
# Split data in training and validation sets
data_train <- dplyr::bind_rows(cv.data[-k])
data_valid <- dplyr::bind_rows(cv.data[k])
# Train model using lambda on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda,
model.family = binomial(link = "probit"),
verbose = verbose)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data_valid)
# Evaluate predictions based on loss function
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
unit = "individual", measure = "mse",
y = y, geo.unit = geo.unit)
})
# Mean over all k folds
mean(unlist(k_errors))
})
lambda_errors
# Choose best-performing model
min.lambda <- which.min(lambda_errors)
min.lambda
lambda.set
out <- lambda.set[min.lambda]
out
lambda.set <- data.frame(step_size = c(0.1, 0.3, 1, 10), cond_lambda = c(1, 10, NA, NA))
lambda.set
lambda.set <- data.frame(step_size = c(0.1, 0.3, 1, 10), lambda_lb = c(0, 1, 10, 100), lambda_ub = c(1, 10, NA, NA), n_iter = c(NA, NA, NA, 45))
lambda_set
lambda.set
max_iter
max_iter <- 10000
max_iter
seq_along(cv.data)
k
data_train <- dplyr::bind_rows(cv.data[-k])
data_valid <- dplyr::bind_rows(cv.data[k])
dim(data_train)
dim(data_valid)
L2_fe_form
L1_re
lambda
# Set initial lambda value to zero
lambda <- 0
lambda
verbose
model_init <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda,
model.family = binomial(link = "probit"),
verbose = verbose)
summary(model_init)
# Use trained model to make predictions for kth validation set
pred_init <- stats::predict(model_init, newdata = data_valid)
length(pred_init)
dim(pred_init)
class(pred_init)
perform_init <- loss_function(pred = pred_init, data.valid = data_valid,
unit = "individual", measure = "mse",
y = y, geo.unit = geo.unit)
dim(perform_init)
class(perform_init)
length(perform_init)
k_errors_init <- lapply(seq_along(cv.data), function(k) {
# Split data in training and validation sets
data_train <- dplyr::bind_rows(cv.data[-k])
data_valid <- dplyr::bind_rows(cv.data[k])
# Train model using initial lambda on kth training set
model_init <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda,
model.family = binomial(link = "probit"),
verbose = verbose)
# Use trained model to make predictions for kth validation set
pred_init <- stats::predict(model_init, newdata = data_valid)
# Evaluate predictions based on loss function
perform_init <- loss_function(pred = pred_init, data.valid = data_valid,
unit = "individual", measure = "mse",
y = y, geo.unit = geo.unit)
})
k_errors_init
lambda.set
lambda
lambda.set$step_size
max_iter
max_lambda
max_iter
max_iter
max_lambda <- 10000
max_iter <- 60
max.lambda <- 10000
max.iter <- 60
max.iter
lambda
# Initialize number of iterations
iter <- 0
iter
max.iter
iter
max.iter
verbose
iter
lambda
iter
max.iter
seq_along(cv.data)
k
k
data_train <- dplyr::bind_rows(cv.data[-k])
data_valid <- dplyr::bind_rows(cv.data[k])
lambda
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda,
model.family = binomial(link = "probit"),
verbose = verbose)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data_valid)
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
unit = "individual", measure = "mse",
y = y, geo.unit = geo.unit)
perform_l
k_errors <- lapply(seq_along(cv.data), function(k) {
# Split data in training and validation sets
data_train <- dplyr::bind_rows(cv.data[-k])
data_valid <- dplyr::bind_rows(cv.data[k])
# Train model using lambda on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda,
model.family = binomial(link = "probit"),
verbose = verbose)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data_valid)
# Evaluate predictions based on loss function
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
unit = "individual", measure = "mse",
y = y, geo.unit = geo.unit)
})
k_errors
k_errors
# Mean over all k folds
mean(unlist(k_errors))
Inf
100000 < Inf
lambda
lambda.set
seq_along(lambda.set$step_size)
i
i <- 1
lambda.set$lambda_lb[i]
lambda.set <- data.frame(step_size = c(0.1, 0.3, 1, 10), lambda_lb = c(0, 1, 10, 100), lambda_ub = c(1, 10, NA, NA), n_iter = c(NA, NA, NA, 45))
lambda.set
lambda.set <- data.frame(step_size = c(0.1, 0.3, 1, 10), lambda_lb = c(0, 1, 10, 100), lambda_ub = c(1, 10, NA, NA))
lambda.set
lambda.set %>% dplyr::mutate_if(is.na, 0)
lambda.set %>% dplyr::mutate_if(NA, 0)
lambda.set %>% dplyr::mutate_if(is.na(), 0)
lambda.set$lambda_ub %>% dplyr::mutate_if(is.na(), 0)
lambda.set$lambda_ub %>% dplyr::mutate_if(is.na, 0)
lambda.set[, 3]
lambda.set[is.na(lambda.set[, 3]), 3]
max.iter
lambda.set
max.iter
max.lambda
# Replace NAs in upper limit for lambda with maximum number of iterations
lambda.set[is.na(lambda.set[, 3]), 3] <- max.lambda
lambda.set
seq_along(lambda.set[, 1])
i
lambda
lambda.set[i, 2]
lambda.set[i, 3]
lambda.set[i, 1]
i
if (lambda >= lambda.set[i, 2] &
lambda < lambda.set[i, 3]) {
lambda <- lambda + lambda.set[i, 1]
}
lambda
if (lambda >= lambda.set[i, 2] &
lambda < lambda.set[i, 3]) {
lambda <- lambda + lambda.set[i, 1]
}
lambda
for (i in seq_along(lambda.set[, 1])) {
if (lambda >= lambda.set[i, 2] &
lambda < lambda.set[i, 3]) {
lambda <- lambda + lambda.set[i, 1]
break
}
}
lambda
for (i in seq_along(lambda.set[, 1])) {
if (lambda >= lambda.set[i, 2] &
lambda < lambda.set[i, 3]) {
lambda <- lambda + lambda.set[i, 1]
break
}
}
lambda
lambda.set
lamdba <- 4
lambda
rm()
rm(lamdba)
lambda
lambda <- 4
for (i in seq_along(lambda.set[, 1])) {
if (lambda >= lambda.set[i, 2] &
lambda < lambda.set[i, 3]) {
lambda <- lambda + lambda.set[i, 1]
break
}
}
lambda
lambda <- 22
for (i in seq_along(lambda.set[, 1])) {
if (lambda >= lambda.set[i, 2] &
lambda < lambda.set[i, 3]) {
lambda <- lambda + lambda.set[i, 1]
break
}
}
lambda
lambda <- 500
for (i in seq_along(lambda.set[, 1])) {
if (lambda >= lambda.set[i, 2] &
lambda < lambda.set[i, 3]) {
lambda <- lambda + lambda.set[i, 1]
break
}
}
lambda
lambda
for (i in seq_along(lambda.set[, 1])) {
if (lambda >= lambda.set[i, 2] &
lambda < lambda.set[i, 3]) {
lambda <- lambda + lambda.set[i, 1]
break
}
}
lambda
lambda.set
seq_along(c(2, 3, 4))
seq_len(c(2, 3, 4))
seq_along(c(2, 3, 4))
rev(seq_along(c(2, 3, 4)))
rev(seq_along(lambda.set[, 1]))
lambda
for (i in rev(seq_along(lambda.set[, 1]))) {
if (lambda >= lambda.set[i, 2] &
lambda < lambda.set[i, 3]) {
lambda <- lambda + lambda.set[i, 1]
break
}
}
lambda
lambda.set
