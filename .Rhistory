data_list <- data %>%
dplyr::group_split(.data[[L2.unit]])
# Sample one respondent per geographic unit
one_per_unit <- lapply(data_list, function(x) {
sample(x$index, size = 1, replace = FALSE)
}) %>%
unlist()
# Create EBMA hold-out fold
ebma_fold <- data %>%
dplyr::filter(index %in% one_per_unit)
data <- data %>%
dplyr::filter(!(index %in% one_per_unit))
remainder <- sample(data$index, size = ebma.size - length(one_per_unit),
replace = FALSE)
ebma_remainder <- data %>%
dplyr::filter(index %in% remainder)
ebma_fold <- ebma_fold %>%
dplyr::bind_rows(ebma_remainder)
# Extract EBMA hold-out fold from survey sample
cv_data <- data %>%
dplyr::filter(!(index %in% ebma_fold$index))
# Remove index variable
ebma_fold <- ebma_fold %>%
dplyr::select(-index)
cv_data <- cv_data %>%
dplyr::select(-index)
# Function output
out <- list(ebma_fold = ebma_fold,
cv_data = cv_data)
return(out)
}
# Function to create CV folds
cv_folding <- function(data, L2.unit, k.folds,
cv.sampling = c("respondents", "L2 units")) {
if (cv.sampling == "respondents") {
# Add row number to data frame
data <- data %>%
dplyr::mutate(index = row_number())
# Randomize indices of respondents
indices <- sample(data$index, size = length(data$index), replace = FALSE)
# Define number of units per fold
no_floor <- floor(length(indices) / k.folds)
no_remaining <- length(indices) - no_floor * k.folds
no_fold <- rep(no_floor, times = k.folds)
if (no_remaining > 0) {
no_fold[1:no_remaining] <- no_fold[1:no_remaining] + 1
}
# Split indices into folds
fold_indices <- split(indices, rep(1:k.folds, times = no_fold))
# Partition data according to indices
out <- lapply(fold_indices, function(x) {
data %>%
dplyr::filter(index %in% x) %>%
dplyr::select(-index)
})
} else {
# Extract indices of geographic units
indices <- data[[L2.unit]] %>%
unique()
# Randomize order of indices
indices <- sample(indices, size = length(indices), replace = FALSE)
# Define number of units per fold
no_floor <- floor(length(indices) / k.folds)
no_remaining <- length(indices) - no_floor * k.folds
no_fold <- rep(no_floor, times = k.folds)
if (no_remaining > 0) {
no_fold[1:no_remaining] <- no_fold[1:no_remaining] + 1
}
# Split indices into folds
fold_indices <- split(indices, rep(1:k.folds, times = no_fold))
# Partition data according to indices
out <- lapply(fold_indices, function(x) {
data %>%
dplyr::filter(.data[[L2.unit]] %in% x)
})
}
# Function output
return(out)
}
# Function to create model list for best subset classifier
model_list <- function(y, L1.x, L2.x, L2.unit, L2.reg = NULL) {
# Individual-level random effects
L1_re <- paste(paste("(1 | ", L1.x, ")", sep = ""), collapse = " + ")
# Geographic unit or Geographic unit-Geographic region random effects
if (is.null(L2.reg)) {
L2_re <- paste("(1 | ", L2.unit, ")", sep = "")
} else {
L2_re <- paste(paste("(1 | ", L2.reg, "/", L2.unit, ")", sep = ""),
collapse = " + ")
}
# Combine all random effects
all_re <- paste(c(L1_re, L2_re), collapse = " + ")
# Empty model
empty_model <- list(as.formula(paste(y, " ~ ", all_re, sep = "")))
# Remaining models
L2_list <- lapply(seq_along(L2.x), function(x) {combn(L2.x, x)})
L2_list <- lapply(L2_list, function(x) {
apply(x, 2, function(c) {
as.formula(paste(y, " ~ ", paste(c, collapse = " + "), " + ", all_re, sep = ""))
})
}) %>%
unlist()
# Combine models in list
out <- c(empty_model, L2_list)
# Function output
return(out)
}
# Function to create model list for PCA classifier
model_list_pca <- function(y, L1.x, L2.x, L2.unit, L2.reg = NULL) {
# Individual-level random effects
L1_re <- paste(paste("(1 | ", L1.x, ")", sep = ""), collapse = " + ")
# Geographic unit or Geographic unit-Geographic region random effects
if (is.null(L2.reg)) {
L2_re <- paste("(1 | ", L2.unit, ")", sep = "")
} else {
L2_re <- paste(paste("(1 | ", L2.reg, "/", L2.unit, ")", sep = ""),
collapse = " + ")
}
# Combine all random effects
all_re <- paste(c(L1_re, L2_re), collapse = " + ")
# Empty model
empty_model <- list(as.formula(paste(y, " ~ ", all_re, sep = "")))
# Remaining models
L2_list <- lapply(seq_along(L2.x), function(x) {L2.x[1:x]})
L2_list <- lapply(L2_list, function(x) {
as.formula(paste(y, " ~ ", paste(x, collapse = " + "), " + ", all_re, sep = ""))
})
# Combine models in list
out <- c(empty_model, L2_list)
# Function output
return(out)
}
# Loss function
loss_function <- function(pred, data.valid,
loss.unit = c("individual", "L2.units"),
loss.measure = c("mse", "mae"),
y, L2.unit) {
if (loss.unit == "individual" & loss.measure == "mse") {
out <- mean((data.valid[[y]] - pred)^2)
} else if (loss.unit == "individual" & loss.measure == "mae") {
out <- mean(abs(data.valid[[y]] - pred))
} else if (loss.unit == "L2.units" & loss.measure == "mse") {
data.valid <- data.valid %>%
dplyr::mutate(pred = pred)
out <- data.valid %>%
dplyr::group_by_at(L2.unit) %>%
dplyr::summarise_at(.vars = c(y, "pred"), mean) %>%
dplyr::mutate(sqe = (.data[[y]] - pred)^2) %>%
dplyr::pull(sqe)
out <- mean(out)
} else {
data.valid <- data.valid %>%
dplyr::mutate(pred = pred)
out <- data.valid %>%
dplyr::group_by_at(L2.unit) %>%
dplyr::summarise_at(.vars = c(y, "pred"), mean) %>%
dplyr::mutate(ae = abs(.data[[y]] - pred)) %>%
dplyr::pull(ae)
out <- mean(out)
}
# Function output
return(out)
}
y
L1.x
L2.x
L2.unit
L2.reg
L2.x.scale
bin.proportion
bin.size
uncertainty
best.subset
lasso
ebma.size
k.folds
custom.folds
custom.pc
cv.sampling
loss.unit
loss.measure
lasso.lambda.set
lasso.iterations.max
gb.L2.unit.include
gb.L2.reg.include
gb.interaction.set
gb.shrinkage.set
gb.tree.start
gb.tree.increase.set
gb.trees.max.set
gb.iterations.max
gb.n.minobsinnode
svm.kernel
svm.error.fun
svm.gamma.set
svm.cost.set
mrp.L2.x
ebma.n.draws
ebma.tol.values
seed
verbose
# Set seed
if (is.null(seed)) {
set.seed(546213978)
} else {
set.seed(seed)
}
# Error and warning checks
if (!all(L1.x %in% colnames(survey))) {
stop(paste("Individual-level variable(s) '",
L1.x[which(!(L1.x %in% colnames(survey)))],
"' is/are not in your survey data.", sep = ""))
}
if (!all(L1.x %in% colnames(census))) {
stop(paste("Individual-level variable(s) '",
L1.x[which(!(L1.x %in% colnames(census)))],
"' is/are not in your census data.", sep = ""))
}
if (!all(L2.x %in% colnames(survey))) {
stop(paste("Context-level variable(s) '",
L2.x[which(!(L2.x %in% colnames(survey)))],
"' is/are not in your survey data.", sep = ""))
}
if (!all(L2.x %in% colnames(census))) {
stop(paste("Context-level variable(s) '",
L2.x[which(!(L2.x %in% colnames(census)))],
"' is/are not in your census data.", sep = ""))
}
if (!(y %in% colnames(survey))) {
stop(paste("Outcome '", y,
"' is not in your survey data.", sep = ""))
}
if (!(L2.unit %in% colnames(survey))) {
stop(paste("The geographic unit '", L2.unit,
"' is not in your survey data.", sep = ""))
}
if (!(L2.unit %in% colnames(census))) {
stop(paste("The geographic unit '", L2.unit,
"' is not in your census data.", sep = ""))
}
if (!is.null(L2.reg)) {
if (!(L2.reg %in% colnames(survey))) {
stop(paste("The geographic region '", L2.reg,
"' is not in your survey data.", sep = ""))
}
if (!(L2.reg %in% colnames(census))) {
stop(paste("The geographic region '", L2.reg,
"' is not in your census data.", sep = ""))
}
if (any(unlist(lapply(dplyr::group_split(survey, .data[[L2.unit]]),
function(x) length(unique(x[[L2.reg]])))) > 1)) {
stop(paste("The geographic unit(s) '",
which(unlist(lapply(dplyr::group_split(survey, .data[[L2.unit]]),
function(x) length(unique(x[[L2.reg]])))) > 1),
"' is/are nested in multiple regions in your survey data."))
}
if (any(unlist(lapply(dplyr::group_split(census, .data[[L2.unit]]),
function(x) length(unique(x[[L2.reg]])))) > 1)) {
stop(paste("The geographic unit(s) '",
which(unlist(lapply(dplyr::group_split(census, .data[[L2.unit]]),
function(x) length(unique(x[[L2.reg]])))) > 1),
"' is/are nested in multiple regions in your census data."))
}
}
if (is.null(ebma.size)) {
ebma.size <- round(nrow(survey) / 3, digits = 0)
} else if (is.numeric(ebma.size) & ebma.size > 0 & ebma.size < 1) {
ebma.size <- round(nrow(survey) * ebma.size, digits = 0)
} else {
stop("ebma.size must be a rational number in the open unit interval.")
}
if (!((is.integer(k.folds) | all(as.integer(k.folds) == k.folds)) &
length(k.folds) == 1)) {
stop("k.folds must be an integer number.")
}
if (!cv.sampling %in% c("respondents", "L2 units")) {
stop("cv.sampling must take either the value 'respondents' or 'L2 units'.")
}
if (!(is.vector(lasso.lambda.set) | is.data.frame(lasso.lambda.set))) {
stop(paste("lasso.lambda.set must be either a numeric vector or a data.frame ",
"with two columns, one for step size increase and the other ",
"for the upper threshold of the interval of lambdas to which ",
"the step size applies", sep = ""))
}
if (!(is.null(lasso.iterations.max) | (is.numeric(lasso.iterations.max) &
length(lasso.iterations.max) == 1))) {
stop("lasso.iterations.max must be either a numeric scalar or NULL.")
}
if (!(is.integer(gb.interaction.set) |
all(as.integer(gb.interaction.set) == gb.interaction.set))) {
stop("gb.interaction.set must be an integer-valued vector.")
}
if (!is.numeric(gb.shrinkage.set)) {
stop("gb.shrinkage.set must be a numeric vector")
} else if (min(gb.shrinkage.set) < 0.001 | max(gb.shrinkage.set) > 0.1) {
warning("gb.shrinkage.set should have values lying between 0.001 and 0.1.")
}
if (!((is.integer(gb.tree.start) |
all(as.integer(gb.tree.start) == gb.tree.start)) &
length(gb.tree.start) == 1)) {
stop("gb.tree.start must be an integer-valued scalar.")
}
if (!(is.integer(gb.tree.increase.set) |
all(as.integer(gb.tree.increase.set) == gb.tree.increase.set))) {
stop("gb.tree.increase.set must be an integer-valued scalar or vector.")
} else if (length(gb.tree.increase.set) > 1 &
length(gb.tree.increase.set) != length(gb.shrinkage.set)) {
stop(paste("gb.tree.increase.set must be either a scalar or a vector of ",
"size `length(gb.shrinkage.set)`.", sep = ""))
}
if (!(is.integer(gb.trees.max.set) |
all(as.integer(gb.trees.max.set) == gb.trees.max.set))) {
stop("gb.trees.max.set must be an integer-valued scalar or vector.")
} else if (length(gb.trees.max.set) > 1 &
length(gb.trees.max.set) != length(gb.shrinkage.set)) {
stop(paste("gb.trees.max.set must be either a scalar or a vector of size ",
"`length(gb.shrinkage.set)`.", sep = ""))
}
if (!is.null(custom.folds)) {
if (!(is.double(survey %>% dplyr::select_at(.vars = custom.folds) %>% dplyr::pull()) |
is.integer(survey %>% dplyr::select_at(.vars = custom.folds) %>% dplyr::pull()))) {
stop("The variable specifying folds must of type integer or double.")
}
if (!all(survey %>% dplyr::select_at(.vars = custom.folds) %>%
dplyr::pull() %>% unique() %>% sort() == 1:(k.folds + 1))) {
stop("custom.folds must contain integers ranging from 1 to `k.folds` + 1.")
}
}
# If not provided in census data, calculate bin size and bin proportion for
# each ideal type in a geographic unit
if (is.null(bin.proportion)) {
if (is.null(bin.size)) {
census <- census %>%
dplyr::group_by(.dots = c(L1.x, L2.unit)) %>%
dplyr::summarise(n = dplyr::n())
} else {
census$n <- census[[bin.size]]
}
census <- census %>%
dplyr::group_by(.dots = L2.unit) %>%
dplyr::mutate(prop = n / sum(n))
} else {
census <- census %>%
dplyr::rename(prop = one_of(bin.proportion))
}
if (is.null(custom.pc)) {
# Compute principal components for survey data
pca_out <- stats::prcomp(survey[, L2.x],
retx = TRUE,
center = TRUE,
scale. = TRUE,
tol = NULL)
# Add PCs to survey data
survey <- survey %>%
dplyr::bind_cols(as.data.frame(pca_out$x))
# Add PCs to census data
pc_names <- colnames(pca_out$x)
census <- census %>%
dplyr::left_join(unique(survey %>% dplyr::select(all_of(L2.unit),
all_of(pc_names))),
by = L2.unit)
}
# Scale context-level variables in survey and census data
if (isTRUE(L2.x.scale)) {
survey[, L2.x] <- scale(survey[, L2.x], center = TRUE, scale = TRUE)
census[, L2.x] <- scale(census[, L2.x], center = TRUE, scale = TRUE)
}
# Convert survey and census data to tibble
survey <- tibble::as_tibble(x = survey)
census <- tibble::as_tibble(x = census)
if (is.null(custom.folds)) {
# EBMA hold-out fold
ebma_folding_out <- ebma_folding(data = survey,
L2.unit = L2.unit,
ebma.size = ebma.size)
ebma_fold <- ebma_folding_out$ebma_fold
cv_data <- ebma_folding_out$cv_data
# K folds for cross-validation
cv_folds <- cv_folding(data = cv_data,
L2.unit = L2.unit,
k.folds = k.folds,
cv.sampling = cv.sampling)
} else {
# EBMA hold-out fold
ebma_fold <- survey %>%
dplyr::filter_at(dplyr::vars(dplyr::one_of(custom.folds)),
dplyr::any_vars(. == k.folds + 1))
# K folds for cross-validation
cv_data <- survey %>%
dplyr::filter_at(dplyr::vars(dplyr::one_of(custom.folds)),
dplyr::any_vars(. != k.folds + 1))
cv_folds <- cv_data %>%
dplyr::group_split(.data[[custom.folds]])
}
source("./best_subset.R")
source("./best_subset_classifier.R")
source("./lasso.R")
source("./lasso_classifier.R")
source("./pca.R")
source("./gb.R")
source("./gb_classifier.R")
source("./svm_classifier.R")
source("./svm.R")
here::here()
here::here("R", "best_subset.R")
# classifiers
source(here::here("R", "best_subset.R"))
source(here::here("R", "best_subset_classifier.R"))
source(here::here("R", "lasso.R"))
source(here::here("R", "lasso_classifier.R"))
source(here::here("R", "pca.R"))
source(here::here("R", "gb.R"))
source(here::here("R", "gb_classifier.R"))
source(here::here("R", "svm_classifier.R"))
source(here::here("R", "svm.R"))
# Classifier 1: Best Subset
if (isTRUE(best.subset)) {
best_subset_out <- best_subset(y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
loss.unit = loss.unit,
loss.measure = loss.measure,
data = cv_folds,
verbose = verbose)
} else {
best_subset_out <- NULL
}
# Classifier 2: Lasso
if (isTRUE(lasso)) {
lasso_out <- lasso(y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
loss.unit = loss.unit,
loss.measure = loss.measure,
lambda.set = lasso.lambda.set,
iterations.max = lasso.iterations.max,
data = cv_folds,
verbose = verbose)
} else {
lasso_out <- NULL
}
# Classifier 3: PCA
if (isTRUE(pca)) {
pca_out <- pca(y = y,
L1.x = L1.x,
L2.x = pc_names,
L2.unit = L2.unit,
L2.reg = L2.reg,
loss.unit = loss.unit,
loss.measure = loss.measure,
data = cv_folds,
verbose = verbose)
} else {
pca_out <- NULL
}
# Classifier 4: GB
if (isTRUE(gb)) {
gb_out <- gb(y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
L2.unit.include = gb.L2.unit.include,
L2.reg.include = gb.L2.reg.include,
loss.unit = loss.unit,
loss.measure = loss.measure,
interaction.set = gb.interaction.set,
shrinkage.set = gb.shrinkage.set,
tree.start = gb.tree.start,
tree.increase.set = gb.tree.increase.set,
trees.max.set = gb.trees.max.set,
iterations.max = gb.iterations.max,
n.minobsinnode = gb.n.minobsinnode,
data = cv_folds,
verbose = verbose)
} else {
gb_out <- NULL
}
# Classifier 5: SVM
if (isTRUE(svm)) {
svm_out <- svm(y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
kernel = svm.kernel,
error.fun = svm.error.fun,
gamma.set = svm.gamma.set,
cost.set = svm.cost.set,
k.folds = k.folds,
data = cv_folds,
verbose = verbose)
} else {
svm_out <- NULL
}
y
L1.x
L2.x
L2.unit
L2.reg
best_subset_out
best.subset = best_subset_out
lasso_out
pca_out
gb_out
svm_out
lasso
best.subset
