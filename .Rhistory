}
!is.null(iterations.max) & iter_since_improv > iterations.max
lambda
lambda <= dplyr::last(lambda.set[, 2])
# Set lambda value
lambda <- round(lambda, digits = 10)
lambda
lambda
lambda.set[, 1][which(lambda < lambda.set[, 2])[1]]
lambda < dplyr::last(lambda.set[, 2])
lasso <- function(y, L1.x, L2.x, L2.unit, L2.reg,
loss.unit, loss.measure,
lambda.set, iterations.max = NULL,
data, verbose) {
# Error checks
if (!(is.vector(lambda.set) | is.data.frame(lambda.set))) {
stop(paste("lambda.set must be either a numeric vector or a data.frame ",
"with two columns, one for step size increase and the other ",
"for the upper threshold of the interval of lambdas to which ",
"the step size applies", sep = ""))
}
if (!(is.null(iterations.max) | (is.numeric(iterations.max) &
length(iterations.max) == 1))) {
stop("iterations.max must be either a numeric scalar or NULL.")
}
# Context-level fixed effects
L2_fe <- paste(L2.x, collapse = " + ")
L2_fe_form <- as.formula(paste(y, " ~ ", L2_fe, sep = ""))
# Individual-level random effects as named list
L1_re <- setNames(as.list(rep(c(~ 1), times = length(c(L1.x, L2.unit, L2.reg)))),
c(L1.x, L2.unit, L2.reg))
# Train and evaluate each model
if (is.vector(lambda.set)) {
# Add value of 0 to lambda.set if not already included
if (!0 %in% lambda.set) {
lambda.set <- c(0, lambda.set)
}
# Set lambda to 0
lambda <- lambda.set[1]
# Print lambda
if (isTRUE(verbose == TRUE)) {
L <- length(lambda.set)
cat(paste("Lasso: Running lambda w/ value ", lambda,
" (lambda ", 1, " out of max. ",
L, " lambdas)\n", sep = ""))
}
# Loop over each fold
k_errors <- lapply(seq_along(data), function(k) {
# Split data in training and validation sets
data_train <- dplyr::bind_rows(data[-k])
data_valid <- dplyr::bind_rows(data[k])
# Convert individual-level, geographic unit, and geographic region
# covariates to factor variables in training and validation sets
data_train <- data_train %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
data_valid <- data_valid %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
# Train model using lambda on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda,
model.family = binomial(link = "probit"),
verbose = verbose)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data_valid)
# Evaluate predictions based on loss function
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
loss.unit = loss.unit,
loss.measure = loss.measure,
y = y, L2.unit = L2.unit)
})
# Mean over all k folds
best_error <- mean(unlist(k_errors))
# Initialize lambda associated with currently best error
out <- lambda
# Initialize counter for iterations since last performance improvement
iter_since_improv <- 0
# Loop over lambda values in lambda.set
for (l in 2:length(lambda.set)) {
# Set lambda value
lambda <- lambda.set[l]
# Print lambda
if (isTRUE(verbose == TRUE)) {
L <- length(lambda.set)
cat(paste("Lasso: Running lambda w/ value ", lambda,
" (lambda ", l, " out of max. ",
L, " lambdas)\n", sep = ""))
}
# Loop over each fold
k_errors <- lapply(seq_along(data), function(k) {
# Split data in training and validation sets
data_train <- dplyr::bind_rows(data[-k])
data_valid <- dplyr::bind_rows(data[k])
# Convert individual-level, geographic unit, and geographic region
# covariates to factor variables in training and validation sets
data_train <- data_train %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
data_valid <- data_valid %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
# Train model using lambda on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda,
model.family = binomial(link = "probit"),
verbose = verbose)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data_valid)
# Evaluate predictions based on loss function
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
loss.unit = loss.unit,
loss.measure = loss.measure,
y = y, L2.unit = L2.unit)
})
# Mean over all k folds
current_error <- mean(unlist(k_errors))
# Check if current lambda outperforms lambda that was best so far
if (current_error < best_error) {
best_error <- current_error
out <- lambda
iter_since_improv <- 0
} else {
iter_since_improv <- iter_since_improv + 1
}
# Break loop if maximum number of iterations without performance
# improvement is reached
if (!is.null(iterations.max) & iter_since_improv > iterations.max) {
break
}
}
# Function output
return(out)
} else {
# Set lambda to 0
lambda <- 0
# Initialize counter for lambda
lambda_no <- 1
# Print lambda
if (isTRUE(verbose == TRUE)) {
cat(paste("Lasso: Running lambda w/ value ", lambda,
" (lambda no. ", lambda_no, ")\n", sep = ""))
}
# Loop over each fold
k_errors <- lapply(seq_along(data), function(k) {
# Split data in training and validation sets
data_train <- dplyr::bind_rows(data[-k])
data_valid <- dplyr::bind_rows(data[k])
# Convert individual-level, geographic unit, and geographic region
# covariates to factor variables in training and validation sets
data_train <- data_train %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
data_valid <- data_valid %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
# Train model using lambda on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda,
model.family = binomial(link = "probit"),
verbose = verbose)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data_valid)
# Evaluate predictions based on loss function
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
loss.unit = loss.unit,
loss.measure = loss.measure,
y = y, L2.unit = L2.unit)
})
# Mean over all k folds
best_error <- mean(unlist(k_errors))
# Initialize lambda associated with currently best error
out <- lambda
# Initialize counter for iterations since last performance improvement
iter_since_improv <- 0
# Loop over lambda values in lambda.set
while(lambda < dplyr::last(lambda.set[, 2])) {
# Set lambda value
lambda <- round(lambda, digits = 10)
lambda <- lambda + lambda.set[, 1][which(lambda < lambda.set[, 2])[1]]
# Update counter for lambda
lambda_no <- lambda_no + 1
# Print lambda
if (isTRUE(verbose == TRUE)) {
cat(paste("Lasso: Running lambda w/ value ", lambda,
" (lambda no.: ", lambda_no, "; iterations w/o improvement: ",
iter_since_improv, ")\n", sep = ""))
}
# Loop over each fold
k_errors <- lapply(seq_along(data), function(k) {
# Split data in training and validation sets
data_train <- dplyr::bind_rows(data[-k])
data_valid <- dplyr::bind_rows(data[k])
# Convert individual-level, geographic unit, and geographic region
# covariates to factor variables in training and validation sets
data_train <- data_train %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
data_valid <- data_valid %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
# Train model using lambda on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda,
model.family = binomial(link = "probit"),
verbose = verbose)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data_valid)
# Evaluate predictions based on loss function
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
loss.unit = loss.unit,
loss.measure = loss.measure,
y = y, L2.unit = L2.unit)
})
# Mean over all k folds
current_error <- mean(unlist(k_errors))
# Check if current lambda outperforms lambda that was best so far
if (current_error < best_error) {
best_error <- current_error
out <- lambda
iter_since_improv <- 0
} else {
iter_since_improv <- iter_since_improv + 1
}
# Break loop if maximum number of iterations without performance
# improvement is reached
if (!is.null(iterations.max) & iter_since_improv > iterations.max) {
break
}
}
# Function output
return(out)
}
}
lasso_out <- lasso(y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
loss.unit = loss.unit,
loss.measure = loss.measure,
data = cv_folds,
lambda.set = lambda.set,
iterations.max = iterations.max,
verbose = verbose)
lasso <- function(y, L1.x, L2.x, L2.unit, L2.reg,
loss.unit, loss.measure,
lambda.set, iterations.max = NULL,
data, verbose) {
# Error checks
if (!(is.vector(lambda.set) | is.data.frame(lambda.set))) {
stop(paste("lambda.set must be either a numeric vector or a data.frame ",
"with two columns, one for step size increase and the other ",
"for the upper threshold of the interval of lambdas to which ",
"the step size applies", sep = ""))
}
if (!(is.null(iterations.max) | (is.numeric(iterations.max) &
length(iterations.max) == 1))) {
stop("iterations.max must be either a numeric scalar or NULL.")
}
# Context-level fixed effects
L2_fe <- paste(L2.x, collapse = " + ")
L2_fe_form <- as.formula(paste(y, " ~ ", L2_fe, sep = ""))
# Individual-level random effects as named list
L1_re <- setNames(as.list(rep(c(~ 1), times = length(c(L1.x, L2.unit, L2.reg)))),
c(L1.x, L2.unit, L2.reg))
# Train and evaluate each model
if (is.vector(lambda.set)) {
# Add value of 0 to lambda.set if not already included
if (!0 %in% lambda.set) {
lambda.set <- c(0, lambda.set)
}
# Set lambda to 0
lambda <- lambda.set[1]
# Print lambda
if (isTRUE(verbose == TRUE)) {
L <- length(lambda.set)
cat(paste("Lasso: Running lambda w/ value ", lambda,
" (lambda ", 1, " out of max. ",
L, " lambdas)\n", sep = ""))
}
# Loop over each fold
k_errors <- lapply(seq_along(data), function(k) {
# Split data in training and validation sets
data_train <- dplyr::bind_rows(data[-k])
data_valid <- dplyr::bind_rows(data[k])
# Convert individual-level, geographic unit, and geographic region
# covariates to factor variables in training and validation sets
data_train <- data_train %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
data_valid <- data_valid %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
# Train model using lambda on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda,
model.family = binomial(link = "probit"),
verbose = verbose)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data_valid)
# Evaluate predictions based on loss function
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
loss.unit = loss.unit,
loss.measure = loss.measure,
y = y, L2.unit = L2.unit)
})
# Mean over all k folds
best_error <- mean(unlist(k_errors))
# Initialize lambda associated with currently best error
out <- lambda
# Initialize counter for iterations since last performance improvement
iter_since_improv <- 0
# Loop over lambda values in lambda.set
for (l in 2:length(lambda.set)) {
# Set lambda value
lambda <- lambda.set[l]
# Print lambda
if (isTRUE(verbose == TRUE)) {
L <- length(lambda.set)
cat(paste("Lasso: Running lambda w/ value ", lambda,
" (lambda ", l, " out of max. ",
L, " lambdas)\n", sep = ""))
}
# Loop over each fold
k_errors <- lapply(seq_along(data), function(k) {
# Split data in training and validation sets
data_train <- dplyr::bind_rows(data[-k])
data_valid <- dplyr::bind_rows(data[k])
# Convert individual-level, geographic unit, and geographic region
# covariates to factor variables in training and validation sets
data_train <- data_train %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
data_valid <- data_valid %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
# Train model using lambda on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda,
model.family = binomial(link = "probit"),
verbose = verbose)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data_valid)
# Evaluate predictions based on loss function
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
loss.unit = loss.unit,
loss.measure = loss.measure,
y = y, L2.unit = L2.unit)
})
# Mean over all k folds
current_error <- mean(unlist(k_errors))
# Check if current lambda outperforms lambda that was best so far
if (current_error < best_error) {
best_error <- current_error
out <- lambda
iter_since_improv <- 0
} else {
iter_since_improv <- iter_since_improv + 1
}
# Break loop if maximum number of iterations without performance
# improvement is reached
if (!is.null(iterations.max) & iter_since_improv > iterations.max) {
break
}
}
# Function output
return(out)
} else {
# Set lambda to 0
lambda <- 0
# Initialize counter for lambda
lambda_no <- 1
# Print lambda
if (isTRUE(verbose == TRUE)) {
cat(paste("Lasso: Running lambda w/ value ", lambda,
" (lambda no. ", lambda_no, " -- no improvement evaluation)\n", sep = ""))
}
# Loop over each fold
k_errors <- lapply(seq_along(data), function(k) {
# Split data in training and validation sets
data_train <- dplyr::bind_rows(data[-k])
data_valid <- dplyr::bind_rows(data[k])
# Convert individual-level, geographic unit, and geographic region
# covariates to factor variables in training and validation sets
data_train <- data_train %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
data_valid <- data_valid %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
# Train model using lambda on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda,
model.family = binomial(link = "probit"),
verbose = verbose)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data_valid)
# Evaluate predictions based on loss function
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
loss.unit = loss.unit,
loss.measure = loss.measure,
y = y, L2.unit = L2.unit)
})
# Mean over all k folds
best_error <- mean(unlist(k_errors))
# Initialize lambda associated with currently best error
out <- lambda
# Initialize counter for iterations since last performance improvement
iter_since_improv <- 0
# Loop over lambda values in lambda.set
while(lambda < dplyr::last(lambda.set[, 2])) {
# Set lambda value
lambda <- round(lambda, digits = 10)
lambda <- lambda + lambda.set[, 1][which(lambda < lambda.set[, 2])[1]]
# Update counter for lambda
lambda_no <- lambda_no + 1
# Print lambda
if (isTRUE(verbose == TRUE)) {
cat(paste("Lasso: Running lambda w/ value ", lambda,
" (lambda no.: ", lambda_no, " -- iterations w/o improvement: ",
iter_since_improv, ")\n", sep = ""))
}
# Loop over each fold
k_errors <- lapply(seq_along(data), function(k) {
# Split data in training and validation sets
data_train <- dplyr::bind_rows(data[-k])
data_valid <- dplyr::bind_rows(data[k])
# Convert individual-level, geographic unit, and geographic region
# covariates to factor variables in training and validation sets
data_train <- data_train %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
data_valid <- data_valid %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
# Train model using lambda on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda,
model.family = binomial(link = "probit"),
verbose = verbose)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data_valid)
# Evaluate predictions based on loss function
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
loss.unit = loss.unit,
loss.measure = loss.measure,
y = y, L2.unit = L2.unit)
})
# Mean over all k folds
current_error <- mean(unlist(k_errors))
# Check if current lambda outperforms lambda that was best so far
if (current_error < best_error) {
best_error <- current_error
out <- lambda
iter_since_improv <- 0
} else {
iter_since_improv <- iter_since_improv + 1
}
# Break loop if maximum number of iterations without performance
# improvement is reached
if (!is.null(iterations.max) & iter_since_improv > iterations.max) {
break
}
}
# Function output
return(out)
}
}
lasso_out <- lasso(y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
loss.unit = loss.unit,
loss.measure = loss.measure,
data = cv_folds,
lambda.set = lambda.set,
iterations.max = iterations.max,
verbose = verbose)
?prcomp
data.frame(a = c(1, 2), b = c(3, 4))
list(data.frame(a = c(1, 2), b = c(3, 4)), data.frame(a = c(1, 2), b = c(5, 6)))
dplyr::bind_rows(list(data.frame(a = c(1, 2), b = c(3, 4)), data.frame(a = c(1, 2), b = c(5, 6))))
y = y
L1.x = L1.x
L2.x = L2.x
L2.unit = L2.unit
L2.reg = L2.reg
loss.unit = loss.unit
loss.measure = loss.measure
data = cv_folds
verbose = verbose
L2.x
class(data)
length(data)
dim(data[[1]])
dim(data[[2]])
dim(data[[3]])
dim(data[[4]])
dim(data[[5]])
311 + 144 + 221 + 137 + 187
# Compute principal components
L2_data <- dplyr::bind_rows(data)
dim(L2_data)
head(L2_data)
L2_data <- dplyr::bind_rows(data) %>%
dplyr::select_at(L2.x)
dim(L2_data)
head(L2_data)
colMeans(L2_data)
apply(L2_data, 2, sd)
