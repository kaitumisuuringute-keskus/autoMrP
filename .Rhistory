census <- census %>%
dplyr::left_join(unique(survey %>% dplyr::select(all_of(L2.unit),
all_of(pc_names))),
by = L2.unit)
} else {
pc_names <- pcs
}
# Scale context-level variables in survey and census data
if (isTRUE(L2.x.scale)) {
survey[, L2.x] <- scale(survey[, L2.x], center = TRUE, scale = TRUE)
census[, L2.x] <- scale(census[, L2.x], center = TRUE, scale = TRUE)
}
# Convert survey and census data to tibble
survey <- tibble::as_tibble(x = survey)
census <- tibble::as_tibble(x = census)
if (is.null(folds)) {
# EBMA hold-out fold
ebma.size <- round(nrow(survey) * ebma.size, digits = 0)
ebma_folding_out <- ebma_folding(data = survey,
L2.unit = L2.unit,
ebma.size = ebma.size)
ebma_fold <- ebma_folding_out$ebma_fold
cv_data <- ebma_folding_out$cv_data
# K folds for cross-validation
cv_folds <- cv_folding(data = cv_data,
L2.unit = L2.unit,
k.folds = k.folds,
cv.sampling = cv.sampling)
} else {
# If svm is TRUE, print warning that SVM classifier does not rely on
# user-specified folds
if (isTRUE(svm)) {
warning(paste("Currently the SVM classifier does not use the user-supplied",
" folds. This will be added in the next version of the",
" package.", sep = ""))
}
# EBMA hold-out fold
ebma_fold <- survey %>%
dplyr::filter_at(dplyr::vars(dplyr::one_of(folds)),
dplyr::any_vars(. == k.folds + 1))
# K folds for cross-validation
cv_data <- survey %>%
dplyr::filter_at(dplyr::vars(dplyr::one_of(folds)),
dplyr::any_vars(. != k.folds + 1))
cv_folds <- cv_data %>%
dplyr::group_split(.data[[folds]])
}
# Classifier 1: Best Subset
if (isTRUE(best.subset)) {
# Determine context-level covariates
if (is.null(best.subset.L2.x)) {
best.subset.L2.x <- L2.x
}
# Run classifier
best_subset_out <- run_best_subset(y = y,
L1.x = L1.x,
L2.x = best.subset.L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
loss.unit = loss.unit,
loss.fun = loss.fun,
data = cv_folds,
verbose = verbose)
} else {
best_subset_out <- NULL
}
# Classifier 2: Lasso
if (isTRUE(lasso)) {
# Determine context-level covariates
if (is.null(lasso.L2.x)) {
lasso.L2.x <- L2.x
}
# Run classifier
lasso_out <- run_lasso(y = y,
L1.x = L1.x,
L2.x = lasso.L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
loss.unit = loss.unit,
loss.fun = loss.fun,
lambda = lasso.lambda,
n.iter = lasso.n.iter,
data = cv_folds,
verbose = verbose)
} else {
lasso_out <- NULL
}
# Classifier 3: PCA
if (isTRUE(pca)) {
pca_out <- run_pca(
y = y,
L1.x = L1.x,
L2.x = pc_names,
L2.unit = L2.unit,
L2.reg = L2.reg,
loss.unit = loss.unit,
loss.fun = loss.fun,
data = cv_folds,
verbose = verbose)
} else {
pca_out <- NULL
}
# Classifier 4: GB
if (isTRUE(gb)) {
# Determine context-level covariates
if (is.null(gb.L2.x)) {
gb.L2.x <- L2.x
}
# Evaluate inclusion of L2.unit in GB
if (isTRUE(gb.L2.unit)) {
gb.L2.unit <- L2.unit
} else {
gb.L2.unit <- NULL
}
# Evaluate inclusion of L2.reg in GB
if (isTRUE(gb.L2.reg)) {
gb.L2.reg <- L2.reg
} else {
gb.L2.reg <- NULL
}
# Run classifier
gb_out <- run_gb(y = y,
L1.x = L1.x,
L2.x = gb.L2.x,
L2.unit = gb.L2.unit,
L2.reg = gb.L2.reg,
loss.unit = loss.unit,
loss.fun = loss.fun,
interaction.depth = gb.interaction.depth,
shrinkage = gb.shrinkage,
n.trees.init = gb.n.trees.init,
n.trees.increase = gb.n.trees.increase,
n.trees.max = gb.n.trees.max,
n.iter = gb.n.iter,
n.minobsinnode = gb.n.minobsinnode,
data = cv_folds,
verbose = verbose)
} else {
gb_out <- NULL
}
# Classifier 5: SVM
if (isTRUE(svm)) {
# Determine context-level covariates
if (is.null(svm.L2.x)) {
svm.L2.x <- L2.x
}
# Run classifier
svm_out <- run_svm(y = y,
L1.x = L1.x,
L2.x = svm.L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
kernel = svm.kernel,
loss.fun = svm.loss.fun,
gamma = svm.gamma,
cost = svm.cost,
data = cv_folds,
verbose = verbose)
} else {
svm_out <- NULL
}
ps_out <- post_stratification(
y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
best.subset.opt = best_subset_out,
lasso.opt = lasso_out,
pca.opt = pca_out,
gb.opt = gb_out,
svm.opt = svm_out,
mrp.include = mrp,
n.minobsinnode = gb.n.minobsinnode,
L2.unit.include = gb.L2.unit,
L2.reg.include = gb.L2.reg,
kernel = svm.kernel,
mrp.L2.x = mrp.L2.x,
data = cv_data,
ebma.fold = ebma_fold,
census = census,
verbose = verbose
)
verbose
verbose=FALSE
ps_out <- post_stratification(
y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
best.subset.opt = best_subset_out,
lasso.opt = lasso_out,
pca.opt = pca_out,
gb.opt = gb_out,
svm.opt = svm_out,
mrp.include = mrp,
n.minobsinnode = gb.n.minobsinnode,
L2.unit.include = gb.L2.unit,
L2.reg.include = gb.L2.reg,
kernel = svm.kernel,
mrp.L2.x = mrp.L2.x,
data = cv_data,
ebma.fold = ebma_fold,
census = census,
verbose = verbose
)
verbose=TRUE
ps_out <- post_stratification(
y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
best.subset.opt = best_subset_out,
lasso.opt = lasso_out,
pca.opt = pca_out,
gb.opt = gb_out,
svm.opt = svm_out,
mrp.include = mrp,
n.minobsinnode = gb.n.minobsinnode,
L2.unit.include = gb.L2.unit,
L2.reg.include = gb.L2.reg,
kernel = svm.kernel,
mrp.L2.x = mrp.L2.x,
data = cv_data,
ebma.fold = ebma_fold,
census = census,
verbose = verbose
)
ps_out
ebma_out <- ebma(
ebma.fold = ebma_fold,
y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
post.strat = ps_out,
n.draws = ebma.n.draws,
tol = ebma.tol,
best.subset.opt = best_subset_out,
pca.opt = pca_out,
lasso.opt = lasso_out,
gb.opt = gb_out,
svm.opt = svm_out,
verbose = verbose
)
ebma.fold = ebma_fold
y = y
L1.x = L1.x
L2.x = L2.x
L2.unit = L2.unit
L2.reg = L2.reg
post.strat = ps_out
n.draws = ebma.n.draws
tol = ebma.tol
best.subset.opt = best_subset_out
pca.opt = pca_out
lasso.opt = lasso_out
gb.opt = gb_out
svm.opt = svm_out
verbose = verbose
sum(unlist(lapply(X = post.strat$models, FUN = function(x) !is.null(x)))) > 1
# models
model_bs <- post.strat$models$best_subset
model_pca <- post.strat$models$pca
model_lasso <- post.strat$models$lasso
model_gb <- post.strat$models$gb
model_svm <- post.strat$models$svm
model_mrp <- post.strat$models$mrp
model_bs
model_pca
model_lasso
model_gb
if (sum(unlist(lapply(X = post.strat$models, FUN = function(x) !is.null(x)))) > 1){
print("hallo"))
if (sum(unlist(lapply(X = post.strat$models, FUN = function(x) !is.null(x)))) > 1){
print("hallo")
}
# models
model_bs <- post.strat$models$best_subset
model_pca <- post.strat$models$pca
model_lasso <- post.strat$models$lasso
model_gb <- post.strat$models$gb
model_svm <- post.strat$models$svm
model_mrp <- post.strat$models$mrp
# training predictions
train_preds <- post.strat$predictions$Level1 %>%
dplyr::select(-one_of(y))
# training set outcomes
train_y <- dplyr::select(.data = post.strat$predictions$Level1, one_of(y))
# container to store the MSE on the test folds
mse_collector <- matrix(NA, n.draws, length(tol))
# container for model weights for each draw and tolerance value
weights_box <- array(NA, dim = c(n.draws, ncol(train_preds), length(tol)))
# counter for verbose screen output
counter <- 0
length(tol)
idx.tol=1
n.draws
idx.Ndraws
idx.Ndraws=2
# increase counter
counter <- counter +1
# sample with replacement equal obs/state
test <- ebma.fold %>%
dplyr::group_by(state) %>%
dplyr::mutate(n_L2 = dplyr::n_groups(ebma.fold)) %>%
dplyr::sample_n(as.integer(nrow(ebma.fold) /  n_L2), replace = TRUE) %>%
dplyr::ungroup() %>%
dplyr::mutate_at(.vars = c( L1.x, L2.unit, L2.reg), .funs = as.factor)
# predict outcomes in test set
test_preds <- dplyr::tibble(
best_subset = if(!is.null(model_bs)){
predict(object = model_bs, newdata = test, type = "response", allow.new.levels = TRUE)
} else{NA},
pca = if(!is.null(model_pca)){
predict(object = model_pca, newdata = test, type = "response", allow.new.levels = TRUE)
} else{NA},
lasso = if(!is.null(model_lasso)){
as.numeric(predict(object = model_lasso, newdata = data.frame(test), type = "response"))
} else{NA},
gb = if(!is.null(model_gb)){
gbm::predict.gbm(object = model_gb, newdata = test, n.trees = model_gb$n.trees, type = "response")
} else{NA},
svm = if(!is.null(model_svm)){
as.numeric(attr(predict(object = model_svm, newdata = test, probability = TRUE),"probabilities")[,"1"])
} else{NA},
mrp = if(!is.null(model_mrp)){
predict(object = model_mrp, newdata = test, type = "response", allow.new.levels = TRUE)
} else{NA}
)
test
# remove NA's
test_preds <- test_preds[,apply(X = test_preds, MARGIN = 2, FUN = function(x){
all(!is.na(x))})]
# outcome on the test
test_y <- dplyr::select(.data = test, one_of(y))
# EBMA
forecast.data <- EBMAforecast::makeForecastData(
.predCalibration = data.frame(train_preds),
.outcomeCalibration = as.numeric(unlist(train_y)),
.predTest = data.frame(test_preds),
.outcomeTest = as.numeric(unlist(test_y)))
data.frame(train_preds)
as.numeric(unlist(train_y))
data.frame(test_preds)
as.numeric(unlist(test_y)))
as.numeric(unlist(test_y))
# EBMA
forecast.data <- EBMAforecast::makeForecastData(
.predCalibration = data.frame(train_preds),
.outcomeCalibration = as.numeric(unlist(train_y)),
.predTest = data.frame(test_preds),
.outcomeTest = as.numeric(unlist(test_y)))
# EBMA
forecast.data <- EBMAforecast::makeForecastData(
.predCalibration = as.matrix(train_preds),
.outcomeCalibration = as.numeric(unlist(train_y)),
.predTest = as.matrix(test_preds),
.outcomeTest = as.numeric(unlist(test_y)))
# EBMA
forecast.data <- suppressWarnings(
EBMAforecast::makeForecastData(
.predCalibration = data.frame(train_preds),
.outcomeCalibration = as.numeric(unlist(train_y)),
.predTest = data.frame(test_preds),
.outcomeTest = as.numeric(unlist(test_y)))
)
forecast.out <- EBMAforecast::calibrateEnsemble(
forecast.data,
model = "normal",
useModelParams = FALSE,
tol = tol[idx.tol])
makeForeCastData
makeForeCastData()
EBMAforecast::makeForeCastData()
EBMAforecast::makeForecastData
showMethods("makeForecastData")
rm(list=ls())
library(dplyr)
# load data
load("C:/Users/Philipp/Documents/github/autoMrP/data/survey_paper_i11.RData")
#survey <- dplyr::select(survey, -contains("PC"), -"fold", -"id")
survey
load("C:/Users/Philipp/Documents/github/autoMrP/data/census_paper_i11.RData")
#census <- dplyr::select(census, -contains("PC"))
setwd("C:/Users/Philipp/Documents/github/autoMrP/")
source("./R/best_subset_classifier.R")
source("./R/ebma.R")
source("./R/gb_classifier.R")
source("./R/lasso_classifier.R")
source("./R/post_stratification.R")
source("./R/run_best_subset.R")
source("./R/run_gb.R")
source("./R/run_lasso.R")
source("./R/run_pca.R")
source("./R/run_svm.R")
source("./R/svm_classifier.R")
source("./R/utils.R")
# arguments
y = "YES"
L1.x = c("L1x1", "L1x2", "L1x3")
L2.x = c("L2.x1", "L2.x2")
L2.unit = "state"
L2.reg = "region"
L2.x.scale = TRUE
pcs = NULL
folds = NULL
bin.proportion = "proportion"
bin.size = NULL
survey = survey
census = census
ebma.size = 1/3
k.folds = 5
cv.sampling = "L2 units"
loss.unit = "individuals"
loss.fun = "MSE"
# switch for classifiers
best.subset = FALSE
lasso = FALSE
pca = FALSE
gb = TRUE
svm = FALSE
# the standard MRP model
mrp = TRUE
forward.select = FALSE
best.subset.L2.x = NULL
lasso.L2.x = NULL
pca.L2.x = NULL
gb.L2.x = NULL
svm.L2.x = NULL
# Standard MrP model L2 variables
mrp.L2.x = NULL
gb.L2.unit = FALSE
gb.L2.reg = FALSE
# tuning params lasso
lasso.lambda = list(c(0.1, 0.3), c(1, 10))
lasso.n.iter = 25
# tuning params boosting
gb.interaction.depth = c(1, 2)
gb.shrinkage = c(0.04, 0.01)
gb.n.trees.init = 50
gb.n.trees.increase = 50
gb.n.trees.max = 1000
gb.n.iter = 25
gb.n.minobsinnode = 5
svm.kernel = "radial"
svm.loss.fun = NULL
svm.gamma = c(0.3, 0.5)
svm.cost = c(1, 10)
ebma.n.draws = 2
ebma.tol = 0.01
uncertainty = FALSE
seed = NULL
verbose = TRUE
# Check seed argument and set seed
if (is.null(seed)) {
set.seed(546213978)
} else {
if (isTRUE(dplyr::near(seed, as.integer(seed)))) {
set.seed(seed)
} else {
stop("Seed must be either NULL or an integer-valued scalar.")
}
}
# Call to function doing the error checks
error_checks(y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
L2.x.scale = L2.x.scale,
pcs = pcs,
folds = folds,
bin.proportion = bin.proportion,
bin.size = bin.size,
survey = survey,
census = census,
ebma.size = ebma.size,
k.folds = k.folds,
cv.sampling = cv.sampling,
loss.unit = loss.unit,
loss.fun = loss.fun,
best.subset = best.subset,
lasso = lasso,
pca = pca,
gb = gb,
svm = svm,
mrp = mrp,
forward.select = forward.select,
best.subset.L2.x = best.subset.L2.x,
lasso.L2.x = lasso.L2.x,
gb.L2.x = gb.L2.x,
svm.L2.x = svm.L2.x,
mrp.L2.x = mrp.L2.x,
gb.L2.unit = gb.L2.unit,
gb.L2.reg = gb.L2.reg,
lasso.lambda = lasso.lambda,
lasso.n.iter = lasso.n.iter)
is.logical(pca)
isTRUE(pca)
is.null(pcs)
pcs
pcs
pcs
is.null(pcs)
library(screenreg)
library(texreg)
install.packages("texreg")
library(texreg)
