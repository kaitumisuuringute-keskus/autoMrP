gb = FALSE
svm = FALSE
# the standard MRP model
mrp = TRUE
forward.select = FALSE
best.subset.L2.x = NULL
lasso.L2.x = NULL
pca.L2.x = NULL
gb.L2.x = NULL
svm.L2.x = NULL
# Standard MrP model L2 variables
mrp.L2.x = NULL
gb.L2.unit = FALSE
gb.L2.reg = FALSE
# tuning params lasso
lasso.lambda = 1 / exp(- seq(from = -1, to = 4.5, length = 100))
lasso.n.iter = 70
# tuning params boosting
gb.interaction.depth = c(1, 2, 3)
gb.shrinkage = c(0.04, 0.01, 0.008, 0.005, 0.001)
gb.n.trees.init = 50
gb.n.trees.increase = 50
gb.n.trees.max = 1000
gb.n.iter = 70
gb.n.minobsinnode = 5
svm.kernel = "radial"
svm.loss.fun = NULL
svm.gamma = c(0.3, 0.5, 0.55, 0.6, 0.65, 0.7, 0.8, 0.9, 1, 2, 3, 4)
svm.cost = c(1, 10)
ebma.n.draws = 1
ebma.tol = 0.01
uncertainty = TRUE
seed = NULL
verbose = TRUE
cores = 4
# Binding for global variables
`%>%` <- dplyr::`%>%`
idx_boot <- NULL
# Register cores
cl <- multicore(cores = cores, type = "open", cl = NULL)
# Bootstrap iterations
boot_out <- foreach::foreach(idx_boot = 1:boot.iter, .packages = "autoMrP") %dopar% {
# Bootstrapped survey sample
boot_sample <- dplyr::sample_n(tbl = survey, size = nrow(survey), replace = TRUE)
# Estimate on 1 sample in autoMrP
boot_mrp <- auto_MrP(
survey = boot_sample,
ebma.n.draws = 1,
uncertainty = FALSE,
verbose = FALSE,
cores = 1,
y = y,
L1.x = L1.x,
L2.x = L2.x,
mrp.L2.x = mrp.L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
L2.x.scale = L2.x.scale,
pcs = pcs,
folds = folds,
bin.proportion = bin.proportion,
bin.size = bin.size,
census = census,
ebma.size = ebma.size,
k.folds = k.folds,
cv.sampling = cv.sampling,
loss.unit = loss.unit,
loss.fun = loss.fun,
best.subset = best.subset,
lasso = lasso,
pca = pca,
gb = gb,
svm = svm,
mrp = mrp,
forward.select = forward.select,
best.subset.L2.x = best.subset.L2.x,
lasso.L2.x = lasso.L2.x,
pca.L2.x = pca.L2.x,
gb.L2.x = gb.L2.x,
svm.L2.x = svm.L2.x,
gb.L2.unit = gb.L2.unit,
gb.L2.reg = gb.L2.reg,
lasso.lambda = lasso.lambda,
lasso.n.iter = lasso.n.iter,
gb.interaction.depth = gb.interaction.depth,
gb.shrinkage = gb.shrinkage,
gb.n.trees.init = gb.n.trees.init,
gb.n.trees.increase = gb.n.trees.increase,
gb.n.trees.max = gb.n.trees.max,
gb.n.iter = gb.n.iter,
gb.n.minobsinnode = gb.n.minobsinnode,
svm.kernel = svm.kernel,
svm.gamma = svm.gamma,
svm.cost = svm.cost,
ebma.tol = ebma.tol,
seed = seed,
boot.iter = NULL
)
}
boot.iter
boot.iter = 2
boot.iter
# Check seed argument and set seed
if (is.null(seed)) {
set.seed(546213978)
} else {
if (isTRUE(dplyr::near(seed, as.integer(seed)))) {
set.seed(seed)
} else {
stop("Seed must be either NULL or an integer-valued scalar.")
}
}
# Call to function doing the error checks
error_checks(y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
L2.x.scale = L2.x.scale,
pcs = pcs,
folds = folds,
bin.proportion = bin.proportion,
bin.size = bin.size,
survey = survey,
census = census,
ebma.size = ebma.size,
k.folds = k.folds,
cv.sampling = cv.sampling,
loss.unit = loss.unit,
loss.fun = loss.fun,
best.subset = best.subset,
lasso = lasso,
pca = pca,
gb = gb,
svm = svm,
mrp = mrp,
forward.select = forward.select,
best.subset.L2.x = best.subset.L2.x,
lasso.L2.x = lasso.L2.x,
gb.L2.x = gb.L2.x,
svm.L2.x = svm.L2.x,
mrp.L2.x = mrp.L2.x,
gb.L2.unit = gb.L2.unit,
gb.L2.reg = gb.L2.reg,
lasso.lambda = lasso.lambda,
lasso.n.iter = lasso.n.iter,
uncertainty = uncertainty,
boot.iter = boot.iter)
# Binding for global variables
`%>%` <- dplyr::`%>%`
idx_boot <- NULL
# Register cores
cl <- multicore(cores = cores, type = "open", cl = NULL)
# Bootstrap iterations
boot_out <- foreach::foreach(idx_boot = 1:boot.iter, .packages = "autoMrP") %dopar% {
# Bootstrapped survey sample
boot_sample <- dplyr::sample_n(tbl = survey, size = nrow(survey), replace = TRUE)
# Estimate on 1 sample in autoMrP
boot_mrp <- auto_MrP(
survey = boot_sample,
ebma.n.draws = 1,
uncertainty = FALSE,
verbose = FALSE,
cores = 1,
y = y,
L1.x = L1.x,
L2.x = L2.x,
mrp.L2.x = mrp.L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
L2.x.scale = L2.x.scale,
pcs = pcs,
folds = folds,
bin.proportion = bin.proportion,
bin.size = bin.size,
census = census,
ebma.size = ebma.size,
k.folds = k.folds,
cv.sampling = cv.sampling,
loss.unit = loss.unit,
loss.fun = loss.fun,
best.subset = best.subset,
lasso = lasso,
pca = pca,
gb = gb,
svm = svm,
mrp = mrp,
forward.select = forward.select,
best.subset.L2.x = best.subset.L2.x,
lasso.L2.x = lasso.L2.x,
pca.L2.x = pca.L2.x,
gb.L2.x = gb.L2.x,
svm.L2.x = svm.L2.x,
gb.L2.unit = gb.L2.unit,
gb.L2.reg = gb.L2.reg,
lasso.lambda = lasso.lambda,
lasso.n.iter = lasso.n.iter,
gb.interaction.depth = gb.interaction.depth,
gb.shrinkage = gb.shrinkage,
gb.n.trees.init = gb.n.trees.init,
gb.n.trees.increase = gb.n.trees.increase,
gb.n.trees.max = gb.n.trees.max,
gb.n.iter = gb.n.iter,
gb.n.minobsinnode = gb.n.minobsinnode,
svm.kernel = svm.kernel,
svm.gamma = svm.gamma,
svm.cost = svm.cost,
ebma.tol = ebma.tol,
seed = seed,
boot.iter = NULL
)
}
# Median and standard deviation of EBMA estimates
ebma <- do.call(rbind, do.call(rbind, boot_out)[,"ebma"] ) %>%
dplyr::group_by(.dots = list(L2.unit)) %>%
dplyr::summarise(median = median(ebma),
sd = sd(ebma), .groups = "drop")
ebma
# Median and standard deviations for classifier estimates
classifiers <- do.call(rbind, do.call(rbind, boot_out)[,"classifiers"] ) %>%
dplyr::group_by(.dots = list(L2.unit)) %>%
dplyr::summarise_all(.funs = c(median = median, sd = sd))
classifiers
# Median and standard deviations for classifier estimates
classifiers <- do.call(rbind, do.call(rbind, boot_out)[,"classifiers"] ) %>%
dplyr::group_by(.dots = list(L2.unit)) %>%
dplyr::summarise_all(.funs = c(median = median, sd = sd)) %>%
dplyr::select(
state,
contains("best_subset")
)
classifiers
classifiers <- do.call(rbind, do.call(rbind, boot_out)[,"classifiers"] )
classifiers
# Median and standard deviations for classifier estimates
classifiers <- do.call(rbind, do.call(rbind, boot_out)[,"classifiers"] ) %>%
dplyr::group_by(.dots = list(L2.unit)) %>%
dplyr::summarise_all(.funs = c(median = median, sd = sd)) %>%
dplyr::select(
state,
contains("best_subset"),
contains("pca"),
contains("lasso"),
contains("gbm"),
contains("svm"),
contains("mrp")
)
classifiers
rm(list=ls())
# load functions
devtools::load_all()
y = "YES"
L1.x = c("L1x1", "L1x2", "L1x3")
L2.x = c("L2.x1", "L2.x2")
#L2.x = c("L2.x1", "L2.x2", "L2.x3", "L2.x4")
mrp.L2.x = c("L2.x1", "L2.x2")
L2.unit = "state"
L2.reg = "region"
L2.x.scale = TRUE
pcs = NULL
folds = NULL
bin.proportion = "proportion"
bin.size = NULL
survey = survey_item
census = census
ebma.size = 1/3
k.folds = 5
cv.sampling = "L2 units"
loss.unit = "individuals"
loss.fun = "MSE"
# switch for classifiers
# arguments
y = "YES"
L1.x = c("L1x1", "L1x2", "L1x3")
L2.x = c("L2.x1", "L2.x2")
#L2.x = c("L2.x1", "L2.x2", "L2.x3", "L2.x4")
mrp.L2.x = c("L2.x1", "L2.x2")
L2.unit = "state"
L2.reg = "region"
L2.x.scale = TRUE
pcs = NULL
folds = NULL
bin.proportion = "proportion"
bin.size = NULL
survey = survey_item
census = census
ebma.size = 1/3
k.folds = 5
cv.sampling = "L2 units"
loss.unit = "individuals"
loss.fun = "MSE"
# switch for classifiers
best.subset = FALSE
lasso = FALSE
pca = TRUE
gb = FALSE
svm = FALSE
# the standard MRP model
mrp = FALSE
forward.select = FALSE
best.subset.L2.x = NULL
lasso.L2.x = NULL
pca.L2.x = NULL
gb.L2.x = NULL
svm.L2.x = NULL
# Standard MrP model L2 variables
mrp.L2.x = NULL
gb.L2.unit = FALSE
gb.L2.reg = FALSE
# tuning params lasso
lasso.lambda = 1 / exp(- seq(from = -1, to = 4.5, length = 100))
lasso.n.iter = 70
# tuning params boosting
gb.interaction.depth = c(1, 2, 3)
gb.shrinkage = c(0.04, 0.01, 0.008, 0.005, 0.001)
gb.n.trees.init = 50
gb.n.trees.increase = 50
gb.n.trees.max = 1000
gb.n.iter = 70
gb.n.minobsinnode = 5
svm.kernel = "radial"
svm.loss.fun = NULL
svm.gamma = c(0.3, 0.5, 0.55, 0.6, 0.65, 0.7, 0.8, 0.9, 1, 2, 3, 4)
svm.cost = c(1, 10)
ebma.n.draws = 1
ebma.tol = 0.01
uncertainty = TRUE
seed = NULL
verbose = TRUE
cores = 4
boot.iter = 2
# Check seed argument and set seed
if (is.null(seed)) {
set.seed(546213978)
} else {
if (isTRUE(dplyr::near(seed, as.integer(seed)))) {
set.seed(seed)
} else {
stop("Seed must be either NULL or an integer-valued scalar.")
}
}
# Call to function doing the error checks
error_checks(y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
L2.x.scale = L2.x.scale,
pcs = pcs,
folds = folds,
bin.proportion = bin.proportion,
bin.size = bin.size,
survey = survey,
census = census,
ebma.size = ebma.size,
k.folds = k.folds,
cv.sampling = cv.sampling,
loss.unit = loss.unit,
loss.fun = loss.fun,
best.subset = best.subset,
lasso = lasso,
pca = pca,
gb = gb,
svm = svm,
mrp = mrp,
forward.select = forward.select,
best.subset.L2.x = best.subset.L2.x,
lasso.L2.x = lasso.L2.x,
gb.L2.x = gb.L2.x,
svm.L2.x = svm.L2.x,
mrp.L2.x = mrp.L2.x,
gb.L2.unit = gb.L2.unit,
gb.L2.reg = gb.L2.reg,
lasso.lambda = lasso.lambda,
lasso.n.iter = lasso.n.iter,
uncertainty = uncertainty,
boot.iter = boot.iter)
# Binding for global variables
`%>%` <- dplyr::`%>%`
idx_boot <- NULL
# Register cores
cl <- multicore(cores = cores, type = "open", cl = NULL)
# Bootstrap iterations
boot_out <- foreach::foreach(idx_boot = 1:boot.iter, .packages = "autoMrP") %dopar% {
# Bootstrapped survey sample
boot_sample <- dplyr::sample_n(tbl = survey, size = nrow(survey), replace = TRUE)
# Estimate on 1 sample in autoMrP
boot_mrp <- auto_MrP(
survey = boot_sample,
ebma.n.draws = 1,
uncertainty = FALSE,
verbose = FALSE,
cores = 1,
y = y,
L1.x = L1.x,
L2.x = L2.x,
mrp.L2.x = mrp.L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
L2.x.scale = L2.x.scale,
pcs = pcs,
folds = folds,
bin.proportion = bin.proportion,
bin.size = bin.size,
census = census,
ebma.size = ebma.size,
k.folds = k.folds,
cv.sampling = cv.sampling,
loss.unit = loss.unit,
loss.fun = loss.fun,
best.subset = best.subset,
lasso = lasso,
pca = pca,
gb = gb,
svm = svm,
mrp = mrp,
forward.select = forward.select,
best.subset.L2.x = best.subset.L2.x,
lasso.L2.x = lasso.L2.x,
pca.L2.x = pca.L2.x,
gb.L2.x = gb.L2.x,
svm.L2.x = svm.L2.x,
gb.L2.unit = gb.L2.unit,
gb.L2.reg = gb.L2.reg,
lasso.lambda = lasso.lambda,
lasso.n.iter = lasso.n.iter,
gb.interaction.depth = gb.interaction.depth,
gb.shrinkage = gb.shrinkage,
gb.n.trees.init = gb.n.trees.init,
gb.n.trees.increase = gb.n.trees.increase,
gb.n.trees.max = gb.n.trees.max,
gb.n.iter = gb.n.iter,
gb.n.minobsinnode = gb.n.minobsinnode,
svm.kernel = svm.kernel,
svm.gamma = svm.gamma,
svm.cost = svm.cost,
ebma.tol = ebma.tol,
seed = seed,
boot.iter = NULL
)
}
boot_out
# Median and standard deviation of EBMA estimates
ebma <- do.call(rbind, do.call(rbind, boot_out)[,"ebma"] ) %>%
dplyr::group_by(.dots = list(L2.unit)) %>%
dplyr::summarise(median = median(ebma),
sd = sd(ebma), .groups = "drop")
ebma
do.call(rbind, do.call(rbind, boot_out)[,"ebma"] )
do.call(rbind, do.call(rbind, boot_out)[,"ebma"] )
do.call(rbind, do.call(rbind, boot_out)[,"ebma"] )
do.call(rbind, do.call(rbind, boot_out)[,"ebma"] ) == "EBMA step skipped (only 1 classifier run)"
do.call(rbind, do.call(rbind, boot_out)[,"ebma"] ) == "EBMA step skipped (only 1 classifier run)"
any(do.call(rbind, do.call(rbind, boot_out)[,"ebma"] ) == "EBMA step skipped (only 1 classifier run)")
!any(do.call(rbind, do.call(rbind, boot_out)[,"ebma"] ) == "EBMA step skipped (only 1 classifier run)")
# Median and standard deviation of EBMA estimates
if (!any(do.call(rbind, do.call(rbind, boot_out)[,"ebma"] ) == "EBMA step skipped (only 1 classifier run)")){
ebma <- do.call(rbind, do.call(rbind, boot_out)[,"ebma"] ) %>%
dplyr::group_by(.dots = list(L2.unit)) %>%
dplyr::summarise(median = median(ebma),
sd = sd(ebma), .groups = "drop")
}
# Median and standard deviations for classifier estimates
classifiers <- do.call(rbind, do.call(rbind, boot_out)[,"classifiers"] ) %>%
dplyr::group_by(.dots = list(L2.unit)) %>%
dplyr::summarise_all(.funs = c(median = median, sd = sd)) %>%
dplyr::select(
state,
contains("best_subset"),
contains("pca"),
contains("lasso"),
contains("gbm"),
contains("svm"),
contains("mrp")
)
library(autoMrP)
remove.packages("autoMrP", lib="~/github/autoMrP/packrat/lib/x86_64-w64-mingw32/4.0.2")
warnings()
warnings()
?devtools:build()
?devtools::build()
devtools::build(pkg = "C:/Users/phili/Documents/github/autoMrP/", path = "C:/Users/phili/Documents/github/autoMrP_tarball/")
devtools::build(pkg = "./", path = "C:/Users/phili/Documents/github/autoMrP_tarball/")
devtools::build(pkg = as.package(x = "C:/Users/phili/Documents/github/autoMrP/"), path = "C:/Users/phili/Documents/github/autoMrP_tarball/")
devtools::build(pkg = as.package(x = "C:/Users/phili/Documents/github/autoMrP/"), path = "C:/Users/phili/Documents/github/autoMrP_tarball/")
devtools::build(pkg = as.package(x = "C:/Users/phili/Documents/github/autoMrP/"), path = "C:/Users/phili/Documents/github/autoMrP_tarball/")
devtools::build(pkg = ".", path = "C:/Users/phili/Documents/github/autoMrP_tarball/")
library(autoMrP)
devtools::build(pkg = ".", path = "C:/Users/phili/Documents/github/autoMrP_tarball/")
devtools::build(pkg = ".", path = "C:/Users/phili/Documents/github/autoMrP_tarball/",vignettes = TRUE, mmanual = TRUE)
devtools::build(pkg = ".", path = "C:/Users/phili/Documents/github/autoMrP_tarball/",vignettes = TRUE, manual = TRUE)
devtools::document()
devtools::install()
sessionInfo()
gbm
?gbm
library(autoMrP)
devtools::build(".")
devtools::load_all()
build_vignettes()
devtools::build_vignettes()
devtools::build_vignettes()
devtools::build_vignettes()
devtools::build_vignettes()
devtools::build_vignettes()
library(autoMrP)
library(autoMrP)
devtools::check_win_devel(pkg = ".")
devtools::check_win_devel(pkg = ".")
library(autoMrP)
devtools::check_win_devel(".")
devtools::build(".")
