<<<<<<< HEAD
sep = "")
paste("The argument specifying the fold to which each observation",
" is to be allocated, 'folds', must be a character scalar.",
sep = "")
folds
folds %in% colnames(survey)
paste("The fold variable '", folds,
"' is not in your survey data.", sep = "")
is.double(2L)
is.double(2)
is.double(2/3)
is.double(3.4)
as.double(3.4)
folds
folds_var <- survey %>%
dplyr::select_at(.vars = folds) %>%
dplyr::pull()
folds_var
folds_var <- survey %>%
dplyr::select_at(.vars = folds) %>%
dplyr::pull() %>%
unique()
folds_var
dplyr::near(folds_var, as.integer(folds_var))
dplyr::near(c(1, 2L, 3), as.integer(c(1, 2L, 3)))
dplyr::near(c(1, 2L, 3, 4.2), as.integer(c(1, 2L, 3, 4.2)))
folds_var <- survey %>%
dplyr::select_at(.vars = folds) %>%
dplyr::pull() %>%
unique() %>%
sort()
folds_var
1:max(folds_var)
paste("Fold variable '", folds,
"' must contain a sequence of integers running from 1 to ",
max(folds_var), ".", sep = "")
paste("If argument 'folds' is NULL, then argument 'ebma.size' must",
"be specified.", sep = "")
# Define column in census containing proportion
bin.proportion <- "proportion"
paste("The argument specifying the proportion of ideal types in the",
" census data, 'bin.proportion', must be a character scalar.",
sep = "")
bin.proportion
paste("Proportion of ideal types variable '", bin.proportion,
"' is not in your census data.", sep = "")
min(census$proportion)
max(census$proportion)
?is.numeric
bin_proportion_var <- census %>%
dplyr::select_at(.vars = bin.proportion) %>%
dplyr::pull() %>%
unique()
bin_proportion_var
bin_proportion_var <- census %>%
dplyr::select_at(.vars = bin.proportion) %>%
dplyr::pull() %>%
unique()
is.numeric(bin_proportion_var)
min(bin_proportion_var) >= 0
max(bin_proportion_var) <= 1
(is.numeric(bin_proportion_var) &
min(bin_proportion_var) >= 0 &
max(bin_proportion_var) <= 1)
paste("Proportion of ideal types variable '", bin.proportion,
"' can only take values lying in the unit interval.",
sep = "")
paste("Either argument 'bin.proportion' or argment 'bin.size' must",
" be specified to perform post-stratification..", sep = "")
# Define column in census containing bin size
#bin.size <- "n"
bin.size <- NULL
paste("The argument specifying the bin size of ideal types in the",
" census data, 'bin.size', must be a character scalar.",
sep = "")
paste("The argument 'L2.reg', specifying the geographic region,",
" must be a character scalar.", sep = "")
head(census$n)
paste("Ideal type bin size variable '", bin.size,
"' must be numeric.", sep = "")
bin.size
bin_size_var <- census %>%
dplyr::select_at(.vars = bin.size) %>%
dplyr::pull() %>%
unique()
typeof(survey)
class(survey)
dim(survey)
head(survey)
tibble::is_tibble(survey)
tibble::is_tibble(census)
is.data.frame(census)
is.list(census)
paste("Survey data set '", survey,
"' must be a data.frame.", sep = "")
paste("The argument 'survey', specifying the survey data,",
" must be a data.frame.", sep = "")
ebma.size <- 1/3
# Define number of folds
k.folds <- 5
# Unit to be used in sampling to create CV folds
cv.sampling <- "L2 units"
ebma.size
ebma.size
paste("The argument 'ebma.size', specifying the share of respondents",
" to be allocated to the EBMA fold, must be a rational number in the",
" open unit interval.", sep = "")
paste("The argument 'ebma.size', specifying the share of",
" respondents to be allocated to the EBMA fold, must take a",
" number in the open unit interval.", sep = "")
k.folds
paste("The argument 'k.folds', specifying the number of folds to",
" be used in cross-validation, must be an integer.",
sep = "")
paste("The argument 'k.folds', specifying the number of folds",
" to be used in cross-validation, cannot be larger than",
" the number of survey respondents ", nrow(survey), ".",
sep = "")
paste("The argument 'k.folds', specifying the number of folds",
" to be used in cross-validation, cannot be larger than",
" the number of survey respondents, ", nrow(survey), ".",
sep = "")
k.folds
length(k.folds) == 1
(dplyr::near(k.folds, as.integer(k.folds)) & length(k.folds) == 1)
paste("The argument 'cv.sampling', specifying the sampling method",
" for cross-validation, must be either 'respondents' or",
" 'L2 units'.", sep = "")
paste("The argument 'cv.sampling', specifying the sampling method",
" used for cross-validation, must be either 'respondents'",
" or 'L2 units'.", sep = "")
paste("The argument 'cv.sampling', specifying the sampling method",
" used for cross-validation, must be either 'respondents'",
" or 'L2 units'.", sep = "")
paste("The argument 'cv.sampling', specifying the sampling method",
" to be used for cross-validation, must be either",
" 'respondents' or 'L2 units'.", sep = "")
paste("The logical argument 'best.subset', indicating whether the",
" best subset classifier should be used for predicting y,",
" must be either TRUE or FALSE.", sep = "")
paste("The argument 'best.subset.L2.x', specifying the context-level",
" variables to be used by the best subset classifier, must be",
" a character vector.", sep = "")
paste("Context-level variable '",
best.subset.L2.x[which(!(best.subset.L2.x %in% colnames(survey)))],
"', to be used by the best subset classifier, is not in your",
" survey data.", sep = "")
# Define best subset context-level covariates
best.subset.L2.x <- NULL
# Define lasso context-level covariates
lasso.L2.x <- NULL
# Define gb context-level covariates
gb.L2.x <- NULL
# Define svm context-level covariates
svm.L2.x <- NULL
cat(paste("Context-level variable '",
best.subset.L2.x[which(!(best.subset.L2.x %in% colnames(survey)))],
"', to be used by the best subset classifier, is not in your",
" survey data.", sep = ""), sep = "")
cat(paste("Context-level variable '",
best.subset.L2.x[which(!(best.subset.L2.x %in% colnames(census)))],
"', to be used by the best subset classifier, is not in your",
" census data.", sep = ""), sep = "")
cat(paste("Context-level variable '",
lasso.L2.x[which(!(lasso.L2.x %in% colnames(survey)))],
"', to be used by the lasso classifier, is not in your",
" survey data.", sep = ""), sep = "")
cat(paste("Context-level variable '",
lasso.L2.x[which(!(lasso.L2.x %in% colnames(census)))],
"', to be used by the lasso classifier, is not in your",
" census data.", sep = ""), sep = "")
paste("The argument 'gb.L2.x', specifying the context-level",
" variables to be used by the GB classifier, must be",
" a character vector.", sep = "")
cat(paste("Context-level variable '",
gb.L2.x[which(!(gb.L2.x %in% colnames(survey)))],
"', to be used by the GB classifier, is not in your",
" survey data.", sep = ""), sep = "")
cat(paste("Context-level variable '",
gb.L2.x[which(!(gb.L2.x %in% colnames(census)))],
"', to be used by the GB classifier, is not in your",
" census data.", sep = ""), sep = "")
cat(paste("Context-level variable '",
svm.L2.x[which(!(svm.L2.x %in% colnames(survey)))],
"', to be used by the SVM classifier, is not in your",
" survey data.", sep = ""), sep = "")
cat(paste("Context-level variable '",
svm.L2.x[which(!(svm.L2.x %in% colnames(census)))],
"', to be used by the SVM classifier, is not in your",
" census data.", sep = ""), sep = "")
paste("The argument 'mrp.L2.x', specifying the context-level",
" variables to be used by the standard MRP classifier,",
" must be a character vector.", sep = "")
cat(paste("Context-level variable '",
mrp.L2.x[which(!(mrp.L2.x %in% colnames(survey)))],
"', to be used by the standard MRP classifier, is not in",
" your survey data.", sep = ""), sep = "")
# Define mrp context-level covariates
mrp.L2.x <- NULL
cat(paste("Context-level variable '",
mrp.L2.x[which(!(mrp.L2.x %in% colnames(survey)))],
"', to be used by the standard MRP classifier, is not in",
" your survey data.", sep = ""), sep = "")
cat(paste("Context-level variable '",
mrp.L2.x[which(!(mrp.L2.x %in% colnames(census)))],
"', to be used by the standard MRP classifier, is not in",
" your census data.", sep = ""), sep = "")
cat(paste("Context-level variable '",
mrp.L2.x[which(!(mrp.L2.x %in% colnames(census)))],
"', to be used by the standard MRP classifier, is not in",
" your census data.", sep = ""), sep = "")
cat(paste("Individual-level variable '",
L1.x[which(!(L1.x %in% colnames(survey)))],
"' is not in your survey data.\n", sep = ""), sep = "")
cat(paste("Individual-level variable '",
L1.x[which(!(L1.x %in% colnames(survey)))],
"', specified in argument 'L1.x', is not in your survey",
"data.\n", sep = ""), sep = "")
cat(paste("Individual-level variable '",
L1.x[which(!(L1.x %in% colnames(survey)))],
"', specified in argument 'L1.x', is not in your survey",
" data.\n", sep = ""), sep = "")
cat(paste("Individual-level variable '",
L1.x[which(!(L1.x %in% colnames(census)))],
"', specified in argument 'L1.x', is not in your census",
" data.\n", sep = ""), sep = "")
cat(paste("Context-level variable '",
L2.x[which(!(L2.x %in% colnames(survey)))],
"', specified in argument 'L2.x', is not in your survey",
" data.\n", sep = ""), sep = "")
cat(paste("Context-level variable '",
L2.x[which(!(L2.x %in% colnames(census)))],
"', specified in argument 'L2.x', is not in your census",
" data.\n", sep = ""), sep = "")
cat(paste("Principal component '",
pcs[which(!(pcs %in% colnames(survey)))],
"' is not in your survey data.\n", sep = ""), sep = "")
cat(paste("Principal component '",
pcs[which(!(pcs %in% colnames(survey)))],
"', specified in argument 'pcs', is not in your survey",
" data.\n", sep = ""), sep = "")
cat(paste("Principal component '",
pcs[which(!(pcs %in% colnames(census)))],
"', specified in argument 'pcs', is not in your census",
" data.\n", sep = ""), sep = "")
paste("The argument 'bin.proportion', specifying the variable that",
" indicates the proportion of ideal types in the census data,",
" must be a character scalar.", sep = "")
paste("Proportion of ideal types variable '", bin.proportion,
"' is not in your census data.", sep = "")
paste("Variable '", bin.proportion,
"', indicating the proportion of ideal types, is not in your",
" census data.", sep = "")
paste("Variable '", bin.proportion,
"', indicating the proportion of ideal types, can only take",
" values lying in the unit interval.", sep = "")
paste("Variable '", bin.size,
"', indicating the bin size of ideal types, is not in your",
" census data.", sep = "")
paste("The argument 'bin.size', specifying the variable that",
" indicates the bin size of ideal types in the census data,",
" must be a character scalar.", sep = "")
paste("Variable '", bin.size,
"', indicating the bin size of ideal types, must be numeric.",
sep = "")
paste("Variable '", bin.size,
"', indicating the bin size of ideal types, can only take",
" non-negative values.", sep = "")
cat(paste("Context-level variable '",
best.subset.L2.x[which(!(best.subset.L2.x %in% colnames(survey)))],
"', specified in argument 'best.subset.L2.x' to be used by the",
" best subset classifier, is not in your survey data.", sep = ""),
sep = "")
cat(paste("Context-level variable '",
best.subset.L2.x[which(!(best.subset.L2.x %in% colnames(census)))],
"', specified in argument 'best.subset.L2.x' to be used by the",
" best subset classifier, is not in your census data.", sep = ""),
sep = "")
cat(paste("Context-level variable '",
lasso.L2.x[which(!(lasso.L2.x %in% colnames(survey)))],
"', specified in argument 'lasso.L2.x' to be used by the",
" lasso classifier, is not in your survey data.", sep = ""),
sep = "")
cat(paste("Context-level variable '",
lasso.L2.x[which(!(lasso.L2.x %in% colnames(census)))],
"', specified in argument 'lasso.L2.x' to be used by the",
" lasso classifier, is not in your census data.", sep = ""),
sep = "")
cat(paste("Context-level variable '",
gb.L2.x[which(!(gb.L2.x %in% colnames(survey)))],
"', specified in argument 'gb.L2.x' to be used by the GB",
" classifier, is not in your survey data.", sep = ""),
sep = "")
cat(paste("Context-level variable '",
gb.L2.x[which(!(gb.L2.x %in% colnames(census)))],
"', specified in argument 'gb.L2.x' to be used by the GB",
" classifier, is not in your census data.", sep = ""),
sep = "")
cat(paste("Context-level variable '",
svm.L2.x[which(!(svm.L2.x %in% colnames(survey)))],
"', specified in argument 'svm.L2.x' to be used by the",
" SVM classifier, is not in your survey data.", sep = ""),
sep = "")
cat(paste("Context-level variable '",
svm.L2.x[which(!(svm.L2.x %in% colnames(census)))],
"', specified in argument 'svm.L2.x' to be used by the",
" SVM classifier, is not in your census data.", sep = ""),
sep = "")
cat(paste("Context-level variable '",
mrp.L2.x[which(!(mrp.L2.x %in% colnames(survey)))],
"', specified in argument 'mrp.L2.x' to be used by the",
" standard MRP classifier, is not in your survey data.",
sep = ""), sep = "")
cat(paste("Context-level variable '",
mrp.L2.x[which(!(mrp.L2.x %in% colnames(census)))],
"', specified in argument 'mrp.L2.x' to be used by the",
" standard MRP classifier, is not in your census data.",
sep = ""), sep = "")
paste("The logical argument 'gb.L2.unit', indicating whether",
" 'L2.unit' should be included in the GB classifier must be",
" either TRUE or FALSE.", sep = "")
paste("The logical argument 'gb.L2.reg', indicating whether",
" 'L2.reg' should be included in the GB classifier must be",
" either TRUE or FALSE.", sep = "")
paste("The argument 'best.subset.L2.x', specifying the context-level",
" variables to be used by the best subset classifier, will be",
" ignored because 'best.subset' is set to FALSE", sep = "")
isFALSE(TRUE)
isFALSE("hello")
paste("The argument 'gb.L2.unit', indicating whether 'L2.unit'",
" should be included in the GB classifier will be",
" ignored because 'gb' is set to FALSE.", sep = "")
dplyr::near(2.1, as.integer(2.1))
dplyr::near(2, as.integer(2))
dplyr::near(2L, as.integer(2L))
dplyr::near(c(1, 2), as.integer(c(1, 2)))
is.numeric(c(1, 3))
list(c(1, 3), c(10, 30))
is.numeric(list(c(1, 3), c(10, 30)))
is.vector(c(1, 3))
is.vector(list(c(1, 3), c(10, 30)))
is.list(list(c(1, 3), c(10, 30)))
is.list(c(1, 3))
is.numeric(list(c(1, 3), c(10, 30)))
is.numeric(c(1, 3))
c(1, 2, 3) >= 0
is.numeric(list(c(1, 3), c(10, 30)))
is.list(list(c(1, 3), c(10, 30)))
is.vector(list(c(1, 3), c(10, 30)))
if (NA == TRUE) {print("hello")}
if (NA) {print("hello")}
if (isTRUE(NA == TRUE)) {print("hello")}
if (isTRUE(NA)) {print("hello")}
c(1, 2, 3) >= 0
all(c(1, 2, 3) >= 0)
all(c(1, 2, 3, NA) >= 0)
list(c(1, 3), c(10, 30)) >= 0
min(list(c(1, 3), c(10, 30)))
lasso.lambda
lasso.lambda = list(c(0.1, 0.3, 1), c(1, 10, 10000))
lasso.lambda
length(lasso.lambda)
lasso.lambda
is.numeric(lasso.lambda)
split(lasso.lambda)
unlist(lasso.lambda)
lapply(lasso.lambda, function(x) {is.numeric(x)})
sapply(lasso.lambda, function(x) {is.numeric(x)})
length(lasso.lambda) == 2
sapply(lasso.lambda, function(x) {is.numeric(x)})
!(length(lasso.lambda) == 2 &
all(sapply(lasso.lambda, function(x) {is.numeric(x)})))
paste("If provided as a list, the argument 'lasso.lambda' must",
" be a list of two numeric vectors of equal size, with ",
" the first vector containing the step sizes by which the",
" penalty parameter should increase and the second vector",
" containing the upper thresholds of the intervals to",
" which the step sizes apply.",
sep = "")
paste("If provided as a list, the argument 'lasso.lambda' must",
" be a list of two numeric vectors of equal size, with",
" the first vector containing the step sizes by which the",
" penalty parameter should increase and the second vector",
" containing the upper thresholds of the intervals to",
" which the step sizes apply.",
sep = "")
sapply(lasso.lambda, function(x) {is.numeric(x)})
sapply(lasso.lambda, function(x) {length(x)})
unique(sapply(lasso.lambda, function(x) {length(x)}))
length(unique(sapply(lasso.lambda, function(x) {length(x)}))) == 1
identical(c(2, 2))
!(length(lasso.lambda) == 2 &
all(sapply(lasso.lambda, function(x) {is.numeric(x)})) &
length(unique(sapply(lasso.lambda, function(x) {length(x)}))) == 1)
lasso.lambda
lasso.lambda[[1]]
lasso.lambda[[2]]
c(1, 2, 3) <= c(2, 3, 4)
c(1, 2, 3) <= c(2, 2, 4)
c(1, 2, 3) <= c(2, 1, 4)
lasso.lambda[[1]] <= lasso.lambda[[2]]
all(lasso.lambda[[1]] <= lasso.lambda[[2]])
!all(lasso.lambda[[1]] <= lasso.lambda[[2]])
paste("If argument 'lasso.lambda' is specified as a list of",
" two vectors, the value indicating the step size in",
" the first vector cannot exceed the corresponding value",
" in the second vector indicating the upper threshold",
" of the interval to which the step size should apply.",
sep = "")
paste("If argument 'lasso.lambda' is specified as a list of",
" two vectors, the value in the first vector indicating",
" the step size cannot exceed the corresponding value",
" in the second vector indicating the upper threshold",
" of the interval to which the step size should apply.",
sep = "")
c(1, 2, 3) <= c(2, 1, 4)
any(c(1, 2, 3) <= c(2, 1, 4))
any(c(1, 2, 3) > c(2, 1, 4))
any(c(1, 2, 3) > c(2, 2, 4))
lasso.lambda
unlist(lasso.lambda)
min(unlist(lasso.lambda))
if (c(TRUE, TRUE, FALSE)) {print("hello")}
lapply(c(TRUE, TRUE, FALSE), function(x) {if (x) {print("hello")}})
sapply(c(TRUE, TRUE, FALSE), function(x) {if (x) {print("hello")}})
if (TRUE) {print("hello")}
if (FALSE) {print("hello")}
if (NA) {print("hello")}
if (isTRUE(NA)) {print("hello")}
if (isTRUE(TRUE)) {print("hello")}
if (isTRUE(FALSE)) {print("hello")}
L2.unit.include
list(data.frame(a = c(1, 2), b = c(3, 4)), data.frame(a = c(2, 3), b = c(4, 5)))
dplyr::bind_rows(list(data.frame(a = c(1, 2), b = c(3, 4)), data.frame(a = c(2, 3), b = c(4, 5))))
?dplyr::bind_cols
install.packages(c("backports", "broom", "caret", "cli", "digest", "dplyr", "forcats", "foreach", "ggplot2", "glue", "Hmisc", "lava", "lifecycle", "lme4", "lubridate", "ModelMetrics", "modelr", "nloptr", "plyr", "pROC", "purrr", "Rcpp", "recipes", "reshape2", "rlang", "SQUAREM", "stringi", "survival", "tibble", "vctrs", "withr", "xfun"))
install.packages(c("boot", "class", "foreign", "KernSmooth", "lattice", "MASS", "Matrix", "mgcv", "nlme", "nnet", "spatial", "survival"), lib="/Users/retowuest/Dropbox/MRP and ML/autoMrP/packrat/lib-R/x86_64-apple-darwin15.6.0/3.6.1")
install.packages("knitr")
packrat::restore(prompt = FALSE)
remove.packages(c("broom", "caret", "clipr", "forcats", "foreach", "generics", "gower", "haven", "here", "hms", "ipred", "iterators", "lava", "lazyeval", "lubridate", "ModelMetrics", "modelr", "numDeriv", "pROC", "prodlim", "readr", "recipes", "reshape2", "SQUAREM", "tidyr", "timeDate"))
install.packages("Formula")
install.packages("Formula")
install.packages("knitr")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("colorspace")
install.packages("packrat")
packrat::init()
install.packages("EBMAforecast")
devtools::install_github("jmontgomery/EBMAforecast")
install.packages("devtools")
devtools::install_github("jmontgomery/EBMAforecast")
devtools::install_github("jmontgomery/EBMAforecast")
?devtools::install_github
devtools::install_github("jmontgomery/EBMAforecast")
devtools::install_github("cran/EBMAforecast")
packrat::init()
warnings()
devtools::install_github("cran/Rcpp")
packrat::init()
devtools::install_github("retowuest/autoMrP",
auth_token = "042a7ceb4aeca462c4479d54ad40b5926563c4a6",
force = TRUE)
install.packages("devtools")
devtools::install_github("retowuest/autoMrP",
auth_token = "042a7ceb4aeca462c4479d54ad40b5926563c4a6",
force = TRUE)
=======
L2.unit = "state"
L2.reg = "region"
L2.x.scale = TRUE
pcs = NULL
folds = NULL
bin.proportion = "proportion"
bin.size = NULL
survey = survey
census = census
ebma.size = 1/3
k.folds = 5
cv.sampling = "L2 units"
loss.unit = "individuals"
loss.fun = "MSE"
# switch for classifiers
best.subset = TRUE
lasso = TRUE
pca = TRUE
gb = TRUE
svm = TRUE
# the standard MRP model
mrp = TRUE
forward.select = FALSE
best.subset.L2.x = NULL
lasso.L2.x = NULL
pca.L2.x = NULL
gb.L2.x = NULL
svm.L2.x = NULL
# Standard MrP model L2 variables
gb.L2.unit = FALSE
gb.L2.reg = FALSE
# tuning params lasso
lasso.lambda = list(c(1), c(10))
lasso.n.iter = 20
# tuning params boosting
gb.interaction.depth = c(1, 2, 3)
gb.shrinkage = c(0.04, 0.01)
gb.n.trees.init = 50
gb.n.trees.increase = 50
gb.n.trees.max = 1000
gb.n.iter = 70
gb.n.minobsinnode = 5
svm.kernel = "radial"
svm.loss.fun = NULL
svm.gamma = c(0.3, 0.5)
svm.cost = c(1, 10)
ebma.n.draws = 3
ebma.tol = c(0.01, 0.005)
uncertainty = FALSE
seed = NULL
verbose = TRUE
# Determine context-level covariates
if (is.null(svm.L2.x)) {
svm.L2.x <- L2.x
}
svm.L2.x
L2.x = svm.L2.x
# Create model formula
x <- paste(c(L1.x, L2.x, L2.unit, L2.reg), collapse = " + ")
form <- as.formula(paste(y, " ~ ", x, sep = ""))
form
# tuning parameter grid
svm_grid <- expand.grid(gamma, cost)
names(svm_grid) <- c("gamma", "cost")
svm_grid
# loop over tuning grid
grid_cells <- apply(svm_grid, 1, function(g) {
# Set tuning parameters
gamma_value <- as.numeric(g["gamma"])
cost_value <- as.numeric(g["cost"])
# Loop over each fold
k_errors <- lapply(seq_along(data), function(k) {
# Split data in training and validation sets and factorize DV
data_train <- dplyr::bind_rows(data[-k]) %>%
dplyr::mutate_at(.vars = y, as.factor)
data_valid <- dplyr::bind_rows(data[k]) %>%
dplyr::mutate_at(.vars = y, as.factor)
# Svm classifier
model_l <- svm_classifier(
form = form,
data = data_train,
kernel = kernel,
type = "C-classification",
probability = TRUE,
svm.gamma = gamma_value,
svm.cost = cost_value,
verbose = verbose
)
# Use trained model to make predictions for kth validation set
pred_l <- predict(model_l, newdata = data.frame(data_valid),
probability = TRUE)
pred_l <- as.numeric(attr(pred_l, "probabilities")[, "1"])
# Transform factor DV to numeric for loss function
data_valid <- data_valid %>%
dplyr::mutate_at(.vars = y, function(x) as.numeric(levels(x))[x])
# Evaluate predictions based on loss function
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
loss.unit = loss.unit,
loss.fun = loss.fun,
y = y, L2.unit = L2.unit)
})
# Mean over all k folds
best_error <- mean(unlist(k_errors))
})
loss.unit
loss.fun
# Extract best tuning parameters
out <- list(gamma = svm_grid[which.min(grid_cells), "gamma"],
cost = svm_grid[which.min(grid_cells), "cost"])
out
# Create list of cross-validation folds
cv_folds <- list(
`1` = survey_item[1:200, ],
`2` = survey_item[201:400, ],
`3` = survey_item[401:1500, ])
# Run svm classifier
m <- run_svm(
y = "YES",
L1.x = c("L1x1", "L1x2"),
L2.x = c("L2.x1", "L2.x2"),
L2.unit = "state",
L2.reg = "region",
kernel = "radial",
loss.fun = "MSE",
loss.unit = "individuals",
gamma = c(0.3, 0.1),
cost = c(1, 50),
data = cv_folds,
verbose = TRUE)
m
devtools::load_all()
out <- autoMrP::auto_MrP(
y = "YES",
L1.x = c("L1x1", "L1x2"),
L2.x = c("L2.x1", "L2.x2", "L2.x3"),
L2.unit = "state",
L2.reg = "region",
L2.x.scale = FALSE,
survey = autoMrP::survey_item,
census = autoMrP::census,
bin.proportion = "proportion",
best.subset = TRUE,
lasso = TRUE,
pca = TRUE,
gb = TRUE,
svm = TRUE,
mrp = TRUE,
mrp.L2.x = c("L2.x1", "L2.x2"),
ebma.tol = c(0.001, 0.0005),
ebma.n.draws = 2,
gb.L2.unit = FALSE,
lasso.n.iter = 5
)
run_svm <- function(y, L1.x, L2.x, L2.unit, L2.reg,
kernel = "radial", loss.fun,
loss.unit, gamma, cost, data,
verbose) {
# Create model formula
x <- paste(c(L1.x, L2.x, L2.unit, L2.reg), collapse = " + ")
form <- as.formula(paste(y, " ~ ", x, sep = ""))
# tuning parameter grid
svm_grid <- expand.grid(gamma, cost)
names(svm_grid) <- c("gamma", "cost")
# loop over tuning grid
grid_cells <- apply(svm_grid, 1, function(g) {
# Set tuning parameters
gamma_value <- as.numeric(g["gamma"])
cost_value <- as.numeric(g["cost"])
# Loop over each fold
k_errors <- lapply(seq_along(data), function(k) {
browser()
# Split data in training and validation sets and factorize DV
data_train <- dplyr::bind_rows(data[-k]) %>%
dplyr::mutate_at(.vars = y, as.factor)
data_valid <- dplyr::bind_rows(data[k]) %>%
dplyr::mutate_at(.vars = y, as.factor)
# Svm classifier
model_l <- svm_classifier(
form = form,
data = data_train,
kernel = kernel,
type = "C-classification",
probability = TRUE,
svm.gamma = gamma_value,
svm.cost = cost_value,
verbose = verbose
)
# Use trained model to make predictions for kth validation set
pred_l <- predict(model_l, newdata = data.frame(data_valid),
probability = TRUE)
pred_l <- as.numeric(attr(pred_l, "probabilities")[, "1"])
# Transform factor DV to numeric for loss function
data_valid <- data_valid %>%
dplyr::mutate_at(.vars = y, function(x) as.numeric(levels(x))[x])
# Evaluate predictions based on loss function
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
loss.unit = loss.unit,
loss.fun = loss.fun,
y = y, L2.unit = L2.unit)
})
# Mean over all k folds
best_error <- mean(unlist(k_errors))
})
# Extract best tuning parameters
out <- list(gamma = svm_grid[which.min(grid_cells), "gamma"],
cost = svm_grid[which.min(grid_cells), "cost"])
# Function output
return(out)
}
out <- autoMrP::auto_MrP(
y = "YES",
L1.x = c("L1x1", "L1x2"),
L2.x = c("L2.x1", "L2.x2", "L2.x3"),
L2.unit = "state",
L2.reg = "region",
L2.x.scale = FALSE,
survey = autoMrP::survey_item,
census = autoMrP::census,
bin.proportion = "proportion",
best.subset = TRUE,
lasso = TRUE,
pca = TRUE,
gb = TRUE,
svm = TRUE,
mrp = TRUE,
mrp.L2.x = c("L2.x1", "L2.x2"),
ebma.tol = c(0.001, 0.0005),
ebma.n.draws = 2,
gb.L2.unit = FALSE,
lasso.n.iter = 5
)
out <- autoMrP::auto_MrP(
y = "YES",
L1.x = c("L1x1", "L1x2"),
L2.x = c("L2.x1", "L2.x2", "L2.x3"),
L2.unit = "state",
L2.reg = "region",
L2.x.scale = FALSE,
survey = autoMrP::survey_item,
census = autoMrP::census,
bin.proportion = "proportion",
best.subset = TRUE,
lasso = TRUE,
pca = TRUE,
gb = TRUE,
svm = TRUE,
mrp = TRUE,
mrp.L2.x = c("L2.x1", "L2.x2"),
ebma.tol = c(0.001, 0.0005),
ebma.n.draws = 2,
gb.L2.unit = FALSE,
lasso.n.iter = 5
)
loss.unit
loss.fun
n
>>>>>>> d6c78e96e68f30a639f80a7e5f896379f3624347
library(autoMrP)
# load all package functions
devtools::load_all()
# data
survey <- autoMrP::survey_item
out <- autoMrP::auto_MrP(
y = "YES",
L1.x = c("L1x1", "L1x2"),
L2.x = c("L2.x1", "L2.x2", "L2.x3"),
L2.unit = "state",
L2.reg = "region",
L2.x.scale = FALSE,
survey = autoMrP::survey_item,
census = autoMrP::census,
bin.proportion = "proportion",
best.subset = TRUE,
lasso = TRUE,
pca = TRUE,
gb = TRUE,
svm = TRUE,
mrp = TRUE,
mrp.L2.x = c("L2.x1", "L2.x2"),
ebma.tol = c(0.001, 0.0005),
ebma.n.draws = 2,
gb.L2.unit = FALSE,
lasso.n.iter = 5
)
# data
survey <- autoMrP::survey_item
# load all package functions
devtools::load_all()
# test function
rm(list=ls())
out <- autoMrP::auto_MrP(
y = "YES",
L1.x = c("L1x1", "L1x2"),
L2.x = c("L2.x1", "L2.x2", "L2.x3"),
L2.unit = "state",
L2.reg = "region",
L2.x.scale = FALSE,
survey = autoMrP::survey_item,
census = autoMrP::census,
bin.proportion = "proportion",
best.subset = TRUE,
lasso = TRUE,
pca = TRUE,
gb = TRUE,
svm = TRUE,
mrp = TRUE,
mrp.L2.x = c("L2.x1", "L2.x2"),
ebma.tol = c(0.001, 0.0005),
ebma.n.draws = 2,
gb.L2.unit = FALSE,
lasso.n.iter = 5
)
out
library(autoMrP)
# load all package functions
devtools::load_all()
# test function
rm(list=ls())
# load all package functions
devtools::load_all()
# data
survey <- autoMrP::survey_item
out <- autoMrP::auto_MrP(
y = "YES",
L1.x = c("L1x1", "L1x2"),
L2.x = c("L2.x1", "L2.x2", "L2.x3"),
L2.unit = "state",
L2.reg = "region",
L2.x.scale = FALSE,
survey = autoMrP::survey_item,
census = autoMrP::census,
bin.proportion = "proportion",
best.subset = TRUE,
lasso = TRUE,
pca = TRUE,
gb = TRUE,
svm = TRUE,
mrp = TRUE,
mrp.L2.x = c("L2.x1", "L2.x2"),
ebma.tol = c(0.001, 0.0005),
ebma.n.draws = 2,
gb.L2.unit = FALSE,
lasso.n.iter = 5
)
out
library(autoMrP)
# test function
rm(list=ls())
# data
survey <- autoMrP::survey_item
# load all package functions
devtools::load_all()
out <- autoMrP::auto_MrP(
y = "YES",
L1.x = c("L1x1", "L1x2"),
L2.x = c("L2.x1", "L2.x2", "L2.x3"),
L2.unit = "state",
L2.reg = "region",
L2.x.scale = FALSE,
survey = autoMrP::survey_item,
census = autoMrP::census,
bin.proportion = "proportion",
best.subset = TRUE,
lasso = TRUE,
pca = TRUE,
gb = TRUE,
svm = TRUE,
mrp = TRUE,
mrp.L2.x = c("L2.x1", "L2.x2"),
ebma.tol = c(0.001, 0.0005),
ebma.n.draws = 2,
gb.L2.unit = FALSE,
lasso.n.iter = 5
)
out
?autoMrP
?autoMrP::autoMrP
autoMrP::autoMrP
# load all package functions
devtools::load_all()
?auto_MrP
out <- autoMrP::auto_MrP(
y = "YES",
L1.x = c("L1x1", "L1x2"),
L2.x = c("L2.x1", "L2.x2", "L2.x3"),
L2.unit = "state",
L2.reg = "region",
L2.x.scale = FALSE,
survey = autoMrP::survey_item,
census = autoMrP::census,
bin.proportion = "proportion",
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = TRUE,
mrp = FALSE,
ebma.tol = c(0.001, 0.0005),
svm.gamma = c(0.3, 0.5, 0.55, 0.6, 0.65, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10),
svm.cost = c(1, 10),
ebma.n.draws = 2,
gb.L2.unit = FALSE,
lasso.n.iter = 5
)
out
out <- autoMrP::auto_MrP(
y = "YES",
L1.x = c("L1x1", "L1x2"),
L2.x = c("L2.x1", "L2.x2", "L2.x3"),
L2.unit = "state",
L2.reg = "region",
L2.x.scale = FALSE,
survey = autoMrP::survey_item,
census = autoMrP::census,
bin.proportion = "proportion",
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = TRUE,
mrp = FALSE,
ebma.tol = c(0.001, 0.0005),
svm.gamma = c(0.3, 0.5, 0.55, 0.6, 0.65, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10),
svm.cost = c(0.5, 1, 10),
ebma.n.draws = 2,
gb.L2.unit = FALSE,
lasso.n.iter = 5
)
out
out <- autoMrP::auto_MrP(
y = "YES",
L1.x = c("L1x1", "L1x2"),
L2.x = c("L2.x1", "L2.x2", "L2.x3"),
L2.unit = "state",
L2.reg = "region",
L2.x.scale = FALSE,
survey = autoMrP::survey_item,
census = autoMrP::census,
bin.proportion = "proportion",
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = TRUE,
mrp = FALSE,
ebma.tol = c(0.001, 0.0005),
svm.gamma = c(0.3, 0.5, 0.55, 0.6, 0.65, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10),
svm.cost = c(0.1, 0.5, 1, 5, 10, 20),
ebma.n.draws = 2,
gb.L2.unit = FALSE,
lasso.n.iter = 5
)
out
print(out$classifiers, n  = 48)
out <- autoMrP::auto_MrP(
y = "YES",
L1.x = c("L1x1", "L1x2"),
L2.x = c("L2.x1", "L2.x2", "L2.x3"),
L2.unit = "state",
L2.reg = "region",
L2.x.scale = FALSE,
survey = autoMrP::survey_item,
census = autoMrP::census,
bin.proportion = "proportion",
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = TRUE,
svm = TRUE,
mrp = FALSE,
ebma.tol = c(0.001, 0.0005),
svm.gamma = c(0.3, 0.5, 0.55, 0.6, 0.65, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10),
svm.cost = c(0.1, 0.5, 1, 5, 10, 20, 50, 100),
ebma.n.draws = 2,
gb.L2.unit = FALSE,
lasso.n.iter = 5
)
out
library(autoMrP)
library(autoMrP)
<<<<<<< HEAD
devtools::install_github("retowuest/autoMrP",
auth_token = "042a7ceb4aeca462c4479d54ad40b5926563c4a6",
force = TRUE)
?autoMrP::auto_MrP
install.packages("knitr")
library(knitr)
install.packages("knitr", lib="C:/Users/Philipp/Dropbox/MRP and ML/autoMrP/packrat/lib-R/x86_64-w64-mingw32/4.0.0")
devtools::install_github("retowuest/autoMrP",lib="C:/Users/Philipp/Dropbox/MRP and ML/autoMrP/packrat/lib-R/x86_64-w64-mingw32/4.0.0")
install.packages("devtools", lib="C:/Users/Philipp/Dropbox/MRP and ML/autoMrP/packrat/lib-R/x86_64-w64-mingw32/4.0.0")
devtools::install_github("retowuest/autoMrP",lib="C:/Users/Philipp/Dropbox/MRP and ML/autoMrP/packrat/lib-R/x86_64-w64-mingw32/4.0.0")
devtools::install_github("cran/EBMAforecast",lib="C:/Users/Philipp/Dropbox/MRP and ML/autoMrP/packrat/lib-R/x86_64-w64-mingw32/4.0.0")
library(autoMrP)
?auto_MrP::census
?autoMrP::census
library(autoMrP)
=======
# test function
rm(list=ls())
# data
survey <- autoMrP::survey_item
# load all package functions
devtools::load_all()
out <- autoMrP::auto_MrP(
y = "YES",
L1.x = c("L1x1", "L1x2"),
L2.x = c("L2.x1", "L2.x2", "L2.x3"),
L2.unit = "state",
L2.reg = "region",
L2.x.scale = FALSE,
survey = autoMrP::survey_item,
census = autoMrP::census,
bin.proportion = "proportion",
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = TRUE,
svm = TRUE,
mrp = FALSE,
ebma.tol = c(0.001, 0.0005),
svm.gamma = c(0.3, 0.5, 0.55, 0.6, 0.65, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10),
svm.cost = c(0.1, 0.5, 1, 5, 10, 20, 50, 100),
svm.L2.unit = FALSE,
svm.L2.reg = FALSE,
ebma.n.draws = 2,
gb.L2.reg = TRUE,
lasso.n.iter = 5
)
out
print(out$classifiers, n = 48)
>>>>>>> d6c78e96e68f30a639f80a7e5f896379f3624347
