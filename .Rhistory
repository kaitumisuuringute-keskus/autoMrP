}
L2.reg
!is.null(L2.reg)
if (!(L2.reg %in% colnames(survey))) {
stop(paste("The geographic region '", L2.reg,
"' is not in your survey data.", sep = ""))
}
if (!(L2.reg %in% colnames(census))) {
stop(paste("The geographic region '", L2.reg,
"' is not in your census data.", sep = ""))
}
if (any(unlist(lapply(dplyr::group_split(survey, .data[[L2.unit]]),
function(x) length(unique(x[[L2.reg]])))) > 1)) {
stop(paste("The geographic unit(s) '",
which(unlist(lapply(dplyr::group_split(survey, .data[[L2.unit]]),
function(x) length(unique(x[[L2.reg]])))) > 1),
"' is/are nested in multiple regions in your survey data."))
}
if (any(unlist(lapply(dplyr::group_split(census, .data[[L2.unit]]),
function(x) length(unique(x[[L2.reg]])))) > 1)) {
stop(paste("The geographic unit(s) '",
which(unlist(lapply(dplyr::group_split(census, .data[[L2.unit]]),
function(x) length(unique(x[[L2.reg]])))) > 1),
"' is/are nested in multiple regions in your census data."))
}
ebma.size
if (is.null(ebma.size)) {
ebma.size <- round(nrow(survey) / 3, digits = 0)
} else if (is.numeric(ebma.size) & ebma.size > 0 & ebma.size < 1) {
ebma.size <- round(nrow(survey) * ebma.size, digits = 0)
} else {
stop("ebma.size must be a rational number in the open unit interval.")
}
k.folds
as.integer(k.folds)
if (!((is.integer(k.folds) | all(as.integer(k.folds) == k.folds)) &
length(k.folds) == 1)) {
stop("k.folds must be an integer number.")
}
cv.sampling
if (!cv.sampling %in% c("respondents", "L2 units")) {
stop("cv.sampling must take either the value 'respondents' or 'L2 units'.")
}
lasso.lambda.set
if (!(is.vector(lasso.lambda.set) | is.data.frame(lasso.lambda.set))) {
stop(paste("lasso.lambda.set must be either a numeric vector or a data.frame ",
"with two columns, one for step size increase and the other ",
"for the upper threshold of the interval of lambdas to which ",
"the step size applies", sep = ""))
}
lasso.iterations.max
if (!(is.null(lasso.iterations.max) | (is.numeric(lasso.iterations.max) &
length(lasso.iterations.max) == 1))) {
stop("lasso.iterations.max must be either a numeric scalar or NULL.")
}
gb.interaction.set
if (!(is.integer(gb.interaction.set) |
all(as.integer(gb.interaction.set) == gb.interaction.set))) {
stop("gb.interaction.set must be an integer-valued vector.")
}
gb.interaction.set
if (!is.numeric(gb.shrinkage.set)) {
stop("gb.shrinkage.set must be a numeric vector")
} else if (min(gb.shrinkage.set) < 0.001 | max(gb.shrinkage.set) > 0.1) {
warning("gb.shrinkage.set should have values lying between 0.001 and 0.1.")
}
gb.shrinkage.set
gb.tree.start
if (!((is.integer(gb.tree.start) |
all(as.integer(gb.tree.start) == gb.tree.start)) &
length(gb.tree.start) == 1)) {
stop("gb.tree.start must be an integer-valued scalar.")
}
gb.tree.increase.set
if (!(is.integer(gb.tree.increase.set) |
all(as.integer(gb.tree.increase.set) == gb.tree.increase.set))) {
stop("gb.tree.increase.set must be an integer-valued scalar or vector.")
} else if (length(gb.tree.increase.set) > 1 &
length(gb.tree.increase.set) != length(gb.shrinkage.set)) {
stop(paste("gb.tree.increase.set must be either a scalar or a vector of ",
"size `length(gb.shrinkage.set)`.", sep = ""))
}
gb.trees.max.set
if (!(is.integer(gb.trees.max.set) |
all(as.integer(gb.trees.max.set) == gb.trees.max.set))) {
stop("gb.trees.max.set must be an integer-valued scalar or vector.")
} else if (length(gb.trees.max.set) > 1 &
length(gb.trees.max.set) != length(gb.shrinkage.set)) {
stop(paste("gb.trees.max.set must be either a scalar or a vector of size ",
"`length(gb.shrinkage.set)`.", sep = ""))
}
custom.folds
names(survey)
head(as.data.frame(survey))
head(survey[, custom.folds])
tail(as.data.frame(survey))
tail(survey[, custom.folds])
length(unique(survey[, custom.folds]))
unique(survey[, custom.folds])
max(survey[, custom.folds])
k.folds
unique(survey[, custom.folds])
unique(c(2, 1, 3))
unique(c(2, 1, 3, 2))
sort(unique(c(2, 1, 3, 2)))
TRUE | FALSE
unique(survey[, custom.folds])
c(1, 2, 3, 4, 5, 6) == 1:6
c(1, 3, 2, 4, 5, 6) == 1:6
unique(survey[, custom.folds])
unique(survey[, custom.folds]) == 1:6
custom.folds
survey %>% dplyr::select_at(.vars = custom.folds) %>%
dplyr::pull() %>% unique() %>% sort()
1:(k.folds + 1)
survey %>% dplyr::select_at(.vars = custom.folds) %>%
dplyr::pull() %>% unique() %>% sort() == 1:(k.folds + 1)
all(survey %>% dplyr::select_at(.vars = custom.folds) %>%
dplyr::pull() %>% unique() %>% sort() == 1:(k.folds + 1))
all(survey %>% dplyr::select_at(.vars = custom.folds) %>%
dplyr::pull() %>% unique() %>% sort() == 1:(k.folds + 1))
!all(survey %>% dplyr::select_at(.vars = custom.folds) %>%
dplyr::pull() %>% unique() %>% sort() == 1:(k.folds + 1))
if (!is.null(custom.folds)) {
if (!(is.double(survey[, custom.folds]) |
is.integer(survey[ ,custom.folds]))) {
stop("The variable specifying folds must of type integer or double.")
}
if (!all(survey %>% dplyr::select_at(.vars = custom.folds) %>%
dplyr::pull() %>% unique() %>% sort() == 1:(k.folds + 1))) {
stop("custom.folds must contain integers ranging from 1 to `k.folds` + 1.")
}
}
head(survey[, custom.folds])
class(survey[, custom.folds])
class(survey %>% dplyr::select_at(.vars = custom.folds) %>%
dplyr::pull())
is.double(survey %>% dplyr::select_at(.vars = custom.folds) %>%
dplyr::pull())
is.integer(survey %>% dplyr::select_at(.vars = custom.folds) %>%
dplyr::pull())
if (!is.null(custom.folds)) {
if (!(is.double(survey %>% dplyr::select_at(.vars = custom.folds) %>% dplyr::pull()) |
is.integer(survey %>% dplyr::select_at(.vars = custom.folds) %>% dplyr::pull()))) {
stop("The variable specifying folds must of type integer or double.")
}
if (!all(survey %>% dplyr::select_at(.vars = custom.folds) %>%
dplyr::pull() %>% unique() %>% sort() == 1:(k.folds + 1))) {
stop("custom.folds must contain integers ranging from 1 to `k.folds` + 1.")
}
}
bin.size
bin.proportion
?dplyr::rename_at
names(census)
test <- census %>%
dplyr::rename(prop = one_of(proportion))
names(test)
test <- census %>%
dplyr::rename_at(.vars = proportion, prop)
test <- census %>%
dplyr::rename_at(prop = one_of(proportion))
test <- census %>%
dplyr::rename_at(prop = .vars(proportion))
test <- census %>%
dplyr::rename_at(.vars = proportion)
test <- census %>%
dplyr::rename_at(.vars = proportion, .funs = "prop")
paste0("prop")
test <- census %>%
dplyr::rename_at(.vars = proportion, .funs = paste0("prop"))
test <- census %>%
dplyr::rename_at(vars(proportion), .funs = paste0("prop"))
test <- census %>%
dplyr::rename(prop = one_of(proportion))
names(test)
bin.proportion
test <- census %>%
dplyr::rename_at(.vars = bin.proportion, .funs = paste0("prop"))
?paste0
test <- census %>%
dplyr::rename_at(.vars = bin.proportion, .funs = paste0(.))
test <- census %>%
dplyr::rename_at(vars(bin.proportion), funs(paste0("var", .)))
test <- census %>%
dplyr::rename_at(vars(proportion), funs(paste0("var", .)))
test <- census %>%
dplyr::rename_at(dplyr::vars(proportion), funs(paste0("var", .)))
test <- census %>%
dplyr::rename_at(dplyr::vars(proportion), dplyr::funs(paste0("var", .)))
test <- census %>%
dplyr::rename_at(.vars = proportion, dplyr::funs(paste0("var", .)))
names(test)
test <- census %>%
dplyr::rename_at(.vars = proportion, .funs = paste0("var", .))
test <- census %>%
dplyr::rename(prop = one_of(proportion))
names(test)
custom.pc
isFALSE(TRUE)
isFALSE(custom.pc)
custom.pc
?stats::prcomp
pca_out <- stats::prcomp(survey[, L2.x],
retx = TRUE,
center = TRUE,
scale. = TRUE,
tol = NULL)
dim(pca_out)
class(pca_out)
dim(pca_out$x)
head(pca_out$x)
class(pca_out$x)
survey <- survey %>%
dplyr::bind_cols(as.data.frame(pca_out$x))
dim(survey)
head(survey)
head(as.data.frame(survey))
# Add PCs to census data
pc_names <- colnames(pca_out$x)
pc_names
unique(survey %>% dplyr::select(all_of(L2.unit),
all_of(pc_names)))
dim(unique(survey %>% dplyr::select(all_of(L2.unit),
all_of(pc_names))))
census <- census %>%
dplyr::left_join(unique(survey %>% dplyr::select(all_of(L2.unit),
all_of(pc_names))),
by = L2.unit)
dim(census)
head(census)
L2.x.scale
isTRUE(L2.x.scale)
custom.folds
custom.folds
is.null(custom.folds)
ebma_folding_out <- ebma_folding(data = survey,
L2.unit = L2.unit,
ebma.size = ebma.size)
# Function to create EBMA hold-out fold
ebma_folding <- function(data, L2.unit, ebma.size) {
# Add row number to data frame
data <- data %>%
dplyr::mutate(index = row_number())
# Split data by geographic unit into a list of data frames
data_list <- data %>%
dplyr::group_split(.data[[L2.unit]])
# Sample one respondent per geographic unit
one_per_unit <- lapply(data_list, function(x) {
sample(x$index, size = 1, replace = FALSE)
}) %>%
unlist()
# Create EBMA hold-out fold
ebma_fold <- data %>%
dplyr::filter(index %in% one_per_unit)
data <- data %>%
dplyr::filter(!(index %in% one_per_unit))
remainder <- sample(data$index, size = ebma.size - length(one_per_unit),
replace = FALSE)
ebma_remainder <- data %>%
dplyr::filter(index %in% remainder)
ebma_fold <- ebma_fold %>%
dplyr::bind_rows(ebma_remainder)
# Extract EBMA hold-out fold from survey sample
cv_data <- data %>%
dplyr::filter(!(index %in% ebma_fold$index))
# Remove index variable
ebma_fold <- ebma_fold %>%
dplyr::select(-index)
cv_data <- cv_data %>%
dplyr::select(-index)
# Function output
out <- list(ebma_fold = ebma_fold,
cv_data = cv_data)
return(out)
}
# Function to create CV folds
cv_folding <- function(data, L2.unit, k.folds,
cv.sampling = c("respondents", "L2 units")) {
if (cv.sampling == "respondents") {
# Add row number to data frame
data <- data %>%
dplyr::mutate(index = row_number())
# Randomize indices of respondents
indices <- sample(data$index, size = length(data$index), replace = FALSE)
# Define number of units per fold
no_floor <- floor(length(indices) / k.folds)
no_remaining <- length(indices) - no_floor * k.folds
no_fold <- rep(no_floor, times = k.folds)
if (no_remaining > 0) {
no_fold[1:no_remaining] <- no_fold[1:no_remaining] + 1
}
# Split indices into folds
fold_indices <- split(indices, rep(1:k.folds, times = no_fold))
# Partition data according to indices
out <- lapply(fold_indices, function(x) {
data %>%
dplyr::filter(index %in% x) %>%
dplyr::select(-index)
})
} else {
# Extract indices of geographic units
indices <- data[[L2.unit]] %>%
unique()
# Randomize order of indices
indices <- sample(indices, size = length(indices), replace = FALSE)
# Define number of units per fold
no_floor <- floor(length(indices) / k.folds)
no_remaining <- length(indices) - no_floor * k.folds
no_fold <- rep(no_floor, times = k.folds)
if (no_remaining > 0) {
no_fold[1:no_remaining] <- no_fold[1:no_remaining] + 1
}
# Split indices into folds
fold_indices <- split(indices, rep(1:k.folds, times = no_fold))
# Partition data according to indices
out <- lapply(fold_indices, function(x) {
data %>%
dplyr::filter(.data[[L2.unit]] %in% x)
})
}
# Function output
return(out)
}
# Function to create model list for best subset classifier
model_list <- function(y, L1.x, L2.x, L2.unit, L2.reg = NULL) {
# Individual-level random effects
L1_re <- paste(paste("(1 | ", L1.x, ")", sep = ""), collapse = " + ")
# Geographic unit or Geographic unit-Geographic region random effects
if (is.null(L2.reg)) {
L2_re <- paste("(1 | ", L2.unit, ")", sep = "")
} else {
L2_re <- paste(paste("(1 | ", L2.reg, "/", L2.unit, ")", sep = ""),
collapse = " + ")
}
# Combine all random effects
all_re <- paste(c(L1_re, L2_re), collapse = " + ")
# Empty model
empty_model <- list(as.formula(paste(y, " ~ ", all_re, sep = "")))
# Remaining models
L2_list <- lapply(seq_along(L2.x), function(x) {combn(L2.x, x)})
L2_list <- lapply(L2_list, function(x) {
apply(x, 2, function(c) {
as.formula(paste(y, " ~ ", paste(c, collapse = " + "), " + ", all_re, sep = ""))
})
}) %>%
unlist()
# Combine models in list
out <- c(empty_model, L2_list)
# Function output
return(out)
}
# Function to create model list for PCA classifier
model_list_pca <- function(y, L1.x, L2.x, L2.unit, L2.reg = NULL) {
# Individual-level random effects
L1_re <- paste(paste("(1 | ", L1.x, ")", sep = ""), collapse = " + ")
# Geographic unit or Geographic unit-Geographic region random effects
if (is.null(L2.reg)) {
L2_re <- paste("(1 | ", L2.unit, ")", sep = "")
} else {
L2_re <- paste(paste("(1 | ", L2.reg, "/", L2.unit, ")", sep = ""),
collapse = " + ")
}
# Combine all random effects
all_re <- paste(c(L1_re, L2_re), collapse = " + ")
# Empty model
empty_model <- list(as.formula(paste(y, " ~ ", all_re, sep = "")))
# Remaining models
L2_list <- lapply(seq_along(L2.x), function(x) {L2.x[1:x]})
L2_list <- lapply(L2_list, function(x) {
as.formula(paste(y, " ~ ", paste(x, collapse = " + "), " + ", all_re, sep = ""))
})
# Combine models in list
out <- c(empty_model, L2_list)
# Function output
return(out)
}
# Loss function
loss_function <- function(pred, data.valid,
loss.unit = c("individual", "L2.units"),
loss.measure = c("mse", "mae"),
y, L2.unit) {
if (loss.unit == "individual" & loss.measure == "mse") {
out <- mean((data.valid[[y]] - pred)^2)
} else if (loss.unit == "individual" & loss.measure == "mae") {
out <- mean(abs(data.valid[[y]] - pred))
} else if (loss.unit == "L2.units" & loss.measure == "mse") {
data.valid <- data.valid %>%
dplyr::mutate(pred = pred)
out <- data.valid %>%
dplyr::group_by_at(L2.unit) %>%
dplyr::summarise_at(.vars = c(y, "pred"), mean) %>%
dplyr::mutate(sqe = (.data[[y]] - pred)^2) %>%
dplyr::pull(sqe)
out <- mean(out)
} else {
data.valid <- data.valid %>%
dplyr::mutate(pred = pred)
out <- data.valid %>%
dplyr::group_by_at(L2.unit) %>%
dplyr::summarise_at(.vars = c(y, "pred"), mean) %>%
dplyr::mutate(ae = abs(.data[[y]] - pred)) %>%
dplyr::pull(ae)
out <- mean(out)
}
# Function output
return(out)
}
ebma_folding_out <- ebma_folding(data = survey,
L2.unit = L2.unit,
ebma.size = ebma.size)
# Load packages
library(magrittr)
# Clean working environment
rm(list = ls())
# Load survey data
load(here::here("data", "survey_paper_i11.RData"))
# Load census data
load(here::here("data", "census_paper_i11.RData"))
# Define outcome variable
#y <- "y"
y <- "YES"
#L1.x <- c("age", "educ", "gXr")
L1.x <- c("L1x1", "L1x2", "L1x3")
# Define context-level covariates
#L2.x <- c("pvote", "religcon", "urban", "unemp", "hispanics", "white")
L2.x <- c("L2.x1", "L2.x2", "L2.x3", "L2.x4", "L2.x5", "L2.x6")
# Define context-level unit
#L2.unit <- "stateid"
L2.unit <- "L2.unit"
# Define region in which context-level units are nested
L2.reg <- "region"
# Whether to scale context level variables (defaults to TRUE)
L2.x.scale <- FALSE
# Define column in census containing proportion
bin.proportion <- "proportion"
# Define column in census containing bin size
#bin.size <- "n"
bin.size <- NULL
# Whether to obtain bootstrapped prediction uncertainty
uncertainty <- FALSE
# Whether to include best subset classifier
best.subset <- TRUE
# Whether to include lasso classifier
lasso <- TRUE
# Whether to include pca classifier
pca <- TRUE
# Whether to include gb classifier
gb <- TRUE
# Whether to include svm classifier
svm <- TRUE
# Whether to include mrp classifier
mrp <- FALSE
# Whether to include forward selection
forward.selection <- FALSE
# Define fraction of EBMA size (NULL defaults to 1/3)
ebma.size <- NULL
# Define number of folds
k.folds <- 5
# provide user controlled fold assignment
custom.folds <- "fold"
# provide user controlled principal components
custom.pc <- TRUE
# Unit to be used in sampling to create CV folds
cv.sampling <- "L2 units"
# Set seed (NULL defaults to 12345)
seed <- NULL
# Set verbose option
verbose <- TRUE
# Define unit for loss function
loss.unit <- "individual"
# Define measure for loss function
loss.measure <- "mse"
# Define lambdas as vector for Lasso
lasso.lambda.set <- c(1, 2)
# Define maximum number of iterations w/o improvement for Lasso
lasso.iterations.max <- NULL
# Define set of interaction depths for GB
gb.interaction.set <- c(1, 2, 3)
# Define set of learning rates for GB
gb.shrinkage.set <- c(0.04, 0.01, 0.008, 0.005, 0.001)
# Define initial number of total trees
gb.tree.start <- 50
# Define increase in number of trees as scalar for GB
gb.tree.increase.set <- 50
# Define maximum number of trees as scalar for GB
gb.trees.max.set <- 1000
# Define maximum number of iterations w/o improvement for GB
gb.iterations.max <- 70
# Define minimum number of observations in terminal nodes for GB
gb.n.minobsinnode <- 5
# Define whether L2.unit should be inlcuded in GB
gb.L2.unit.include <- FALSE
# Define whether L2.reg should be included in GB
gb.L2.reg.include <- TRUE
# Define kernel for SVM
svm.kernel <- "radial"
# Define error function for SVM
svm.error.fun <- "MSE"   # // might need to be changed to NULL
# Define gamma parameters for SVM
svm.gamma.set <- c(0.3, 0.5, 0.55, 0.6, 0.65, 0.7, 0.8, 0.9, 1, 2, 3, 4)
# Define cost parameters for SVM
svm.cost.set <- c(1, 10)
# EBMA draws
ebma.n.draws <- 100
# tolerance values for ebma tuning
ebma.tol.values <- c(0.01, 0.001)
y
L1.x
L2.x
L2.unit
L2.reg
