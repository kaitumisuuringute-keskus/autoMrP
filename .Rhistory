model.family = binomial(link = "probit"),
model.optimizer = "bobyqa",
n.iter = 1000000,
verbose = verbose)
# Fit optimal model for post-stratification w/o EBMA
best_subset_opt_poststrat_only <- best_subset_classifier(
model = best.subset.opt,
data.train = no_ebma_data,
model.family = binomial(link = "probit"),
model.optimizer = "bobyqa",
n.iter = 1000000,
verbose = verbose)
# post-stratification
bs_preds <- census %>%
dplyr::mutate(best_subset = stats::predict(object = best_subset_opt_poststrat_only,
newdata = census, allow.new.levels = TRUE,
type = "response")) %>%
dplyr::group_by(.dots = list(L2_unit)) %>%
dplyr::summarize(best_subset = weighted.mean(x = best_subset, w = .data$prop), .groups = "keep")
# individual level predictions for EBMA
bs_ind <- stats::predict(object = best_subset_opt_ebma, type = "response")
# model for EBMA
models$best_subset <- best_subset_opt_ebma
}
# Determine context-level covariates
if (is.null(lasso.L2.x)) {
lasso.L2.x <- L2.x
}
# Context-level fixed effects
L2_fe <- paste(lasso.L2.x, collapse = " + ")
L2_fe_form <- as.formula(paste(y, " ~ ", L2_fe, sep = ""))
# Individual-level random effects as named list
L1_re <- setNames(as.list(rep(c(~ 1), times = length(c(L1.x, L2.unit, L2.reg)))),
c(L1.x, L2.unit, L2.reg))
# Fit optimal model for EBMA
lasso_opt_ebma <- lasso_classifier(
L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data,
lambda = lasso.opt,
model.family = binomial(link = "probit"),
verbose = verbose)
# Fit optimal model for post-stratification w/o EBMA
lasso_opt_poststrat_only <- lasso_classifier(
L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = no_ebma_data,
lambda = lasso.opt,
model.family = binomial(link = "probit"),
verbose = verbose)
# predictions for post-stratification only (no EBMA)
lasso_ests <- predict_glmmLasso(
m = lasso_opt_poststrat_only,
lasso.L2.x = lasso.L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
L1.x = L1.x,
census = census)
lasso_ests
class(lasso_ests)
mrp_out <- auto_MrP(
y = "YES",
L1.x = c("L1x1", "L1x2", "L1x3"),
L2.x = c("L2.x1", "L2.x2", "L2.x3", "L2.x4", "L2.x5", "L2.x6"),
L2.unit = "state",
L2.reg = "region",
bin.proportion = "proportion",
survey = taxes_survey,
census = taxes_census,
ebma.size = 0,
cores = max_cores,
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = FALSE,
mrp = TRUE
)
test <- mrp_out <- auto_MrP(
y = "YES",
L1.x = c("L1x1", "L1x2", "L1x3"),
L2.x = c("L2.x1", "L2.x2", "L2.x3", "L2.x4", "L2.x5", "L2.x6"),
L2.unit = "state",
L2.reg = "region",
bin.proportion = "proportion",
survey = taxes_survey,
census = taxes_census,
ebma.size = 0,
cores = max_cores,
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = FALSE,
mrp = TRUE
)
library(autoMrP)
devtools::load_all()
test <- mrp_out <- auto_MrP(
y = "YES",
L1.x = c("L1x1", "L1x2", "L1x3"),
L2.x = c("L2.x1", "L2.x2", "L2.x3", "L2.x4", "L2.x5", "L2.x6"),
L2.unit = "state",
L2.reg = "region",
bin.proportion = "proportion",
survey = autoMrP::taxes_survey,
census = autoMrP::taxes_census,
ebma.size = 0,
cores = max_cores,
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = FALSE,
mrp = TRUE
)
rm(list=ls())
# arguments
seed <- NULL
y = "YES"
L1.x = c("L1x1", "L1x2", "L1x3")
L2.x = c("")
L2.x = c("L2.x1", "L2.x2", "L2.x3", "L2.x4", "L2.x5", "L2.x6")
mrp.L2.x = NULL
L2.unit = "state"
L2.reg = "region"
L2.x.scale = TRUE
pcs = NULL
folds = NULL
bin.proportion = "proportion"
bin.size = NULL
survey = autoMrP::survey_item
census = autoMrP::census
ebma.size = 1/3
k.folds = 5
cv.sampling = "L2 units"
loss.unit = c("individuals", "L2 units")
loss.fun = c("MSE", "f1", "cross-entropy", "msfe")
# switch for classifiers
best.subset = TRUE
lasso = TRUE
pca = TRUE
gb = TRUE
svm = TRUE
# the standard MRP model
mrp = TRUE
forward.select = FALSE
best.subset.L2.x = NULL
lasso.L2.x = NULL
pca.L2.x = NULL
gb.L2.x = NULL
svm.L2.x = NULL
# Standard MrP model L2 variables
gb.L2.unit = FALSE
gb.L2.reg = TRUE
# tuning params lasso
#lasso.lambda = list(c(0.1, 0.3, 1), c(1, 10, 10000))
lasso.lambda = NULL #1/exp(-seq(from = -1, to = 4.5, length = 100))
lasso.n.iter = 100
# tuning params boosting
gb.interaction.depth = c(1, 2, 3)
gb.shrinkage = c(0.04, 0.01, 0.008, 0.005, 0.001)
gb.n.trees.init = 50
gb.n.trees.increase = 50
gb.n.trees.max = 1000
#gb.n.iter = 70
gb.n.minobsinnode = 5
svm.kernel = c("radial", "polynomial")
svm.loss.fun = NULL
svm.cost = NULL #  .1 #c(1, 2, 5, 10)
svm.gamma = NULL
svm.degree = NULL
ebma.n.draws = 1
ebma.tol = c(0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001)
uncertainty = FALSE
boot.iter <- NULL
seed = 2
verbose = FALSE
cores = 6
svm.L2.reg = TRUE
svm.L2.unit = TRUE
oversampling <- FALSE
ranef.test = TRUE
devtools::load_all()
test <- mrp_out <- auto_MrP(
y = "YES",
L1.x = c("L1x1", "L1x2", "L1x3"),
L2.x = c("L2.x1", "L2.x2", "L2.x3", "L2.x4", "L2.x5", "L2.x6"),
L2.unit = "state",
L2.reg = "region",
bin.proportion = "proportion",
survey = autoMrP::taxes_survey,
census = autoMrP::taxes_census,
ebma.size = 0,
cores = max_cores,
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = FALSE,
mrp = TRUE
)
test
summary.autoMrP(test)
log_spaced(min = .1, max = 100, n = 100)
library(autoMrP)
devtools::build()
# arguments
seed <- NULL
y = "YES"
L1.x = c("L1x1", "L1x2", "L1x3")
L2.x = c("")
L2.x = c("L2.x1", "L2.x2", "L2.x3", "L2.x4", "L2.x5", "L2.x6")
mrp.L2.x = NULL
L2.unit = "state"
L2.reg = "region"
L2.x.scale = TRUE
pcs = NULL
folds = NULL
bin.proportion = "proportion"
bin.size = NULL
survey = autoMrP::survey_item
census = autoMrP::census
ebma.size = 1/3
k.folds = 5
cv.sampling = "L2 units"
loss.unit = c("individuals", "L2 units")
loss.fun = c("MSE", "f1", "cross-entropy", "msfe")
# switch for classifiers
best.subset = TRUE
lasso = TRUE
pca = TRUE
gb = TRUE
svm = TRUE
# the standard MRP model
mrp = TRUE
forward.select = FALSE
best.subset.L2.x = NULL
lasso.L2.x = NULL
pca.L2.x = NULL
gb.L2.x = NULL
svm.L2.x = NULL
# Standard MrP model L2 variables
gb.L2.unit = FALSE
gb.L2.reg = TRUE
# tuning params lasso
#lasso.lambda = list(c(0.1, 0.3, 1), c(1, 10, 10000))
lasso.lambda = NULL #1/exp(-seq(from = -1, to = 4.5, length = 100))
lasso.n.iter = 100
# tuning params boosting
gb.interaction.depth = c(1, 2, 3)
gb.shrinkage = c(0.04, 0.01, 0.008, 0.005, 0.001)
gb.n.trees.init = 50
gb.n.trees.increase = 50
gb.n.trees.max = 1000
#gb.n.iter = 70
gb.n.minobsinnode = 5
svm.kernel = c("radial", "polynomial")
svm.loss.fun = NULL
svm.cost = NULL #  .1 #c(1, 2, 5, 10)
svm.gamma = NULL
svm.degree = NULL
ebma.n.draws = 1
ebma.tol = c(0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001)
uncertainty = FALSE
boot.iter <- NULL
seed = 2
verbose = FALSE
cores = 6
svm.L2.reg = TRUE
svm.L2.unit = TRUE
oversampling <- FALSE
ranef.test = TRUE
devtools::load_all()
survey <- autoMrP::taxes_survey
census <- autoMrP::taxes_census
start <- Sys.time()
mrp_out <- auto_MrP(
y = "YES",
L1.x = c("L1x1", "L1x2", "L1x3"),
L2.x = c("L2.x1", "L2.x2", "L2.x3", "L2.x4", "L2.x5", "L2.x6"),
L2.unit = "state",
L2.reg = "region",
bin.proportion = "proportion",
survey = taxes_survey,
census = taxes_census,
ebma.size = 0,
cores = max_cores,
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = FALSE,
mrp = TRUE
)
end <- Sys.time()
difftime(time1 = end, time2 = start, units = "secs")
library(autoMrP)
library(autoMrP)
devtools::check_win_devel(pkg = ".")
library(autoMrP)
devtools::check_win_devel(pkg = ".")
# toy example
taxes_survey
test <- taxes_survey %>%
dplyr::filter(dplyr::slice_sample(prop = 0.5))
`%>%` <- magrittr::`%>%`
test <- taxes_survey %>%
dplyr::filter(dplyr::slice_sample(prop = 0.5))
`%>%` <- magrittr::`%>%`
test <- taxes_survey %>%
dplyr::slice(dplyr::slice_sample(prop = 0.5))
dplyr::slice(dplyr::slice_sample(n = 100)
test <- taxes_survey %>%
test <- taxes_survey %>%
taxes_survey %>%
dplyr::slice(dplyr::slice_sample(n = 100)
test <- taxes_survey %>%
dplyr::slice(dplyr::slice_sample(n = 100))
test <- taxes_survey %>%
dplyr::slice_sample(prop = 0.5)
test
start <- Sys.time()
mrp_out <- auto_MrP(
y = "YES",
L1.x = c("L1x1", "L1x2", "L1x3"),
L2.x = c("L2.x1", "L2.x2", "L2.x3", "L2.x4", "L2.x5", "L2.x6"),
L2.unit = "state",
L2.reg = "region",
bin.proportion = "proportion",
survey = taxes_survey,
census = taxes_census,
ebma.size = 0,
cores = max_cores,
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = FALSE,
mrp = TRUE
)
end <- Sys.time()
difftime(time1 = end, time2 = start, units = "secs")
test <- taxes_survey %>%
dplyr::slice_sample(prop = 0.2)
start <- Sys.time()
mrp_out <- auto_MrP(
y = "YES",
L1.x = c("L1x1", "L1x2", "L1x3"),
L2.x = c("L2.x1", "L2.x2", "L2.x3", "L2.x4", "L2.x5", "L2.x6"),
L2.unit = "state",
L2.reg = "region",
bin.proportion = "proportion",
survey = taxes_survey,
census = taxes_census,
ebma.size = 0,
cores = max_cores,
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = FALSE,
mrp = TRUE
)
end <- Sys.time()
difftime(time1 = end, time2 = start, units = "secs")
test
`%>%` <- magrittr::`%>%`
test <- taxes_survey %>%
dplyr::slice_sample(prop = 0.2)
start <- Sys.time()
mrp_out <- auto_MrP(
y = "YES",
L1.x = c("L1x1"),
L2.x = c("L2.x1", "L2.x2"),
L2.unit = "state",
bin.proportion = "proportion",
survey = taxes_survey,
census = taxes_census,
ebma.size = 0,
cores = max_cores,
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = FALSE,
mrp = TRUE
)
end <- Sys.time()
difftime(time1 = end, time2 = start, units = "secs")
mrp_out <- auto_MrP(
y = "YES",
L1.x = c("L1x1"),
L2.x = c("L2.x1", "L2.x2"),
L2.unit = "state",
bin.proportion = "proportion",
survey = taxes_survey,
census = taxes_census,
ebma.size = 0,
cores = max_cores,
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = FALSE,
mrp = TRUE
)
end <- Sys.time()
difftime(time1 = end, time2 = start, units = "secs")
start <- Sys.time()
mrp_out <- auto_MrP(
y = "YES",
L1.x = c("L1x1"),
L2.x = c("L2.x1", "L2.x2"),
L2.unit = "state",
bin.proportion = "proportion",
survey = taxes_survey,
census = taxes_census,
ebma.size = 0,
cores = max_cores,
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = FALSE,
mrp = TRUE
)
end <- Sys.time()
difftime(time1 = end, time2 = start, units = "secs")
start <- Sys.time()
mrp_out <- auto_MrP(
y = "YES",
L1.x = c("L1x1"),
L2.x = c("L2.x1", "L2.x2"),
L2.unit = "state",
bin.proportion = "proportion",
survey = taxes_survey,
census = taxes_census,
ebma.size = 0,
cores = max_cores,
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = FALSE,
mrp = TRUE
)
end <- Sys.time()
difftime(time1 = end, time2 = start, units = "secs")
# Minimal example without machine learning
start <- Sys.time()
mrp_out <- auto_MrP(
y = "YES",
L1.x = c("L1x1"),
L2.x = c("L2.x1", "L2.x2"),
L2.unit = "state",
bin.proportion = "proportion",
survey = taxes_survey,
census = taxes_census,
ebma.size = 0,
cores = max_cores,
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = FALSE,
mrp = TRUE
)
end <- Sys.time()
difftime(time1 = end, time2 = start, units = "secs")
# Minimal example without machine learning
m_out <- auto_MrP(
y = "YES",
L1.x = c("L1x1"),
L2.x = c("L2.x1", "L2.x2"),
L2.unit = "state",
bin.proportion = "proportion",
survey = taxes_survey,
census = taxes_census,
ebma.size = 0,
cores = max_cores,
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = FALSE,
mrp = TRUE
)
# Minimal example without machine learning
m <- auto_MrP(
y = "YES",
L1.x = c("L1x1"),
L2.x = c("L2.x1", "L2.x2"),
L2.unit = "state",
bin.proportion = "proportion",
survey = taxes_survey,
census = taxes_census,
ebma.size = 0,
cores = max_cores,
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = FALSE,
mrp = TRUE
)
difftime(time1 = end, time2 = start, units = "secs")
summary(m)
plot(m)
library(autoMrP)
devtools::check_win_devel(".")
devtools::build(".")
