dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
data_valid <- data_valid %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
# Train model using lambda value on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda_value,
model.family = binomial(link = "probit"),
verbose = verbose)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data.frame(data_valid))
# Evaluate predictions based on loss function
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
loss.unit = loss.unit,
loss.fun = loss.fun,
y = y, L2.unit = L2.unit)
})
# Mean over all k folds
best_error <- mean(unlist(k_errors))
# Initialize lambda value associated with currently best error
lambda_out <- lambda_value
# Initialize counter for iterations since last performance improvement
iter_since_improv <- 0
# Loop over lambda values in lambda
for (l in 2:length(lambda)) {
# Set lambda value
lambda_value <- lambda[l]
# Print lambda value
if (isTRUE(verbose)) {
L <- length(lambda)
cat(paste("Lasso: Running lambda w/ value ", lambda_value,
" (lambda ", l, " out of max. ",
L, " lambdas)\n", sep = ""))
}
# Loop over each fold
k_errors <- lapply(seq_along(data), function(k) {
# Split data in training and validation sets
data_train <- dplyr::bind_rows(data[-k])
data_valid <- dplyr::bind_rows(data[k])
# Convert individual-level, geographic unit, and geographic region
# covariates to factor variables in training and validation sets
data_train <- data_train %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
data_valid <- data_valid %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
# Train model using lambda value on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda_value,
model.family = binomial(link = "probit"),
verbose = verbose)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data.frame(data_valid))
# Evaluate predictions based on loss function
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
loss.unit = loss.unit,
loss.fun = loss.fun,
y = y, L2.unit = L2.unit)
})
# Mean over all k folds
current_error <- mean(unlist(k_errors))
# Check if current lambda value outperforms the lambda value that was
# best so far
if (current_error < best_error) {
best_error <- current_error
lambda_out <- lambda_value
iter_since_improv <- 0
} else {
iter_since_improv <- iter_since_improv + 1
}
# Break loop if maximum number of iterations without performance
# improvement is reached
if (!is.null(iterations.max)) {
if (iter_since_improv > iterations.max) {
break
}
}
}
# Function output
return(lambda_out)
} else {
# Set lambda value to 0
lambda_value <- 0
# Initialize counter for lambda
lambda_no <- 1
# Print lambda value
if (isTRUE(verbose)) {
cat(paste("Lasso: Running lambda w/ value ", lambda_value,
" (lambda no. ", lambda_no, " -- no improvement evaluation)\n",
sep = ""))
}
# Loop over each fold
k_errors <- lapply(seq_along(data), function(k) {
# Split data in training and validation sets
data_train <- dplyr::bind_rows(data[-k])
data_valid <- dplyr::bind_rows(data[k])
# Convert individual-level, geographic unit, and geographic region
# covariates to factor variables in training and validation sets
data_train <- data_train %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
data_valid <- data_valid %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
# Train model using lambda value on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = as.numeric(lambda_value),
model.family = binomial(link = "probit"),
verbose = verbose)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data.frame(data_valid))
# Evaluate predictions based on loss function
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
loss.unit = loss.unit,
loss.fun = loss.fun,
y = y, L2.unit = L2.unit)
})
# Mean over all k folds
best_error <- mean(unlist(k_errors))
# Initialize lambda value associated with currently best error
lambda_out <- lambda_value
# Initialize counter for iterations since last performance improvement
iter_since_improv <- 0
# Loop over lambda values in lambda
while(lambda_value < dplyr::last(lambda[[2]])) {
# Set lambda value
lambda_value <- round(as.numeric(lambda_value), digits = 10)
lambda_value <- as.numeric(lambda_value) +
lambda[[1]][which(lambda_value < lambda[[2]])[1]]
# Update counter for lambda
lambda_no <- lambda_no + 1
# Print lambda value
if (isTRUE(verbose)) {
cat(paste("Lasso: Running lambda w/ value ", lambda_value,
" (lambda no. ", lambda_no, " -- iterations w/o improvement: ",
iter_since_improv, ")\n", sep = ""))
}
# Loop over each fold
k_errors <- lapply(seq_along(data), function(k) {
# Split data in training and validation sets
data_train <- dplyr::bind_rows(data[-k])
data_valid <- dplyr::bind_rows(data[k])
# Convert individual-level, geographic unit, and geographic region
# covariates to factor variables in training and validation sets
data_train <- data_train %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
data_valid <- data_valid %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
# Train model using lambda value on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = as.numeric(lambda_value),
model.family = binomial(link = "probit"),
verbose = verbose)
# Use trained model to make predictions for kth validation set
pred_l <- stats::predict(model_l, newdata = data.frame(data_valid))
# Evaluate predictions based on loss function
perform_l <- loss_function(pred = pred_l, data.valid = data_valid,
loss.unit = loss.unit,
loss.fun = loss.fun,
y = y, L2.unit = L2.unit)
})
# Mean over all k folds
current_error <- mean(unlist(k_errors))
# Check if current lambda value outperforms the lambda value that was
# best so far
if (current_error < best_error) {
best_error <- current_error
lambda_out <- lambda_value
iter_since_improv <- 0
} else {
iter_since_improv <- iter_since_improv + 1
}
# Break loop if maximum number of iterations without performance
# improvement is reached
if (!is.null(n.iter)) {
if (iter_since_improv > n.iter) {
break
}
}
}
# turn cat function back on
if(!isTRUE(verbose)) {
cat <- base::cat
}
# Function output
return(lambda_out)
}
cat <- base::cat
svm_classifier <- function(method, form, data, kernel,
error.fun, probability,
svm.gamma, svm.cost,
sampling = "cross", cross,
verbose = c(TRUE, FALSE)) {
# Train and evaluate model using the supplied set of tuning parameters
if (isTRUE(verbose == TRUE)) {
out <- e1071::tune(method = method,
train.x = form,
data = data,
kernel = kernel,
error.fun = error.fun,
probability = probability,
ranges = list(gamma = svm.gamma,
cost = svm.cost),
tunecontrol = e1071::tune.control(sampling = sampling,
cross = cross))
} else {
out <- invisible(capture.output(
suppressMessages(suppressWarnings(
e1071::tune(method = method,
train.x = form,
data = data,
kernel = kernel,
error.fun = error.fun,
probability = probability,
ranges = list(gamma = svm.gamma,
cost = svm.cost),
tunecontrol = e1071::tune.control(sampling = sampling,
cross = cross))
))
))
}
# Function output
return(out)
}
# Train model using lambda value on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = as.numeric(lambda_value),
model.family = binomial(link = "probit"),
verbose = verbose)
data_train
L2_fe
L2_fe_form
L1_re
lambda
lambda_value
k_errors
data_train
# Split data in training and validation sets
data_train <- dplyr::bind_rows(data[-k])
k=1
# Split data in training and validation sets
data_train <- dplyr::bind_rows(data[-k])
data_valid <- dplyr::bind_rows(data[k])
# Convert individual-level, geographic unit, and geographic region
# covariates to factor variables in training and validation sets
data_train <- data_train %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
data_valid <- data_valid %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
# Train model using lambda value on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda_value,
model.family = binomial(link = "probit"),
verbose = verbose)
model_l
# Run classifier
lasso_out <- run_lasso(y = y,
L1.x = L1.x,
L2.x = lasso.L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
loss.unit = loss.unit,
loss.fun = loss.fun,
lambda = lasso.lambda,
n.iter = lasso.n.iter,
data = cv_folds,
verbose = verbose)
verbose = verbose
data = cv_folds
n.iter = lasso.n.iter
verbos
verbose
lambda = lasso.lambda
f()
invisible(capture.output(f()))
test <- invisible(capture.output(f()))
test
test <- suppressMessages(suppressWarnings(test <- invisible(capture.output(f()))))
test
test <- suppressMessages(suppressWarnings(invisible(capture.output(f()))))
test
test <- suppressMessages(suppressWarnings(invisible(capture.output(f()))))
verbose=TRUE
# Run classifier
best_subset_out <- run_best_subset(y = y,
L1.x = L1.x,
L2.x = best.subset.L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
loss.unit = loss.unit,
loss.fun = loss.fun,
data = cv_folds,
verbose = verbose)
# Run classifier
lasso_out <- run_lasso(y = y,
L1.x = L1.x,
L2.x = lasso.L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
loss.unit = loss.unit,
loss.fun = loss.fun,
lambda = lasso.lambda,
n.iter = lasso.n.iter,
data = cv_folds,
verbose = verbose)
# Context-level fixed effects
L2_fe <- paste(L2.x, collapse = " + ")
L2_fe_form <- as.formula(paste(y, " ~ ", L2_fe, sep = ""))
# Individual-level random effects as named list
L1_re <- setNames(as.list(rep(c(~ 1),
times = length(c(L1.x, L2.unit, L2.reg)))),
c(L1.x, L2.unit, L2.reg))
lambda_value = 3
lambda_value = 3.4
lambda_value
k_errors
# Split data in training and validation sets
data_train <- dplyr::bind_rows(data[-k])
data_valid <- dplyr::bind_rows(data[k])
# Convert individual-level, geographic unit, and geographic region
# covariates to factor variables in training and validation sets
data_train <- data_train %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
data_valid <- data_valid %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
# Train model using lambda value on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda_value,
model.family = binomial(link = "probit"),
verbose = verbose)
model_l
k=2
# Split data in training and validation sets
data_train <- dplyr::bind_rows(data[-k])
data_valid <- dplyr::bind_rows(data[k])
# Convert individual-level, geographic unit, and geographic region
# covariates to factor variables in training and validation sets
data_train <- data_train %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
data_valid <- data_valid %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
# Train model using lambda value on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda_value,
model.family = binomial(link = "probit"),
verbose = verbose)
k=3
# Split data in training and validation sets
data_train <- dplyr::bind_rows(data[-k])
data_valid <- dplyr::bind_rows(data[k])
# Convert individual-level, geographic unit, and geographic region
# covariates to factor variables in training and validation sets
data_train <- data_train %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
data_valid <- data_valid %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
# Train model using lambda value on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda_value,
model.family = binomial(link = "probit"),
verbose = verbose)
k=4
# Split data in training and validation sets
data_train <- dplyr::bind_rows(data[-k])
data_valid <- dplyr::bind_rows(data[k])
# Convert individual-level, geographic unit, and geographic region
# covariates to factor variables in training and validation sets
data_train <- data_train %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
data_valid <- data_valid %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), as.factor)
# Train model using lambda value on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda_value,
model.family = binomial(link = "probit"),
verbose = verbose)
L2_fe_form
L2.fix = L2_fe_form
L1.re = L1_re
L1_re
data_train
data.train = data_train
lambda = lambda_value
model.family = binomial(link = "probit")
verbose
verbose= FALSE
# Train model using lambda value on kth training set
model_l <- lasso_classifier(L2.fix = L2_fe_form,
L1.re = L1_re,
data.train = data_train,
lambda = lambda_value,
model.family = binomial(link = "probit"),
verbose = verbose)
out <- invisible(capture.output(
suppressMessages(suppressWarnings(
e1071::tune(method = method,
train.x = form,
data = data,
kernel = kernel,
error.fun = error.fun,
probability = probability,
ranges = list(gamma = svm.gamma,
cost = svm.cost),
tunecontrol = e1071::tune.control(sampling = sampling,
cross = cross))
))
))
sampling
sampling = "cross"
out <- invisible(capture.output(
suppressMessages(suppressWarnings(
e1071::tune(method = method,
train.x = form,
data = data,
kernel = kernel,
error.fun = error.fun,
probability = probability,
ranges = list(gamma = svm.gamma,
cost = svm.cost),
tunecontrol = e1071::tune.control(sampling = sampling,
cross = cross))
))
))
cross
warnings()
?e1071::tune.control
out <- invisible(capture.output(
suppressMessages(suppressWarnings(
glmmLasso::glmmLasso(fix = L2.fix, rnd = L1.re,
data = data.train, lambda = lambda,
family = model.family,
switch.NR = FALSE, final.re = TRUE,
control = list(center = TRUE,
standardize = TRUE))
))
))
out
out <- glmmLasso::glmmLasso(fix = L2.fix, rnd = L1.re,
data = data.train, lambda = lambda,
family = model.family,
switch.NR = FALSE, final.re = TRUE,
control = list(center = TRUE,
standardize = TRUE))
out
class(out)
out <- invisible(capture.output(
suppressMessages(suppressWarnings(
glmmLasso::glmmLasso(fix = L2.fix, rnd = L1.re,
data = data.train, lambda = lambda,
family = model.family,
switch.NR = FALSE, final.re = TRUE,
control = list(center = TRUE,
standardize = TRUE))
))
))
class(out)
out <- invisible(
suppressMessages(suppressWarnings(
glmmLasso::glmmLasso(fix = L2.fix, rnd = L1.re,
data = data.train, lambda = lambda,
family = model.family,
switch.NR = FALSE, final.re = TRUE,
control = list(center = TRUE,
standardize = TRUE))
))
)
out <- quiet(
suppressMessages(suppressWarnings(
glmmLasso::glmmLasso(fix = L2.fix, rnd = L1.re,
data = data.train, lambda = lambda,
family = model.family,
switch.NR = FALSE, final.re = TRUE,
control = list(center = TRUE,
standardize = TRUE))
))
)
quiet <- function(x) {
sink(tempfile())
on.exit(sink())
invisible(force(x))
}
out <- quiet(
suppressMessages(suppressWarnings(
glmmLasso::glmmLasso(fix = L2.fix, rnd = L1.re,
data = data.train, lambda = lambda,
family = model.family,
switch.NR = FALSE, final.re = TRUE,
control = list(center = TRUE,
standardize = TRUE))
))
)
out
class(out)
library(autoMrP)
library(autoMrP)
library(autoMrP)
