svm.L2.x <- L2.x
}
# SVM without L2 variables
if (all(L2.x == "")) svm.L2.x <- NULL
# Evaluate inclusion of L2.unit in GB
if (isTRUE(svm.L2.unit)) {
svm.L2.unit <- L2.unit
} else {
svm.L2.unit <- NULL
}
# Evaluate inclusion of L2.reg in GB
if (isTRUE(svm.L2.reg)) {
svm.L2.reg <- L2.reg
} else {
svm.L2.reg <- NULL
}
# Run classifier
set.seed(seed)
svm_out <- run_svm(
y = y,
L1.x = L1.x,
L2.x = svm.L2.x,
L2.eval.unit = L2.unit,
L2.unit = svm.L2.unit,
L2.reg = svm.L2.reg,
kernel = svm.kernel,
loss.fun = loss.fun,
loss.unit = loss.unit,
gamma = svm.gamma,
cost = svm.cost,
data = cv_folds,
verbose = verbose,
cores = cores)
} else {
svm_out <- NULL
}
svm_out
message("Starting post-stratification")
set.seed(seed)
ps_out <- post_stratification(
y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
best.subset.opt = best_subset_out,
lasso.opt = lasso_out,
lasso.L2.x = lasso.L2.x,
pca.opt = pca_out,
gb.opt = gb_out,
svm.opt = svm_out,
svm.L2.reg = svm.L2.reg,
svm.L2.unit = svm.L2.unit,
svm.L2.x = svm.L2.x,
mrp.include = mrp,
n.minobsinnode = gb.n.minobsinnode,
L2.unit.include = gb.L2.unit,
L2.reg.include = gb.L2.reg,
kernel = svm.kernel,
mrp.L2.x = mrp.L2.x,
data = cv_data,
ebma.fold = ebma_fold,
census = census,
verbose = verbose
)
ps_out
set.seed(seed)
ebma_out <- ebma(
ebma.fold = ebma_fold,
y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
pc.names = pc_names,
post.strat = ps_out,
n.draws = ebma.n.draws,
tol = ebma.tol,
best.subset.opt = best_subset_out,
pca.opt = pca_out,
lasso.opt = lasso_out,
gb.opt = gb_out,
svm.opt = svm_out,
verbose = verbose,
cores = cores
)
ebma.fold = ebma_fold
y = y
L2.reg = L2.reg
pc.names = pc_names
post.strat = ps_out
n.draws = ebma.n.draws
tol = ebma.tol
best.subset.opt = best_subset_out
pca.opt = pca_out
lasso.opt = lasso_out
gb.opt = gb_out
svm.opt = svm_out
verbose = verbose
cores = cores
cores
message("Starting bayesian ensemble model averaging tuning")
all(L2.x == "")
# Models
model_bs <- post.strat$models$best_subset
model_pca <- post.strat$models$pca
model_lasso <- post.strat$models$lasso
model_gb <- post.strat$models$gb
model_svm <- post.strat$models$svm
model_mrp <- post.strat$models$mrp
model_bs
model_pca
model_lasso
model_gb
model_svm
model_mrp
# Training predictions
train_preds <- post.strat$predictions$Level1 %>%
dplyr::select(-one_of(y))
train_preds
# Training set outcomes
train_y <- dplyr::pull(.data = post.strat$predictions$Level1, var = y)
train_y
length(train_y)
cores
# Counter for verbose screen output
counter <- 0
# Container to store the MSE on the test folds
# Bootstrap draws in rows and tolerance values in columns
mse_collector <- matrix(
NA, nrow = n.draws,
ncol = length(tol),
dimnames = list( c(paste0("Ndraw_", seq(1:n.draws))),
c(paste0("Tol: ", tol) )))
mse_collector
# container for model weights for each draw and tolerance value
# Dimension 1 (rows): Bootstrap draws
# Dimension 2 (columns): Classifiers
# Dimension 3 (layers): Tolerance values
weights_box <- array(
NA,
dim = c(n.draws, ncol(train_preds), length(tol)),
dimnames = list( c(paste0("Ndraw_", seq(1:n.draws))),
c(colnames(train_preds)),
c(paste0("Tol: ", tol))))
idx.tol=1
idx.Ndraws=1
# Increase counter
counter <- counter +1
counter
# Determine number per group to sample
n_per_group <- as.integer(nrow(ebma.fold) / length(levels(ebma.fold[[L2.unit]])))
n_per_group
# Test set with n_per_group persons per state (with resampling)
test <- ebma.fold %>%
dplyr::group_by_at( .vars = L2.unit ) %>%
dplyr::sample_n( n_per_group, replace = TRUE) %>%
dplyr::ungroup() %>%
dplyr::mutate_at(.vars = c( L1.x, L2.unit, L2.reg), .funs = as.factor) %>%
dplyr::select( dplyr::one_of(c(y, L1.x, L2.x, L2.unit, L2.reg, pc.names)))
test
summary(test)
# predict outcomes in test set
test_preds <- dplyr::tibble(
best_subset = if(!is.null(model_bs)){
predict(object = model_bs, newdata = test, type = "response", allow.new.levels = TRUE)
} else{NA},
pca = if(!is.null(model_pca)){
predict(object = model_pca, newdata = test, type = "response", allow.new.levels = TRUE)
} else{NA},
lasso = if(!is.null(model_lasso)){
as.numeric(predict(object = model_lasso, newdata = data.frame(test), type = "response"))
} else{NA},
gb = if(!is.null(model_gb)){
gbm::predict.gbm(object = model_gb, newdata = test, n.trees = model_gb$n.trees, type = "response")
} else{NA},
svm = if(!is.null(model_svm)){
as.numeric(attr(predict(object = model_svm, newdata = test, probability = TRUE),"probabilities")[,"1"])
} else{NA},
mrp = if(!is.null(model_mrp)){
predict(object = model_mrp, newdata = test, type = "response", allow.new.levels = TRUE)
} else{NA}
)
test_preds
# remove NA's
test_preds <- tidyr::drop_na(data = test_preds)
test_preds
# predict outcomes in test set
test_preds <- dplyr::tibble(
best_subset = if(!is.null(model_bs)){
predict(object = model_bs, newdata = test, type = "response", allow.new.levels = TRUE)
} else{NA},
pca = if(!is.null(model_pca)){
predict(object = model_pca, newdata = test, type = "response", allow.new.levels = TRUE)
} else{NA},
lasso = if(!is.null(model_lasso)){
as.numeric(predict(object = model_lasso, newdata = data.frame(test), type = "response"))
} else{NA},
gb = if(!is.null(model_gb)){
gbm::predict.gbm(object = model_gb, newdata = test, n.trees = model_gb$n.trees, type = "response")
} else{NA},
svm = if(!is.null(model_svm)){
as.numeric(attr(predict(object = model_svm, newdata = test, probability = TRUE),"probabilities")[,"1"])
} else{NA},
mrp = if(!is.null(model_mrp)){
predict(object = model_mrp, newdata = test, type = "response", allow.new.levels = TRUE)
} else{NA}
)
# remove NA's
test_preds <- test_preds[,apply(X = test_preds, MARGIN = 2, FUN = function(x){
all(!is.na(x))})]
test_preds
# outcome on the test
# test_y <- dplyr::select(.data = test, one_of(y))
test_y <- dplyr::pull(.data = test, y)
# EBMA
if(verbose){
forecast.data <- EBMAforecast::makeForecastData(
.predCalibration = data.frame(train_preds),
.outcomeCalibration = train_y,
.predTest = data.frame(test_preds),
.outcomeTest = test_y)
forecast.out <- EBMAforecast::calibrateEnsemble(
forecast.data,
model = "normal",
useModelParams = FALSE,
tol = tol[idx.tol])
} else {
forecast.data <- quiet(
EBMAforecast::makeForecastData(
.predCalibration = data.frame(train_preds),
.outcomeCalibration = as.numeric(unlist(train_y)),
.predTest = data.frame(test_preds),
.outcomeTest = as.numeric(unlist(test_y)))
)
forecast.out <- quiet(EBMAforecast::calibrateEnsemble(
forecast.data,
model = "normal",
useModelParams = FALSE,
tol = tol[idx.tol]))
}
# mse
mse_collector[idx.Ndraws, idx.tol] <- mean(( as.numeric(unlist(test_y)) -
as.numeric( attributes(forecast.out)$predTest[,1,1]))^2)
# model weights
weights_box[idx.Ndraws, , idx.tol] <- attributes(forecast.out)$modelWeights
# progress
if (verbose) cat(paste("\n","EBMA: ", round(counter / (length(tol) * n.draws),2)*100, "% done",sep=""))
# loop over Ndraws wit equal obs/state
for (idx.Ndraws in 1:n.draws){
# Increase counter
counter <- counter +1
# Determine number per group to sample
n_per_group <- as.integer(nrow(ebma.fold) / length(levels(ebma.fold[[L2.unit]])))
# Test set with n_per_group persons per state (with resampling)
test <- ebma.fold %>%
dplyr::group_by_at( .vars = L2.unit ) %>%
dplyr::sample_n( n_per_group, replace = TRUE) %>%
dplyr::ungroup() %>%
dplyr::mutate_at(.vars = c( L1.x, L2.unit, L2.reg), .funs = as.factor) %>%
dplyr::select( dplyr::one_of(c(y, L1.x, L2.x, L2.unit, L2.reg, pc.names)))
# predict outcomes in test set
test_preds <- dplyr::tibble(
best_subset = if(!is.null(model_bs)){
predict(object = model_bs, newdata = test, type = "response", allow.new.levels = TRUE)
} else{NA},
pca = if(!is.null(model_pca)){
predict(object = model_pca, newdata = test, type = "response", allow.new.levels = TRUE)
} else{NA},
lasso = if(!is.null(model_lasso)){
as.numeric(predict(object = model_lasso, newdata = data.frame(test), type = "response"))
} else{NA},
gb = if(!is.null(model_gb)){
gbm::predict.gbm(object = model_gb, newdata = test, n.trees = model_gb$n.trees, type = "response")
} else{NA},
svm = if(!is.null(model_svm)){
as.numeric(attr(predict(object = model_svm, newdata = test, probability = TRUE),"probabilities")[,"1"])
} else{NA},
mrp = if(!is.null(model_mrp)){
predict(object = model_mrp, newdata = test, type = "response", allow.new.levels = TRUE)
} else{NA}
)
# remove NA's
test_preds <- test_preds[,apply(X = test_preds, MARGIN = 2, FUN = function(x){
all(!is.na(x))})]
# outcome on the test
# test_y <- dplyr::select(.data = test, one_of(y))
test_y <- dplyr::pull(.data = test, y)
# EBMA
if(verbose){
forecast.data <- EBMAforecast::makeForecastData(
.predCalibration = data.frame(train_preds),
.outcomeCalibration = train_y,
.predTest = data.frame(test_preds),
.outcomeTest = test_y)
forecast.out <- EBMAforecast::calibrateEnsemble(
forecast.data,
model = "normal",
useModelParams = FALSE,
tol = tol[idx.tol])
} else {
forecast.data <- quiet(
EBMAforecast::makeForecastData(
.predCalibration = data.frame(train_preds),
.outcomeCalibration = as.numeric(unlist(train_y)),
.predTest = data.frame(test_preds),
.outcomeTest = as.numeric(unlist(test_y)))
)
forecast.out <- quiet(EBMAforecast::calibrateEnsemble(
forecast.data,
model = "normal",
useModelParams = FALSE,
tol = tol[idx.tol]))
}
# mse
mse_collector[idx.Ndraws, idx.tol] <- mean(( as.numeric(unlist(test_y)) -
as.numeric( attributes(forecast.out)$predTest[,1,1]))^2)
# model weights
weights_box[idx.Ndraws, , idx.tol] <- attributes(forecast.out)$modelWeights
# progress
if (verbose) cat(paste("\n","EBMA: ", round(counter / (length(tol) * n.draws),2)*100, "% done",sep=""))
}
# which tolerance value minimizes the mse on the test set
best_tolerance <- apply(mse_collector, 1, function(x) which.min(x))
# container of best model weights
weights_mat <- matrix(data = NA, nrow = n.draws, ncol = ncol(train_preds))
# model weights; rows = observations, columns = model weights, layers = tolerance values
if (length(tol)>1){
for (idx.tol in 1:length(best_tolerance)){
weights_mat[idx.tol, ] <- weights_box[idx.tol, ,][ ,best_tolerance[idx.tol]]
}
} else{
weights_mat <- weights_box[, , 1]
}
# average model weights
if (is.null(dim(weights_mat))){
final_model_weights <- as.numeric(weights_mat)
} else{
final_model_weights <- apply(weights_mat, 2, mean)
}
names(final_model_weights) <- names(train_preds)
# Parallel tuning, if cores > 1
if (cores > 1){
# Distribute clusters over tolerance values or n.draws
if(length(tol) <= n.draws*3){
final_model_weights <- ebma_mc_draws(
train.preds = train_preds,
train.y = train_y,
ebma.fold = ebma.fold,
y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
pc.names = pc.names,
model.bs = model_bs,
model.pca = model_pca,
model.lasso = model_lasso,
model.gb = model_gb,
model.svm = model_svm,
model.mrp = model_mrp,
tol = tol,
n.draws = n.draws,
cores = cores)
} else {
final_model_weights <- ebma_mc_tol(
train.preds = train_preds,
train.y = train_y,
ebma.fold = ebma.fold,
y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
pc.names = pc.names,
model.bs = model_bs,
model.pca = model_pca,
model.lasso = model_lasso,
model.gb = model_gb,
model.svm = model_svm,
model.mrp = model_mrp,
tol = tol,
n.draws = n.draws,
cores = cores)
}
} else{
# Counter for verbose screen output
counter <- 0
# Container to store the MSE on the test folds
# Bootstrap draws in rows and tolerance values in columns
mse_collector <- matrix(
NA, nrow = n.draws,
ncol = length(tol),
dimnames = list( c(paste0("Ndraw_", seq(1:n.draws))),
c(paste0("Tol: ", tol) )))
# container for model weights for each draw and tolerance value
# Dimension 1 (rows): Bootstrap draws
# Dimension 2 (columns): Classifiers
# Dimension 3 (layers): Tolerance values
weights_box <- array(
NA,
dim = c(n.draws, ncol(train_preds), length(tol)),
dimnames = list( c(paste0("Ndraw_", seq(1:n.draws))),
c(colnames(train_preds)),
c(paste0("Tol: ", tol))))
# loop over tolerance values
for (idx.tol in 1:length(tol)){
# loop over Ndraws wit equal obs/state
for (idx.Ndraws in 1:n.draws){
# Increase counter
counter <- counter +1
# Determine number per group to sample
n_per_group <- as.integer(nrow(ebma.fold) / length(levels(ebma.fold[[L2.unit]])))
# Test set with n_per_group persons per state (with resampling)
test <- ebma.fold %>%
dplyr::group_by_at( .vars = L2.unit ) %>%
dplyr::sample_n( n_per_group, replace = TRUE) %>%
dplyr::ungroup() %>%
dplyr::mutate_at(.vars = c( L1.x, L2.unit, L2.reg), .funs = as.factor) %>%
dplyr::select( dplyr::one_of(c(y, L1.x, L2.x, L2.unit, L2.reg, pc.names)))
# predict outcomes in test set
test_preds <- dplyr::tibble(
best_subset = if(!is.null(model_bs)){
predict(object = model_bs, newdata = test, type = "response", allow.new.levels = TRUE)
} else{NA},
pca = if(!is.null(model_pca)){
predict(object = model_pca, newdata = test, type = "response", allow.new.levels = TRUE)
} else{NA},
lasso = if(!is.null(model_lasso)){
as.numeric(predict(object = model_lasso, newdata = data.frame(test), type = "response"))
} else{NA},
gb = if(!is.null(model_gb)){
gbm::predict.gbm(object = model_gb, newdata = test, n.trees = model_gb$n.trees, type = "response")
} else{NA},
svm = if(!is.null(model_svm)){
as.numeric(attr(predict(object = model_svm, newdata = test, probability = TRUE),"probabilities")[,"1"])
} else{NA},
mrp = if(!is.null(model_mrp)){
predict(object = model_mrp, newdata = test, type = "response", allow.new.levels = TRUE)
} else{NA}
)
# remove NA's
test_preds <- test_preds[,apply(X = test_preds, MARGIN = 2, FUN = function(x){
all(!is.na(x))})]
# outcome on the test
# test_y <- dplyr::select(.data = test, one_of(y))
test_y <- dplyr::pull(.data = test, y)
# EBMA
if(verbose){
forecast.data <- EBMAforecast::makeForecastData(
.predCalibration = data.frame(train_preds),
.outcomeCalibration = train_y,
.predTest = data.frame(test_preds),
.outcomeTest = test_y)
forecast.out <- EBMAforecast::calibrateEnsemble(
forecast.data,
model = "normal",
useModelParams = FALSE,
tol = tol[idx.tol])
} else {
forecast.data <- quiet(
EBMAforecast::makeForecastData(
.predCalibration = data.frame(train_preds),
.outcomeCalibration = as.numeric(unlist(train_y)),
.predTest = data.frame(test_preds),
.outcomeTest = as.numeric(unlist(test_y)))
)
forecast.out <- quiet(EBMAforecast::calibrateEnsemble(
forecast.data,
model = "normal",
useModelParams = FALSE,
tol = tol[idx.tol]))
}
# mse
mse_collector[idx.Ndraws, idx.tol] <- mean(( as.numeric(unlist(test_y)) -
as.numeric( attributes(forecast.out)$predTest[,1,1]))^2)
# model weights
weights_box[idx.Ndraws, , idx.tol] <- attributes(forecast.out)$modelWeights
# progress
if (verbose) cat(paste("\n","EBMA: ", round(counter / (length(tol) * n.draws),2)*100, "% done",sep=""))
}
}
# which tolerance value minimizes the mse on the test set
best_tolerance <- apply(mse_collector, 1, function(x) which.min(x))
# container of best model weights
weights_mat <- matrix(data = NA, nrow = n.draws, ncol = ncol(train_preds))
# model weights; rows = observations, columns = model weights, layers = tolerance values
if (length(tol)>1){
for (idx.tol in 1:length(best_tolerance)){
weights_mat[idx.tol, ] <- weights_box[idx.tol, ,][ ,best_tolerance[idx.tol]]
}
} else{
weights_mat <- weights_box[, , 1]
}
# average model weights
if (is.null(dim(weights_mat))){
final_model_weights <- as.numeric(weights_mat)
} else{
final_model_weights <- apply(weights_mat, 2, mean)
}
names(final_model_weights) <- names(train_preds)
}
# weighted average
w_avg <- as.numeric(as.matrix(post.strat$predictions$Level2[,names(final_model_weights)]) %*% final_model_weights)
# L2 preds object
L2_preds <- dplyr::tibble(
state = dplyr::pull(.data = post.strat$predictions$Level2, var = L2.unit),
ebma = w_avg
)
# function output
return(list(ebma = L2_preds, classifiers = post.strat$predictions$Level2, weights = final_model_weights))
library(autoMrP)
