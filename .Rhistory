# K folds for cross-validation
cv_data <- survey %>%
dplyr::filter_at(dplyr::vars(dplyr::one_of(folds)),
dplyr::any_vars(. != k.folds + 1))
cv_folds <- cv_data %>%
dplyr::group_split(.data[[folds]])
}
# Classifier 1: Best Subset
if (isTRUE(best.subset)) {
message("Starting multilevel regression with best subset selection classifier tuning")
# Determine context-level covariates
if (is.null(best.subset.L2.x)) {
best.subset.L2.x <- L2.x
}
# Run classifier
set.seed(seed)
best_subset_out <- run_best_subset(y = y,
L1.x = L1.x,
L2.x = best.subset.L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
loss.unit = loss.unit,
loss.fun = loss.fun,
data = cv_folds,
verbose = verbose,
cores = cores)
} else {
best_subset_out <- NULL
}
# Classifier 2: Lasso
if (isTRUE(lasso) & L2.x != "") {
message("Starting multilevel regression with L1 regularization tuning")
# Determine context-level covariates
if (is.null(lasso.L2.x)) {
lasso.L2.x <- L2.x
}
# Run classifier
set.seed(seed)
lasso_out <- run_lasso(y = y,
L1.x = L1.x,
L2.x = lasso.L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
loss.unit = loss.unit,
loss.fun = loss.fun,
lambda = lasso.lambda,
n.iter = lasso.n.iter,
data = cv_folds,
verbose = verbose,
cores = cores)
} else {
lasso_out <- NULL
}
# Classifier 3: PCA
if (isTRUE(pca) & L2.x != "") {
message("Starting multilevel regression with principal components as context level variables tuning")
set.seed(seed)
pca_out <- run_pca(
y = y,
L1.x = L1.x,
L2.x = pc_names,
L2.unit = L2.unit,
L2.reg = L2.reg,
loss.unit = loss.unit,
loss.fun = loss.fun,
data = cv_folds,
verbose = verbose,
cores = cores)
} else {
pca_out <- NULL
}
# Classifier 4: GB
if (isTRUE(gb)) {
message("Starting gradient tree boosting tuning")
# Determine context-level covariates
if (is.null(gb.L2.x)) {
gb.L2.x <- L2.x
}
# GB without L2 variables
if (L2.x == "") gb.L2.x <- NULL
# Evaluate inclusion of L2.unit in GB
if (isTRUE(gb.L2.unit)) {
gb.L2.unit <- L2.unit
} else {
gb.L2.unit <- NULL
}
# Evaluate inclusion of L2.reg in GB
if (isTRUE(gb.L2.reg)) {
gb.L2.reg <- L2.reg
} else {
gb.L2.reg <- NULL
}
# Run classifier
set.seed(seed)
gb_out <- run_gb(y = y,
L1.x = L1.x,
L2.x = gb.L2.x,
L2.eval.unit = L2.unit,
L2.unit = gb.L2.unit,
L2.reg = gb.L2.reg,
loss.unit = loss.unit,
loss.fun = loss.fun,
interaction.depth = gb.interaction.depth,
shrinkage = gb.shrinkage,
n.trees.init = gb.n.trees.init,
n.trees.increase = gb.n.trees.increase,
n.trees.max = gb.n.trees.max,
n.minobsinnode = gb.n.minobsinnode,
data = cv_folds,
cores = cores,
verbose = verbose)
} else {
gb_out <- NULL
}
# Classifier 5: SVM
if ( isTRUE(svm) ) {
message("Starting support vector machine tuning")
# Determine context-level covariates
if (is.null(svm.L2.x)) {
svm.L2.x <- L2.x
}
# SVM without L2 variables
if (L2.x == "") svm.L2.x <- NULL
# Evaluate inclusion of L2.unit in GB
if (isTRUE(svm.L2.unit)) {
svm.L2.unit <- L2.unit
} else {
svm.L2.unit <- NULL
}
# Evaluate inclusion of L2.reg in GB
if (isTRUE(svm.L2.reg)) {
svm.L2.reg <- L2.reg
} else {
svm.L2.reg <- NULL
}
# Run classifier
set.seed(seed)
svm_out <- run_svm(
y = y,
L1.x = L1.x,
L2.x = svm.L2.x,
L2.eval.unit = L2.unit,
L2.unit = svm.L2.unit,
L2.reg = svm.L2.reg,
kernel = svm.kernel,
loss.fun = loss.fun,
loss.unit = loss.unit,
gamma = svm.gamma,
cost = svm.cost,
data = cv_folds,
verbose = verbose,
cores = cores)
} else {
svm_out <- NULL
}
message("Starting post-stratification")
set.seed(seed)
ps_out <- post_stratification(
y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
best.subset.opt = best_subset_out,
lasso.opt = lasso_out,
lasso.L2.x = lasso.L2.x,
pca.opt = pca_out,
gb.opt = gb_out,
svm.opt = svm_out,
svm.L2.reg = svm.L2.reg,
svm.L2.unit = svm.L2.unit,
svm.L2.x = svm.L2.x,
mrp.include = mrp,
n.minobsinnode = gb.n.minobsinnode,
L2.unit.include = gb.L2.unit,
L2.reg.include = gb.L2.reg,
kernel = svm.kernel,
mrp.L2.x = mrp.L2.x,
data = cv_data,
ebma.fold = ebma_fold,
census = census,
verbose = verbose
)
set.seed(seed)
ebma_out <- ebma(
ebma.fold = ebma_fold,
y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
pc.names = pc_names,
post.strat = ps_out,
n.draws = ebma.n.draws,
tol = ebma.tol,
best.subset.opt = best_subset_out,
pca.opt = pca_out,
lasso.opt = lasso_out,
gb.opt = gb_out,
svm.opt = svm_out,
verbose = verbose,
cores = cores
)
ebma_out
library(autoMrP)
remove.packages("seissMrP")
remove.packages("swissMrP")
library(autoMrP)
library(autoMrP)
setwd("C:/Users/Philipp/Desktop/lucas data")
library(foreign)
#install_github("lleemann/swissMrP")
library(swissMrP)
# see: https://poliscizurich.wordpress.com/2010/04/26/minaret-initiative-and-the-pre-vote-surveys/
DATA <- read.dta("Minaret.dta")
attach(DATA)
# VOX data
table(Minaret)/sum(table(Minaret))    # amtliches Ergebnis 57.5% JA
# age
summary(lm(Minaret ~ factor(agegroup)))
# gender
summary(lm(Minaret ~ factor(female)))
# educ
summary(lm(Minaret ~ factor(educ)))
# cantons
summary(lm(Minaret ~ factor(cantonnr)))
# parties
summary(lm(Minaret ~ factor(party)))  # 1 FDP, 2 CVP, 3 SP, 4 SVP, 5 GPS, 6 GLP, 7 BDP, 8 andere, 9 keine Angabe
summary(lm(Minaret ~ factor(party) + factor(educ) + factor(female) + factor(agegroup) + factor(cantonnr)))
##########################################################################
# What are population values?
help(census)
census$census48.MAZH2013
Zensus <- census$census48.MAZH2013
EDUC.national <- rep(NA, 6)
EDUC.national[1] <- sum(Zensus[1:8,])/sum(Zensus)
EDUC.national[2] <- sum(Zensus[9:16,])/sum(Zensus)
EDUC.national[3] <- sum(Zensus[17:24,])/sum(Zensus)
EDUC.national[4] <- sum(Zensus[25:32,])/sum(Zensus)
EDUC.national[5] <- sum(Zensus[33:40,])/sum(Zensus)
EDUC.national[6] <- sum(Zensus[41:48,])/sum(Zensus)
FEMALE.national <- rep(NA,2)
even <- seq(2,48,by=2)
odd <- even-1
FEMALE.national[1] <- sum(Zensus[odd,])/sum(Zensus)
FEMALE.national[2] <- sum(Zensus[even,])/sum(Zensus)
AGE.national <- rep(NA,4)
a.pointer <- rep(c(1,1,2,2,3,3,4,4),6)
AGE.national[1] <- sum(Zensus[which(a.pointer==1),])/sum(Zensus)
AGE.national[2] <- sum(Zensus[which(a.pointer==2),])/sum(Zensus)
AGE.national[3] <- sum(Zensus[which(a.pointer==3),])/sum(Zensus)
AGE.national[4] <- sum(Zensus[which(a.pointer==4),])/sum(Zensus)
#CH Elections 2007: 15,8 -- 14,5 -- 19,6 -- 29,0 -- 9,6 --
PARTY.national <- c(0.158, 0.145, 0.196, 0.29, 0.096)
PARTY.national[6] <- 1-sum(PARTY.national)
educ.sample.distr <- table(educ)/sum(table(educ))
EDUC.national
1008*EDUC.national
1008*educ.sample.distr
weight.now <- EDUC.national/educ.sample.distr
weight.ind <- weight.now[educ]
wM <- weight.ind*Minaret
sum(weight.ind[-which(is.na(Minaret))]*Minaret[-which(is.na(Minaret))], na.rm=TRUE)/sum(weight.ind[-which(is.na(Minaret))], na.rm=TRUE)
library(survey)
# get rid of missings
drop1 <- which(is.na(educ))
drop2 <- which(is.na(agegroup))
drop3 <- which(is.na(female))
DATA <- DATA[-c(drop1,drop2,drop3),]
age.dist <- data.frame(agegroup = c(1:4), Freq = length(DATA$Minaret) * AGE.national)
female.dist <- data.frame(female = c(0,1), Freq =  length(DATA$Minaret) * FEMALE.national)
educ.dist <- data.frame(educ = c(1:6), Freq =  length(DATA$Minaret) * EDUC.national)
DATA.unweighted <- svydesign(ids=~1, data=DATA)
DATA.weighted <- rake(design = DATA.unweighted,
sample.margins = list(~female, ~educ, ~agegroup),
population.margins = list(female.dist, educ.dist, age.dist))
summary(weights(DATA.weighted))
DATA.weighted1 <- trimWeights(DATA.weighted,
upper=5,
strict=TRUE)
svytable(~ Minaret, design=DATA.weighted1)
svytable(~ Minaret, design=DATA.weighted1)/sum(svytable(~ Minaret, design=DATA.weighted1))
dim(Zensus)
types.population <- rowSums(Zensus)
types.population <- types.population/sum(types.population)
idealtype <- rep(NA, dim(DATA)[1])
a.pointer
e.pointer <- rep(c(1:6),each=8) #kronecker(c(1,2,3,4,5,6), rep(1,8))
f.pointer <- rep(c(0,1),24)
for (i in 1:48){
E <- which(DATA$educ==e.pointer[i])
A <- which(DATA$agegroup==a.pointer[i])
Fe <- which(DATA$female==f.pointer[i])
rows <- intersect(intersect(A,E),Fe)
idealtype[rows] <- i
}
idealtype.sample.freq <- table(idealtype)/sum(table(idealtype))
# compare frequencies
plot(c(idealtype.sample.freq) , types.population)
weights.ps <- types.population/idealtype.sample.freq
Min.48 <- rep(0,48)
for (i in 1:48){
Min.48[i] <- mean(DATA$Minaret[idealtype==i], na.rm=TRUE)
}
Min.48
sum(Min.48 * weights.ps, na.rm = TRUE)/sum(weights.ps[-c(2,3)])
DATA$education <- DATA$educ
DATA$woman <- DATA$female
DATA$age <- DATA$agegroup
DATA1 <- DATA[,c(1,4,5,6,8,10,11,12,13,14)]
DATA2 <- na.omit(DATA1)
M1 <- glmer(Minaret ~ german + (1|woman)  + (1|education) +
(1|age) + (1|cantonnr) + (1|region),
family=binomial("probit"), data=DATA2)
pred.M1.minaret <- swissMrP(response.model=M1, uncertainty=FALSE)
length(table(DATA2$cantonnr))
q <- swissMrP(response.model=M1, uncertainty=FALSE,
augment.data = matrix(c(1,1,1,0),2,2),
augment.row = c(11,21))
summary(q)
q
sum(q * colSums(Zensus))/sum(colSums(Zensus))
# W/o L2
M2 <- glmer(Minaret ~ (1|woman)  + (1|education) + (1|age) + (1|cantonnr) + (1|region), family=binomial("probit"), data=DATA)
pred.M2.minaret <- swissMrP(response.model=M2, uncertainty=FALSE)
sum(c(pred.M2.minaret) * colSums(Zensus)/sum(colSums(Zensus)))
pred.M2.minaret <- swissMrP(response.model=M2, uncertainty=TRUE)
plot(pred.M2.minaret)
map.MrP(pred.M2.minaret,threshold = c(0,0.45,0.5,0.53,0.56,0.59,0.62))
model1 <- glmer(Minaret ~ 1 + (1|female) + (1|agegroup) + (1|educ) + (1|cantonnr), data= DATA, family=binomial("probit"))
summary(model1)
re.female <- ranef(model1)$female[[1]]
re.agegroup <- ranef(model1)$agegroup[[1]]
re.educ <- ranef(model1)$educ[[1]]
re.cantonnr <- ranef(model1)$cantonnr[[1]]
female.re <- rep(re.female,24)
age.re <- rep(kronecker(re.agegroup,c(1,1)), 6)
educ.re <- kronecker(re.educ,rep(1, 8))
ind.re <- rowSums(cbind(female.re, age.re, educ.re))
ind.re <- ind.re + fixef(model1)
y.lat <- rep(NA,1248)
for (i in 1:26){
a <- ((i-1)*48)+1
b <- a + 47
y.lat[a:b] <- ind.re + re.cantonnr[i]
}
# predicted probabilities!
pp <- pnorm(y.lat)
dim(census$census48.MAZH2013)
a <- c()
for (i in 1:26){
a <- c(a,census$census48.MAZH2013[,i])
}
# Estimate
sum(pp*a)/sum(a)
devtools::install_github("retowuest/autoMrP")
swissMrP::census$census48.MAZH2013
data.census <- data.frame(matrix(NA,2*4*6*26,7))
data.census[,1] <- kronecker(c(1:26),rep(1, 48))
colnames(data.census)[1] <- "cantonnr"
data.census[,2] <- rep(kronecker(c(1:6),rep(1, 8)),26)
colnames(data.census)[2] <- "educ"
data.census[,3] <- rep(rep(kronecker(c(1:4),c(1,1)), 6),26)
colnames(data.census)[3] <- "agegroup"
data.census[,4] <- rep(rep(c(1:2),24),26)
colnames(data.census)[4] <- "female"
# Level 2
colnames(data.census)[5] <- "german"
data.census[,5] <- 0
german.canton <- which(table(DATA$german,DATA$cantonnr)[2,]!=0)
for (i in 1:26){
if (i %in% german.canton){
data.census[data.census$cantonnr==i,5] <- 1
}
}
colnames(data.census)[6] <- "proportion"
for (i in 1:26){
numbers.census <- swissMrP::census$census48.MAZH2013[,i]
numbers.census <- numbers.census/sum(numbers.census)
a <- 1+ (i-1)*48
b <- i*48
data.census[a:b,6] <- numbers.census
}
colnames(data.census)[7] <- "region"
cr.table <- table(DATA$cantonnr,DATA$region)
cr.table[11,2] <- 1
cr.table <- cbind(cr.table,rep(0,26))
cr.table[21,7] <- 1
for (i in 1:26){
fetch.region <- which(cr.table[i,]!=0)
data.census[data.census[,1]==i,7] <- fetch.region
}
mrp_model <- auto_MrP(
y = "Minaret",
L1.x = c("female", "educ", "agegroup"),
L2.x = c("german"),
L2.unit = "cantonnr",
L2.reg = "region",
survey = DATA2, # survey data
census = data.census, # census information
bin.proportion = "proportion",
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = FALSE,
mrp = TRUE)
library(autoMrP)
mrp_model <- auto_MrP(
y = "Minaret",
L1.x = c("female", "educ", "agegroup"),
L2.x = c("german"),
L2.unit = "cantonnr",
L2.reg = "region",
survey = DATA2, # survey data
census = data.census, # census information
bin.proportion = "proportion",
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = FALSE,
mrp = TRUE)
M1 <- glmer(Minaret ~ german + (1|woman)  + (1|education) +
(1|age) + (1|cantonnr) + (1|region),
family=binomial("probit"), data=DATA2)
pred.M1.minaret <- swissMrP(response.model=M1, uncertainty=FALSE,
augment.data = matrix(c(1,1,1,0),2,2),
augment.row = c(11,21))
plot(as.vector(as.matrix(mrp_model$class[,2])),c(pred.M1.minaret))
abline(coef=c(0,1))
vox.data <- read.dta("vox_data.dta", convert.factors=FALSE)
head(vox.data)
summary(vox.data)
table(vox.data$Vorlage)
table(vox.data$AbstNrBFS)
# Let's look at the 10th AHV revision
data.4440 <- vox.data[vox.data$AbstNrBFS==4440,]
head(data.4440)
summary(data.4440)
length(data.4440$abst_entscheid)
table(data.4440$abst_entscheid)
cantonnr <- data.4440$cantonnr
female <- data.4440$sexe
educ <- data.4440$educ
agegroup <- data.4440$age_group
region <- data.4440$region
# Outcome
vote.ahv <- data.4440$abst_entscheid
# Level-2 Variables.
deutsch <- data.4440$german_share
kath <- data.4440$romkath_share
links <- data.4440$leftvote_share
svp <- data.4440$svpvote_share
# Create matrix
data.analysis.4440 <- data.frame(cbind(vote.ahv, cantonnr, region, female, educ, agegroup, deutsch, kath, links, svp))
head(data.analysis.4440)
# add information to census block
deutsch.canton <- which(table(data.analysis.4440$deutsch,data.analysis.4440$cantonnr)[2,]!=0)
data.census$deutsch <- NA
for (i in 1:26){
XXXX <- unique(data.analysis.4440$deutsch[data.analysis.4440$cantonnr==i])
data.census$deutsch[data.census$cantonnr==i] <- XXXX
}
data.census$kath <- NA
for (i in 1:26){
XXXX <- unique(data.analysis.4440$kath[data.analysis.4440$cantonnr==i])
data.census$kath[data.census$cantonnr==i] <- XXXX
}
data.census$links <- NA
for (i in 1:26){
XXXX <- unique(data.analysis.4440$links[data.analysis.4440$cantonnr==i])
data.census$links[data.census$cantonnr==i] <- XXXX
}
data.census$svp <- NA
for (i in 1:26){
XXXX <- unique(data.analysis.4440$svp[data.analysis.4440$cantonnr==i])
data.census$svp[data.census$cantonnr==i] <- XXXX
}
# just run a larger model
mrp_model.2 <- auto_MrP(
y = "vote.ahv",
L1.x = c("female", "educ", "agegroup"),
L2.x = c("deutsch","kath","links", "svp"),
L2.unit = "cantonnr",
#L2.reg = "region",
survey = data.analysis.4440, # survey data
census = data.census, # census information
bin.proportion = "proportion",
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = FALSE,
mrp = TRUE)
c(mrp_model.2$classifiers[,2])$mrp
# just run a larger model
mrp_model.2 <- auto_MrP(
y = "vote.ahv",
L1.x = c("female", "educ", "agegroup"),
L2.x = c("deutsch","kath","links", "svp"),
L2.unit = "cantonnr",
#L2.reg = "region",
survey = data.analysis.4440, # survey data
census = data.census, # census information
bin.proportion = "proportion",
best.subset = FALSE,
lasso = FALSE,
pca = FALSE,
gb = FALSE,
svm = FALSE,
mrp = TRUE)
